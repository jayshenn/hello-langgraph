# å·¥ä½œæµæ¨¡å¼

> ğŸ¯ **å­¦ä¹ ç›®æ ‡**ï¼šæŒæ¡å¸¸è§çš„å·¥ä½œæµè®¾è®¡æ¨¡å¼ï¼Œå­¦ä¼šåœ¨ LangGraph ä¸­æ„å»ºå¤æ‚çš„ä¸šåŠ¡æµç¨‹

## ğŸŒŸ ä»€ä¹ˆæ˜¯å·¥ä½œæµæ¨¡å¼ï¼Ÿ

å·¥ä½œæµæ¨¡å¼æ˜¯è§£å†³ç‰¹å®šä¸šåŠ¡åœºæ™¯çš„**å¯å¤ç”¨çš„å›¾ç»“æ„è®¾è®¡**ã€‚å°±åƒè®¾è®¡æ¨¡å¼åœ¨è½¯ä»¶å¼€å‘ä¸­çš„ä½œç”¨ä¸€æ ·ï¼Œå·¥ä½œæµæ¨¡å¼ä¸ºæˆ‘ä»¬æä¾›äº†ç»è¿‡éªŒè¯çš„è§£å†³æ–¹æ¡ˆã€‚

### ä¸ºä»€ä¹ˆéœ€è¦å·¥ä½œæµæ¨¡å¼ï¼Ÿ

```python
# âŒ æ²¡æœ‰æ¨¡å¼çš„æ··ä¹±ä»£ç 
def messy_workflow(state):
    # æ‰€æœ‰é€»è¾‘éƒ½å †åœ¨ä¸€èµ·
    if state["step1_done"]:
        if state["condition_a"]:
            # åšä¸€å †äº‹æƒ…...
            if state["another_condition"]:
                # åˆåšä¸€å †äº‹æƒ…...
                pass
    # å¾ˆéš¾ç†è§£å’Œç»´æŠ¤

# âœ… ä½¿ç”¨æ¨¡å¼çš„æ¸…æ™°ç»“æ„
def sequential_step1(state): ...
def sequential_step2(state): ...
def conditional_router(state): ...
# æ¸…æ™°ã€å¯ç»´æŠ¤ã€å¯å¤ç”¨
```

## ğŸ“‹ å…­å¤§æ ¸å¿ƒå·¥ä½œæµæ¨¡å¼

### 1. é¡ºåºæ¨¡å¼ï¼ˆSequential Patternï¼‰

**ä½¿ç”¨åœºæ™¯**ï¼šæ­¥éª¤æ˜ç¡®çš„çº¿æ€§æµç¨‹

```python
from typing import TypedDict
from langgraph.graph import StateGraph, END

class SequentialState(TypedDict):
    input_data: str
    processed_data: str
    validated_data: str
    final_result: str
    current_step: str

def data_input(state: SequentialState) -> SequentialState:
    """æ­¥éª¤1ï¼šæ•°æ®è¾“å…¥"""
    return {
        **state,
        "processed_data": f"è¾“å…¥: {state['input_data']}",
        "current_step": "æ•°æ®è¾“å…¥å®Œæˆ"
    }

def data_processing(state: SequentialState) -> SequentialState:
    """æ­¥éª¤2ï¼šæ•°æ®å¤„ç†"""
    processed = state["processed_data"].upper()
    return {
        **state,
        "processed_data": processed,
        "current_step": "æ•°æ®å¤„ç†å®Œæˆ"
    }

def data_validation(state: SequentialState) -> SequentialState:
    """æ­¥éª¤3ï¼šæ•°æ®éªŒè¯"""
    is_valid = len(state["processed_data"]) > 0
    return {
        **state,
        "validated_data": state["processed_data"] if is_valid else "æ— æ•ˆæ•°æ®",
        "current_step": "æ•°æ®éªŒè¯å®Œæˆ"
    }

def generate_result(state: SequentialState) -> SequentialState:
    """æ­¥éª¤4ï¼šç”Ÿæˆç»“æœ"""
    return {
        **state,
        "final_result": f"æœ€ç»ˆç»“æœ: {state['validated_data']}",
        "current_step": "æµç¨‹å®Œæˆ"
    }

# æ„å»ºé¡ºåºå›¾
sequential_graph = StateGraph(SequentialState)
sequential_graph.add_node("input", data_input)
sequential_graph.add_node("process", data_processing)
sequential_graph.add_node("validate", data_validation)
sequential_graph.add_node("result", generate_result)

# é¡ºåºè¿æ¥
sequential_graph.set_entry_point("input")
sequential_graph.add_edge("input", "process")
sequential_graph.add_edge("process", "validate")
sequential_graph.add_edge("validate", "result")
sequential_graph.add_edge("result", END)

sequential_app = sequential_graph.compile()

# æµ‹è¯•
result = sequential_app.invoke({
    "input_data": "hello world",
    "processed_data": "",
    "validated_data": "",
    "final_result": "",
    "current_step": ""
})
print(f"é¡ºåºæ¨¡å¼ç»“æœ: {result['final_result']}")
```

### 2. å¹¶è¡Œæ¨¡å¼ï¼ˆParallel Patternï¼‰

**ä½¿ç”¨åœºæ™¯**ï¼šéœ€è¦åŒæ—¶å¤„ç†å¤šä¸ªç‹¬ç«‹ä»»åŠ¡

```python
class ParallelState(TypedDict):
    user_query: str
    web_results: str
    database_results: str
    api_results: str
    combined_results: str

def web_search(state: ParallelState) -> ParallelState:
    """å¹¶è¡Œä»»åŠ¡1ï¼šç½‘ç»œæœç´¢"""
    import time
    time.sleep(1)  # æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
    return {
        **state,
        "web_results": f"ç½‘ç»œæœç´¢'{state['user_query']}'çš„ç»“æœ"
    }

def database_query(state: ParallelState) -> ParallelState:
    """å¹¶è¡Œä»»åŠ¡2ï¼šæ•°æ®åº“æŸ¥è¯¢"""
    import time
    time.sleep(1.5)  # æ¨¡æ‹Ÿæ•°æ®åº“æŸ¥è¯¢
    return {
        **state,
        "database_results": f"æ•°æ®åº“æŸ¥è¯¢'{state['user_query']}'çš„ç»“æœ"
    }

def api_call(state: ParallelState) -> ParallelState:
    """å¹¶è¡Œä»»åŠ¡3ï¼šAPIè°ƒç”¨"""
    import time
    time.sleep(0.8)  # æ¨¡æ‹ŸAPIè°ƒç”¨
    return {
        **state,
        "api_results": f"APIè°ƒç”¨'{state['user_query']}'çš„ç»“æœ"
    }

def combine_results(state: ParallelState) -> ParallelState:
    """æ±‡æ€»æ‰€æœ‰ç»“æœ"""
    combined = f"""
ç»¼åˆç»“æœï¼š
- ç½‘ç»œ: {state['web_results']}
- æ•°æ®åº“: {state['database_results']}
- API: {state['api_results']}
    """.strip()

    return {
        **state,
        "combined_results": combined
    }

# æ„å»ºå¹¶è¡Œå›¾
parallel_graph = StateGraph(ParallelState)
parallel_graph.add_node("web_search", web_search)
parallel_graph.add_node("db_query", database_query)
parallel_graph.add_node("api_call", api_call)
parallel_graph.add_node("combine", combine_results)

# ä»å…¥å£ç‚¹åˆ°ä¸‰ä¸ªå¹¶è¡Œä»»åŠ¡
parallel_graph.set_entry_point("web_search")
parallel_graph.add_edge("web_search", "combine")
parallel_graph.add_edge("db_query", "combine")
parallel_graph.add_edge("api_call", "combine")
parallel_graph.add_edge("combine", END)

# æ³¨æ„ï¼šå®é™…å¹¶è¡Œéœ€è¦ä½¿ç”¨ç‰¹æ®Šçš„å¹¶è¡ŒèŠ‚ç‚¹
# è¿™é‡Œç®€åŒ–å±•ç¤ºæ¦‚å¿µ
```

### 3. æ¡ä»¶åˆ†æ”¯æ¨¡å¼ï¼ˆConditional Branching Patternï¼‰

**ä½¿ç”¨åœºæ™¯**ï¼šåŸºäºæ¡ä»¶é€‰æ‹©ä¸åŒçš„å¤„ç†è·¯å¾„

```python
class ConditionalState(TypedDict):
    user_message: str
    message_type: str
    urgency_level: str
    processing_method: str
    response: str

def message_classifier(state: ConditionalState) -> ConditionalState:
    """æ¶ˆæ¯åˆ†ç±»å™¨"""
    message = state["user_message"].lower()

    if any(word in message for word in ["ç´§æ€¥", "æ€¥", "é©¬ä¸Š"]):
        urgency = "high"
    elif any(word in message for word in ["ä¸€èˆ¬", "æ™®é€š"]):
        urgency = "medium"
    else:
        urgency = "low"

    if any(word in message for word in ["æŠ€æœ¯", "bug", "é”™è¯¯"]):
        msg_type = "technical"
    elif any(word in message for word in ["é”€å”®", "è´­ä¹°", "ä»·æ ¼"]):
        msg_type = "sales"
    else:
        msg_type = "general"

    return {
        **state,
        "message_type": msg_type,
        "urgency_level": urgency
    }

def route_by_urgency(state: ConditionalState) -> str:
    """æŒ‰ç´§æ€¥ç¨‹åº¦è·¯ç”±"""
    if state["urgency_level"] == "high":
        return "urgent_handler"
    elif state["message_type"] == "technical":
        return "technical_handler"
    elif state["message_type"] == "sales":
        return "sales_handler"
    else:
        return "general_handler"

def urgent_handler(state: ConditionalState) -> ConditionalState:
    """ç´§æ€¥å¤„ç†"""
    return {
        **state,
        "processing_method": "ç´§æ€¥å¤„ç†é€šé“",
        "response": "å·²å‡çº§ä¸ºç´§æ€¥ä»»åŠ¡ï¼Œå°†ç«‹å³å¤„ç†"
    }

def technical_handler(state: ConditionalState) -> ConditionalState:
    """æŠ€æœ¯é—®é¢˜å¤„ç†"""
    return {
        **state,
        "processing_method": "æŠ€æœ¯æ”¯æŒå›¢é˜Ÿ",
        "response": "æŠ€æœ¯å›¢é˜Ÿå°†åœ¨4å°æ—¶å†…å›å¤"
    }

def sales_handler(state: ConditionalState) -> ConditionalState:
    """é”€å”®é—®é¢˜å¤„ç†"""
    return {
        **state,
        "processing_method": "é”€å”®å›¢é˜Ÿ",
        "response": "é”€å”®é¡¾é—®å°†åœ¨2å°æ—¶å†…è”ç³»æ‚¨"
    }

def general_handler(state: ConditionalState) -> ConditionalState:
    """ä¸€èˆ¬é—®é¢˜å¤„ç†"""
    return {
        **state,
        "processing_method": "å®¢æœå›¢é˜Ÿ",
        "response": "æ„Ÿè°¢æ‚¨çš„å’¨è¯¢ï¼Œæˆ‘ä»¬å°†åœ¨24å°æ—¶å†…å›å¤"
    }

# æ„å»ºæ¡ä»¶åˆ†æ”¯å›¾
conditional_graph = StateGraph(ConditionalState)
conditional_graph.add_node("classifier", message_classifier)
conditional_graph.add_node("urgent_handler", urgent_handler)
conditional_graph.add_node("technical_handler", technical_handler)
conditional_graph.add_node("sales_handler", sales_handler)
conditional_graph.add_node("general_handler", general_handler)

conditional_graph.set_entry_point("classifier")
conditional_graph.add_conditional_edges(
    "classifier",
    route_by_urgency,
    {
        "urgent_handler": "urgent_handler",
        "technical_handler": "technical_handler",
        "sales_handler": "sales_handler",
        "general_handler": "general_handler"
    }
)

# æ‰€æœ‰å¤„ç†å™¨éƒ½æŒ‡å‘ç»“æŸ
conditional_graph.add_edge("urgent_handler", END)
conditional_graph.add_edge("technical_handler", END)
conditional_graph.add_edge("sales_handler", END)
conditional_graph.add_edge("general_handler", END)

conditional_app = conditional_graph.compile()
```

### 4. å¾ªç¯æ¨¡å¼ï¼ˆLoop Patternï¼‰

**ä½¿ç”¨åœºæ™¯**ï¼šéœ€è¦é‡è¯•ã€è¿­ä»£æˆ–å¾ªç¯å¤„ç†

```python
class LoopState(TypedDict):
    task_description: str
    attempts: int
    max_attempts: int
    success: bool
    errors: list[str]
    result: str

def attempt_task(state: LoopState) -> LoopState:
    """å°è¯•æ‰§è¡Œä»»åŠ¡"""
    import random

    attempts = state["attempts"] + 1

    # æ¨¡æ‹Ÿä»»åŠ¡æ‰§è¡Œï¼ˆ70% æˆåŠŸç‡ï¼Œéšå°è¯•æ¬¡æ•°å¢åŠ ï¼‰
    success_rate = 0.3 + (attempts * 0.2)
    success = random.random() < success_rate

    if success:
        return {
            **state,
            "attempts": attempts,
            "success": True,
            "result": f"ä»»åŠ¡åœ¨ç¬¬ {attempts} æ¬¡å°è¯•æ—¶æˆåŠŸå®Œæˆ"
        }
    else:
        error_msg = f"ç¬¬ {attempts} æ¬¡å°è¯•å¤±è´¥"
        return {
            **state,
            "attempts": attempts,
            "success": False,
            "errors": state["errors"] + [error_msg]
        }

def check_loop_condition(state: LoopState) -> str:
    """æ£€æŸ¥æ˜¯å¦ç»§ç»­å¾ªç¯"""
    if state["success"]:
        return "success"
    elif state["attempts"] >= state["max_attempts"]:
        return "max_attempts_reached"
    else:
        return "retry"

def handle_success(state: LoopState) -> LoopState:
    """å¤„ç†æˆåŠŸæƒ…å†µ"""
    return {
        **state,
        "result": f"âœ… {state['result']}"
    }

def handle_failure(state: LoopState) -> LoopState:
    """å¤„ç†æœ€ç»ˆå¤±è´¥"""
    return {
        **state,
        "result": f"âŒ ä»»åŠ¡å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({state['max_attempts']})"
    }

# æ„å»ºå¾ªç¯å›¾
loop_graph = StateGraph(LoopState)
loop_graph.add_node("attempt", attempt_task)
loop_graph.add_node("success", handle_success)
loop_graph.add_node("failure", handle_failure)

loop_graph.set_entry_point("attempt")
loop_graph.add_conditional_edges(
    "attempt",
    check_loop_condition,
    {
        "success": "success",
        "max_attempts_reached": "failure",
        "retry": "attempt"  # å¾ªç¯å›åˆ°è‡ªå·±
    }
)

loop_graph.add_edge("success", END)
loop_graph.add_edge("failure", END)

loop_app = loop_graph.compile()

# æµ‹è¯•å¾ªç¯æ¨¡å¼
loop_result = loop_app.invoke({
    "task_description": "ç½‘ç»œAPIè°ƒç”¨",
    "attempts": 0,
    "max_attempts": 5,
    "success": False,
    "errors": [],
    "result": ""
})
print(f"å¾ªç¯æ¨¡å¼ç»“æœ: {loop_result['result']}")
```

### 5. MapReduce æ¨¡å¼

**ä½¿ç”¨åœºæ™¯**ï¼šå¤§æ•°æ®å¤„ç†ï¼Œåˆ†æ•£è®¡ç®—åèšåˆ

```python
class MapReduceState(TypedDict):
    input_data: list[str]
    chunk_size: int
    mapped_results: list[str]
    reduced_result: str

def split_data(state: MapReduceState) -> MapReduceState:
    """åˆ†å‰²æ•°æ®ï¼ˆMapé˜¶æ®µçš„å‡†å¤‡ï¼‰"""
    data = state["input_data"]
    chunk_size = state["chunk_size"]

    # å°†æ•°æ®åˆ†æˆå—
    chunks = [data[i:i + chunk_size] for i in range(0, len(data), chunk_size)]

    return {
        **state,
        "input_data": chunks  # ç°åœ¨å­˜å‚¨çš„æ˜¯åˆ†å—åçš„æ•°æ®
    }

def map_process(state: MapReduceState) -> MapReduceState:
    """Mapé˜¶æ®µï¼šå¹¶è¡Œå¤„ç†æ¯ä¸ªæ•°æ®å—"""
    mapped_results = []

    for chunk in state["input_data"]:
        # å¯¹æ¯ä¸ªå—è¿›è¡Œå¤„ç†ï¼ˆä¾‹å¦‚ï¼šç»Ÿè®¡è¯é¢‘ï¼‰
        chunk_result = f"å¤„ç†äº† {len(chunk)} ä¸ªé¡¹ç›®"
        mapped_results.append(chunk_result)

    return {
        **state,
        "mapped_results": mapped_results
    }

def reduce_process(state: MapReduceState) -> MapReduceState:
    """Reduceé˜¶æ®µï¼šèšåˆæ‰€æœ‰ç»“æœ"""
    total_items = 0
    for result in state["mapped_results"]:
        # æå–æ•°å­—å¹¶ç´¯åŠ 
        items = int(result.split()[1])
        total_items += items

    return {
        **state,
        "reduced_result": f"æ€»å…±å¤„ç†äº† {total_items} ä¸ªé¡¹ç›®"
    }

# æ„å»ºMapReduceå›¾
mapreduce_graph = StateGraph(MapReduceState)
mapreduce_graph.add_node("split", split_data)
mapreduce_graph.add_node("map", map_process)
mapreduce_graph.add_node("reduce", reduce_process)

mapreduce_graph.set_entry_point("split")
mapreduce_graph.add_edge("split", "map")
mapreduce_graph.add_edge("map", "reduce")
mapreduce_graph.add_edge("reduce", END)

mapreduce_app = mapreduce_graph.compile()

# æµ‹è¯•MapReduceæ¨¡å¼
mapreduce_result = mapreduce_app.invoke({
    "input_data": [f"item_{i}" for i in range(100)],  # 100ä¸ªé¡¹ç›®
    "chunk_size": 25,  # æ¯å—25ä¸ª
    "mapped_results": [],
    "reduced_result": ""
})
print(f"MapReduceç»“æœ: {mapreduce_result['reduced_result']}")
```

### 6. ç®¡é“æ¨¡å¼ï¼ˆPipeline Patternï¼‰

**ä½¿ç”¨åœºæ™¯**ï¼šæ•°æ®æµå¤„ç†ï¼Œæ¯ä¸€æ­¥éƒ½å¯¹æ•°æ®è¿›è¡Œè½¬æ¢

```python
class PipelineState(TypedDict):
    raw_text: str
    cleaned_text: str
    tokens: list[str]
    filtered_tokens: list[str]
    analyzed_result: dict

def text_cleaner(state: PipelineState) -> PipelineState:
    """ç®¡é“æ­¥éª¤1ï¼šæ–‡æœ¬æ¸…ç†"""
    import re

    text = state["raw_text"]
    # ç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œè½¬æ¢ä¸ºå°å†™
    cleaned = re.sub(r'[^\w\s]', '', text.lower())

    return {
        **state,
        "cleaned_text": cleaned
    }

def tokenizer(state: PipelineState) -> PipelineState:
    """ç®¡é“æ­¥éª¤2ï¼šåˆ†è¯"""
    tokens = state["cleaned_text"].split()

    return {
        **state,
        "tokens": tokens
    }

def token_filter(state: PipelineState) -> PipelineState:
    """ç®¡é“æ­¥éª¤3ï¼šè¿‡æ»¤åœç”¨è¯"""
    stopwords = {"the", "is", "at", "which", "on", "a", "an", "and", "or", "but"}
    filtered = [token for token in state["tokens"] if token not in stopwords]

    return {
        **state,
        "filtered_tokens": filtered
    }

def text_analyzer(state: PipelineState) -> PipelineState:
    """ç®¡é“æ­¥éª¤4ï¼šæ–‡æœ¬åˆ†æ"""
    tokens = state["filtered_tokens"]

    analysis = {
        "total_tokens": len(tokens),
        "unique_tokens": len(set(tokens)),
        "average_length": sum(len(token) for token in tokens) / len(tokens) if tokens else 0,
        "longest_token": max(tokens, key=len) if tokens else ""
    }

    return {
        **state,
        "analyzed_result": analysis
    }

# æ„å»ºç®¡é“å›¾
pipeline_graph = StateGraph(PipelineState)
pipeline_graph.add_node("clean", text_cleaner)
pipeline_graph.add_node("tokenize", tokenizer)
pipeline_graph.add_node("filter", token_filter)
pipeline_graph.add_node("analyze", text_analyzer)

# ç®¡é“å¼è¿æ¥
pipeline_graph.set_entry_point("clean")
pipeline_graph.add_edge("clean", "tokenize")
pipeline_graph.add_edge("tokenize", "filter")
pipeline_graph.add_edge("filter", "analyze")
pipeline_graph.add_edge("analyze", END)

pipeline_app = pipeline_graph.compile()

# æµ‹è¯•ç®¡é“æ¨¡å¼
pipeline_result = pipeline_app.invoke({
    "raw_text": "Hello! This is a sample text for pipeline processing. It contains various words and punctuation.",
    "cleaned_text": "",
    "tokens": [],
    "filtered_tokens": [],
    "analyzed_result": {}
})
print(f"ç®¡é“åˆ†æç»“æœ: {pipeline_result['analyzed_result']}")
```

## ğŸ”„ æ¨¡å¼ç»„åˆ

å®é™…åº”ç”¨ä¸­ï¼Œæˆ‘ä»¬ç»å¸¸éœ€è¦ç»„åˆå¤šä¸ªæ¨¡å¼ï¼š

```python
class HybridState(TypedDict):
    user_request: str
    request_type: str

    # å¹¶è¡Œå¤„ç†ç»“æœ
    search_results: str
    db_results: str

    # å¾ªç¯å¤„ç†
    processing_attempts: int
    processing_success: bool

    # æœ€ç»ˆç»“æœ
    final_response: str

def classify_request(state: HybridState) -> HybridState:
    """æ¡ä»¶åˆ†æ”¯ï¼šåˆ†ç±»è¯·æ±‚"""
    request = state["user_request"].lower()

    if "æœç´¢" in request:
        req_type = "search"
    elif "æ•°æ®" in request:
        req_type = "data"
    else:
        req_type = "general"

    return {**state, "request_type": req_type}

def parallel_search(state: HybridState) -> HybridState:
    """å¹¶è¡Œæ¨¡å¼ï¼šåŒæ—¶è¿›è¡Œæœç´¢å’Œæ•°æ®åº“æŸ¥è¯¢"""
    # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥å¹¶è¡Œæ‰§è¡Œ
    return {
        **state,
        "search_results": "ç½‘ç»œæœç´¢ç»“æœ",
        "db_results": "æ•°æ®åº“æŸ¥è¯¢ç»“æœ"
    }

def process_with_retry(state: HybridState) -> HybridState:
    """å¾ªç¯æ¨¡å¼ï¼šå¸¦é‡è¯•çš„å¤„ç†"""
    import random

    attempts = state["processing_attempts"] + 1
    success = random.random() > 0.3  # 70% æˆåŠŸç‡

    return {
        **state,
        "processing_attempts": attempts,
        "processing_success": success
    }

def check_retry(state: HybridState) -> str:
    if state["processing_success"]:
        return "finalize"
    elif state["processing_attempts"] >= 3:
        return "finalize"
    else:
        return "retry"

def finalize_response(state: HybridState) -> HybridState:
    """é¡ºåºæ¨¡å¼ï¼šæœ€ç»ˆå¤„ç†"""
    if state["processing_success"]:
        response = f"å¤„ç†æˆåŠŸï¼æœç´¢: {state['search_results']}, æ•°æ®: {state['db_results']}"
    else:
        response = "å¤„ç†å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"

    return {**state, "final_response": response}

# æ„å»ºæ··åˆæ¨¡å¼å›¾
hybrid_graph = StateGraph(HybridState)
hybrid_graph.add_node("classify", classify_request)
hybrid_graph.add_node("parallel_search", parallel_search)
hybrid_graph.add_node("process_retry", process_with_retry)
hybrid_graph.add_node("finalize", finalize_response)

# è¿æ¥èŠ‚ç‚¹
hybrid_graph.set_entry_point("classify")
hybrid_graph.add_edge("classify", "parallel_search")
hybrid_graph.add_edge("parallel_search", "process_retry")

hybrid_graph.add_conditional_edges(
    "process_retry",
    check_retry,
    {
        "retry": "process_retry",
        "finalize": "finalize"
    }
)

hybrid_graph.add_edge("finalize", END)
```

## ğŸª å®è·µç»ƒä¹ 

### ç»ƒä¹  1ï¼šè®¾è®¡ç”µå•†è®¢å•å¤„ç†æµç¨‹

ç»“åˆå¤šç§æ¨¡å¼è®¾è®¡ä¸€ä¸ªç”µå•†è®¢å•å¤„ç†ç³»ç»Ÿï¼š

1. **æ¡ä»¶åˆ†æ”¯**ï¼šæ ¹æ®å•†å“ç±»å‹åˆ†ç±»å¤„ç†
2. **å¹¶è¡Œå¤„ç†**ï¼šåŒæ—¶è¿›è¡Œåº“å­˜æ£€æŸ¥ã€ä»·æ ¼è®¡ç®—ã€ä¼˜æƒ åˆ¸éªŒè¯
3. **å¾ªç¯é‡è¯•**ï¼šæ”¯ä»˜å¤±è´¥æ—¶çš„é‡è¯•æœºåˆ¶
4. **é¡ºåºå¤„ç†**ï¼šæœ€ç»ˆçš„è®¢å•ç¡®è®¤æµç¨‹

### ç»ƒä¹  2ï¼šæ™ºèƒ½æ–‡æ¡£å¤„ç†ç³»ç»Ÿ

è®¾è®¡ä¸€ä¸ªæ–‡æ¡£å¤„ç†ç³»ç»Ÿï¼š

1. **ç®¡é“æ¨¡å¼**ï¼šæ–‡æ¡£æ¸…ç† â†’ æ ¼å¼è½¬æ¢ â†’ å†…å®¹æå– â†’ ç»“æ„åŒ–
2. **MapReduce**ï¼šå¤§æ–‡æ¡£åˆ†å—å¤„ç†
3. **æ¡ä»¶åˆ†æ”¯**ï¼šæ ¹æ®æ–‡æ¡£ç±»å‹é€‰æ‹©ä¸åŒçš„å¤„ç†ç­–ç•¥

## ğŸ’¡ æ¨¡å¼é€‰æ‹©æŒ‡å—

| åœºæ™¯ | æ¨èæ¨¡å¼ | ç‰¹ç‚¹ |
|------|----------|------|
| çº¿æ€§ä¸šåŠ¡æµç¨‹ | é¡ºåºæ¨¡å¼ | ç®€å•ã€å¯é¢„æµ‹ |
| ç‹¬ç«‹ä»»åŠ¡å¹¶å‘ | å¹¶è¡Œæ¨¡å¼ | æé«˜æ•ˆç‡ |
| åŸºäºæ¡ä»¶å†³ç­– | æ¡ä»¶åˆ†æ”¯ | çµæ´»è·¯ç”± |
| éœ€è¦é‡è¯•æœºåˆ¶ | å¾ªç¯æ¨¡å¼ | å®¹é”™æ€§å¼º |
| å¤§æ•°æ®å¤„ç† | MapReduce | å¯æ‰©å±• |
| æ•°æ®è½¬æ¢é“¾ | ç®¡é“æ¨¡å¼ | èŒè´£æ¸…æ™° |

## ğŸš€ ä¸‹ä¸€æ­¥

æŒæ¡å·¥ä½œæµæ¨¡å¼åï¼Œæ¥ä¸‹æ¥å­¦ä¹ ï¼š
- `04-å¯è§†åŒ–ç†è§£.md` - å­¦ä¼šå¯è§†åŒ–å’Œè°ƒè¯•å›¾ç»“æ„
- `../03-LangGraphåŸºç¡€/` - å¼€å§‹ LangGraph å®æˆ˜å¼€å‘

---

*ç°åœ¨ä½ å·²ç»æŒæ¡äº†ä¸»è¦çš„å·¥ä½œæµæ¨¡å¼ï¼Œå¯ä»¥è®¾è®¡å‡ºå¤æ‚è€Œä¼˜é›…çš„ AI Agent ç³»ç»Ÿï¼* ğŸ‰