# 工作流模式

> 🎯 **学习目标**：掌握常见的工作流设计模式，学会在 LangGraph 中构建复杂的业务流程

## 🌟 什么是工作流模式？

工作流模式是解决特定业务场景的**可复用的图结构设计**。就像设计模式在软件开发中的作用一样，工作流模式为我们提供了经过验证的解决方案。

### 为什么需要工作流模式？

```python
# ❌ 没有模式的混乱代码
def messy_workflow(state):
    # 所有逻辑都堆在一起
    if state["step1_done"]:
        if state["condition_a"]:
            # 做一堆事情...
            if state["another_condition"]:
                # 又做一堆事情...
                pass
    # 很难理解和维护

# ✅ 使用模式的清晰结构
def sequential_step1(state): ...
def sequential_step2(state): ...
def conditional_router(state): ...
# 清晰、可维护、可复用
```

## 📋 六大核心工作流模式

### 1. 顺序模式（Sequential Pattern）

**使用场景**：步骤明确的线性流程

```python
from typing import TypedDict
from langgraph.graph import StateGraph, END

class SequentialState(TypedDict):
    input_data: str
    processed_data: str
    validated_data: str
    final_result: str
    current_step: str

def data_input(state: SequentialState) -> SequentialState:
    """步骤1：数据输入"""
    return {
        **state,
        "processed_data": f"输入: {state['input_data']}",
        "current_step": "数据输入完成"
    }

def data_processing(state: SequentialState) -> SequentialState:
    """步骤2：数据处理"""
    processed = state["processed_data"].upper()
    return {
        **state,
        "processed_data": processed,
        "current_step": "数据处理完成"
    }

def data_validation(state: SequentialState) -> SequentialState:
    """步骤3：数据验证"""
    is_valid = len(state["processed_data"]) > 0
    return {
        **state,
        "validated_data": state["processed_data"] if is_valid else "无效数据",
        "current_step": "数据验证完成"
    }

def generate_result(state: SequentialState) -> SequentialState:
    """步骤4：生成结果"""
    return {
        **state,
        "final_result": f"最终结果: {state['validated_data']}",
        "current_step": "流程完成"
    }

# 构建顺序图
sequential_graph = StateGraph(SequentialState)
sequential_graph.add_node("input", data_input)
sequential_graph.add_node("process", data_processing)
sequential_graph.add_node("validate", data_validation)
sequential_graph.add_node("result", generate_result)

# 顺序连接
sequential_graph.set_entry_point("input")
sequential_graph.add_edge("input", "process")
sequential_graph.add_edge("process", "validate")
sequential_graph.add_edge("validate", "result")
sequential_graph.add_edge("result", END)

sequential_app = sequential_graph.compile()

# 测试
result = sequential_app.invoke({
    "input_data": "hello world",
    "processed_data": "",
    "validated_data": "",
    "final_result": "",
    "current_step": ""
})
print(f"顺序模式结果: {result['final_result']}")
```

### 2. 并行模式（Parallel Pattern）

**使用场景**：需要同时处理多个独立任务

```python
class ParallelState(TypedDict):
    user_query: str
    web_results: str
    database_results: str
    api_results: str
    combined_results: str

def web_search(state: ParallelState) -> ParallelState:
    """并行任务1：网络搜索"""
    import time
    time.sleep(1)  # 模拟网络延迟
    return {
        **state,
        "web_results": f"网络搜索'{state['user_query']}'的结果"
    }

def database_query(state: ParallelState) -> ParallelState:
    """并行任务2：数据库查询"""
    import time
    time.sleep(1.5)  # 模拟数据库查询
    return {
        **state,
        "database_results": f"数据库查询'{state['user_query']}'的结果"
    }

def api_call(state: ParallelState) -> ParallelState:
    """并行任务3：API调用"""
    import time
    time.sleep(0.8)  # 模拟API调用
    return {
        **state,
        "api_results": f"API调用'{state['user_query']}'的结果"
    }

def combine_results(state: ParallelState) -> ParallelState:
    """汇总所有结果"""
    combined = f"""
综合结果：
- 网络: {state['web_results']}
- 数据库: {state['database_results']}
- API: {state['api_results']}
    """.strip()

    return {
        **state,
        "combined_results": combined
    }

# 构建并行图
parallel_graph = StateGraph(ParallelState)
parallel_graph.add_node("web_search", web_search)
parallel_graph.add_node("db_query", database_query)
parallel_graph.add_node("api_call", api_call)
parallel_graph.add_node("combine", combine_results)

# 从入口点到三个并行任务
parallel_graph.set_entry_point("web_search")
parallel_graph.add_edge("web_search", "combine")
parallel_graph.add_edge("db_query", "combine")
parallel_graph.add_edge("api_call", "combine")
parallel_graph.add_edge("combine", END)

# 注意：实际并行需要使用特殊的并行节点
# 这里简化展示概念
```

### 3. 条件分支模式（Conditional Branching Pattern）

**使用场景**：基于条件选择不同的处理路径

```python
class ConditionalState(TypedDict):
    user_message: str
    message_type: str
    urgency_level: str
    processing_method: str
    response: str

def message_classifier(state: ConditionalState) -> ConditionalState:
    """消息分类器"""
    message = state["user_message"].lower()

    if any(word in message for word in ["紧急", "急", "马上"]):
        urgency = "high"
    elif any(word in message for word in ["一般", "普通"]):
        urgency = "medium"
    else:
        urgency = "low"

    if any(word in message for word in ["技术", "bug", "错误"]):
        msg_type = "technical"
    elif any(word in message for word in ["销售", "购买", "价格"]):
        msg_type = "sales"
    else:
        msg_type = "general"

    return {
        **state,
        "message_type": msg_type,
        "urgency_level": urgency
    }

def route_by_urgency(state: ConditionalState) -> str:
    """按紧急程度路由"""
    if state["urgency_level"] == "high":
        return "urgent_handler"
    elif state["message_type"] == "technical":
        return "technical_handler"
    elif state["message_type"] == "sales":
        return "sales_handler"
    else:
        return "general_handler"

def urgent_handler(state: ConditionalState) -> ConditionalState:
    """紧急处理"""
    return {
        **state,
        "processing_method": "紧急处理通道",
        "response": "已升级为紧急任务，将立即处理"
    }

def technical_handler(state: ConditionalState) -> ConditionalState:
    """技术问题处理"""
    return {
        **state,
        "processing_method": "技术支持团队",
        "response": "技术团队将在4小时内回复"
    }

def sales_handler(state: ConditionalState) -> ConditionalState:
    """销售问题处理"""
    return {
        **state,
        "processing_method": "销售团队",
        "response": "销售顾问将在2小时内联系您"
    }

def general_handler(state: ConditionalState) -> ConditionalState:
    """一般问题处理"""
    return {
        **state,
        "processing_method": "客服团队",
        "response": "感谢您的咨询，我们将在24小时内回复"
    }

# 构建条件分支图
conditional_graph = StateGraph(ConditionalState)
conditional_graph.add_node("classifier", message_classifier)
conditional_graph.add_node("urgent_handler", urgent_handler)
conditional_graph.add_node("technical_handler", technical_handler)
conditional_graph.add_node("sales_handler", sales_handler)
conditional_graph.add_node("general_handler", general_handler)

conditional_graph.set_entry_point("classifier")
conditional_graph.add_conditional_edges(
    "classifier",
    route_by_urgency,
    {
        "urgent_handler": "urgent_handler",
        "technical_handler": "technical_handler",
        "sales_handler": "sales_handler",
        "general_handler": "general_handler"
    }
)

# 所有处理器都指向结束
conditional_graph.add_edge("urgent_handler", END)
conditional_graph.add_edge("technical_handler", END)
conditional_graph.add_edge("sales_handler", END)
conditional_graph.add_edge("general_handler", END)

conditional_app = conditional_graph.compile()
```

### 4. 循环模式（Loop Pattern）

**使用场景**：需要重试、迭代或循环处理

```python
class LoopState(TypedDict):
    task_description: str
    attempts: int
    max_attempts: int
    success: bool
    errors: list[str]
    result: str

def attempt_task(state: LoopState) -> LoopState:
    """尝试执行任务"""
    import random

    attempts = state["attempts"] + 1

    # 模拟任务执行（70% 成功率，随尝试次数增加）
    success_rate = 0.3 + (attempts * 0.2)
    success = random.random() < success_rate

    if success:
        return {
            **state,
            "attempts": attempts,
            "success": True,
            "result": f"任务在第 {attempts} 次尝试时成功完成"
        }
    else:
        error_msg = f"第 {attempts} 次尝试失败"
        return {
            **state,
            "attempts": attempts,
            "success": False,
            "errors": state["errors"] + [error_msg]
        }

def check_loop_condition(state: LoopState) -> str:
    """检查是否继续循环"""
    if state["success"]:
        return "success"
    elif state["attempts"] >= state["max_attempts"]:
        return "max_attempts_reached"
    else:
        return "retry"

def handle_success(state: LoopState) -> LoopState:
    """处理成功情况"""
    return {
        **state,
        "result": f"✅ {state['result']}"
    }

def handle_failure(state: LoopState) -> LoopState:
    """处理最终失败"""
    return {
        **state,
        "result": f"❌ 任务失败，已达到最大重试次数 ({state['max_attempts']})"
    }

# 构建循环图
loop_graph = StateGraph(LoopState)
loop_graph.add_node("attempt", attempt_task)
loop_graph.add_node("success", handle_success)
loop_graph.add_node("failure", handle_failure)

loop_graph.set_entry_point("attempt")
loop_graph.add_conditional_edges(
    "attempt",
    check_loop_condition,
    {
        "success": "success",
        "max_attempts_reached": "failure",
        "retry": "attempt"  # 循环回到自己
    }
)

loop_graph.add_edge("success", END)
loop_graph.add_edge("failure", END)

loop_app = loop_graph.compile()

# 测试循环模式
loop_result = loop_app.invoke({
    "task_description": "网络API调用",
    "attempts": 0,
    "max_attempts": 5,
    "success": False,
    "errors": [],
    "result": ""
})
print(f"循环模式结果: {loop_result['result']}")
```

### 5. MapReduce 模式

**使用场景**：大数据处理，分散计算后聚合

```python
class MapReduceState(TypedDict):
    input_data: list[str]
    chunk_size: int
    mapped_results: list[str]
    reduced_result: str

def split_data(state: MapReduceState) -> MapReduceState:
    """分割数据（Map阶段的准备）"""
    data = state["input_data"]
    chunk_size = state["chunk_size"]

    # 将数据分成块
    chunks = [data[i:i + chunk_size] for i in range(0, len(data), chunk_size)]

    return {
        **state,
        "input_data": chunks  # 现在存储的是分块后的数据
    }

def map_process(state: MapReduceState) -> MapReduceState:
    """Map阶段：并行处理每个数据块"""
    mapped_results = []

    for chunk in state["input_data"]:
        # 对每个块进行处理（例如：统计词频）
        chunk_result = f"处理了 {len(chunk)} 个项目"
        mapped_results.append(chunk_result)

    return {
        **state,
        "mapped_results": mapped_results
    }

def reduce_process(state: MapReduceState) -> MapReduceState:
    """Reduce阶段：聚合所有结果"""
    total_items = 0
    for result in state["mapped_results"]:
        # 提取数字并累加
        items = int(result.split()[1])
        total_items += items

    return {
        **state,
        "reduced_result": f"总共处理了 {total_items} 个项目"
    }

# 构建MapReduce图
mapreduce_graph = StateGraph(MapReduceState)
mapreduce_graph.add_node("split", split_data)
mapreduce_graph.add_node("map", map_process)
mapreduce_graph.add_node("reduce", reduce_process)

mapreduce_graph.set_entry_point("split")
mapreduce_graph.add_edge("split", "map")
mapreduce_graph.add_edge("map", "reduce")
mapreduce_graph.add_edge("reduce", END)

mapreduce_app = mapreduce_graph.compile()

# 测试MapReduce模式
mapreduce_result = mapreduce_app.invoke({
    "input_data": [f"item_{i}" for i in range(100)],  # 100个项目
    "chunk_size": 25,  # 每块25个
    "mapped_results": [],
    "reduced_result": ""
})
print(f"MapReduce结果: {mapreduce_result['reduced_result']}")
```

### 6. 管道模式（Pipeline Pattern）

**使用场景**：数据流处理，每一步都对数据进行转换

```python
class PipelineState(TypedDict):
    raw_text: str
    cleaned_text: str
    tokens: list[str]
    filtered_tokens: list[str]
    analyzed_result: dict

def text_cleaner(state: PipelineState) -> PipelineState:
    """管道步骤1：文本清理"""
    import re

    text = state["raw_text"]
    # 移除特殊字符，转换为小写
    cleaned = re.sub(r'[^\w\s]', '', text.lower())

    return {
        **state,
        "cleaned_text": cleaned
    }

def tokenizer(state: PipelineState) -> PipelineState:
    """管道步骤2：分词"""
    tokens = state["cleaned_text"].split()

    return {
        **state,
        "tokens": tokens
    }

def token_filter(state: PipelineState) -> PipelineState:
    """管道步骤3：过滤停用词"""
    stopwords = {"the", "is", "at", "which", "on", "a", "an", "and", "or", "but"}
    filtered = [token for token in state["tokens"] if token not in stopwords]

    return {
        **state,
        "filtered_tokens": filtered
    }

def text_analyzer(state: PipelineState) -> PipelineState:
    """管道步骤4：文本分析"""
    tokens = state["filtered_tokens"]

    analysis = {
        "total_tokens": len(tokens),
        "unique_tokens": len(set(tokens)),
        "average_length": sum(len(token) for token in tokens) / len(tokens) if tokens else 0,
        "longest_token": max(tokens, key=len) if tokens else ""
    }

    return {
        **state,
        "analyzed_result": analysis
    }

# 构建管道图
pipeline_graph = StateGraph(PipelineState)
pipeline_graph.add_node("clean", text_cleaner)
pipeline_graph.add_node("tokenize", tokenizer)
pipeline_graph.add_node("filter", token_filter)
pipeline_graph.add_node("analyze", text_analyzer)

# 管道式连接
pipeline_graph.set_entry_point("clean")
pipeline_graph.add_edge("clean", "tokenize")
pipeline_graph.add_edge("tokenize", "filter")
pipeline_graph.add_edge("filter", "analyze")
pipeline_graph.add_edge("analyze", END)

pipeline_app = pipeline_graph.compile()

# 测试管道模式
pipeline_result = pipeline_app.invoke({
    "raw_text": "Hello! This is a sample text for pipeline processing. It contains various words and punctuation.",
    "cleaned_text": "",
    "tokens": [],
    "filtered_tokens": [],
    "analyzed_result": {}
})
print(f"管道分析结果: {pipeline_result['analyzed_result']}")
```

## 🔄 模式组合

实际应用中，我们经常需要组合多个模式：

```python
class HybridState(TypedDict):
    user_request: str
    request_type: str

    # 并行处理结果
    search_results: str
    db_results: str

    # 循环处理
    processing_attempts: int
    processing_success: bool

    # 最终结果
    final_response: str

def classify_request(state: HybridState) -> HybridState:
    """条件分支：分类请求"""
    request = state["user_request"].lower()

    if "搜索" in request:
        req_type = "search"
    elif "数据" in request:
        req_type = "data"
    else:
        req_type = "general"

    return {**state, "request_type": req_type}

def parallel_search(state: HybridState) -> HybridState:
    """并行模式：同时进行搜索和数据库查询"""
    # 这里简化处理，实际应该并行执行
    return {
        **state,
        "search_results": "网络搜索结果",
        "db_results": "数据库查询结果"
    }

def process_with_retry(state: HybridState) -> HybridState:
    """循环模式：带重试的处理"""
    import random

    attempts = state["processing_attempts"] + 1
    success = random.random() > 0.3  # 70% 成功率

    return {
        **state,
        "processing_attempts": attempts,
        "processing_success": success
    }

def check_retry(state: HybridState) -> str:
    if state["processing_success"]:
        return "finalize"
    elif state["processing_attempts"] >= 3:
        return "finalize"
    else:
        return "retry"

def finalize_response(state: HybridState) -> HybridState:
    """顺序模式：最终处理"""
    if state["processing_success"]:
        response = f"处理成功！搜索: {state['search_results']}, 数据: {state['db_results']}"
    else:
        response = "处理失败，请稍后重试"

    return {**state, "final_response": response}

# 构建混合模式图
hybrid_graph = StateGraph(HybridState)
hybrid_graph.add_node("classify", classify_request)
hybrid_graph.add_node("parallel_search", parallel_search)
hybrid_graph.add_node("process_retry", process_with_retry)
hybrid_graph.add_node("finalize", finalize_response)

# 连接节点
hybrid_graph.set_entry_point("classify")
hybrid_graph.add_edge("classify", "parallel_search")
hybrid_graph.add_edge("parallel_search", "process_retry")

hybrid_graph.add_conditional_edges(
    "process_retry",
    check_retry,
    {
        "retry": "process_retry",
        "finalize": "finalize"
    }
)

hybrid_graph.add_edge("finalize", END)
```

## 🎪 实践练习

### 练习 1：设计电商订单处理流程

结合多种模式设计一个电商订单处理系统：

1. **条件分支**：根据商品类型分类处理
2. **并行处理**：同时进行库存检查、价格计算、优惠券验证
3. **循环重试**：支付失败时的重试机制
4. **顺序处理**：最终的订单确认流程

### 练习 2：智能文档处理系统

设计一个文档处理系统：

1. **管道模式**：文档清理 → 格式转换 → 内容提取 → 结构化
2. **MapReduce**：大文档分块处理
3. **条件分支**：根据文档类型选择不同的处理策略

## 💡 模式选择指南

| 场景 | 推荐模式 | 特点 |
|------|----------|------|
| 线性业务流程 | 顺序模式 | 简单、可预测 |
| 独立任务并发 | 并行模式 | 提高效率 |
| 基于条件决策 | 条件分支 | 灵活路由 |
| 需要重试机制 | 循环模式 | 容错性强 |
| 大数据处理 | MapReduce | 可扩展 |
| 数据转换链 | 管道模式 | 职责清晰 |

## 🚀 下一步

掌握工作流模式后，接下来学习：
- `04-可视化理解.md` - 学会可视化和调试图结构
- `../03-LangGraph基础/` - 开始 LangGraph 实战开发

---

*现在你已经掌握了主要的工作流模式，可以设计出复杂而优雅的 AI Agent 系统！* 🎉