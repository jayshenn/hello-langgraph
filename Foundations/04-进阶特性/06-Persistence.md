# 06-Persistence

## ğŸ¯ å­¦ä¹ ç›®æ ‡

é€šè¿‡æœ¬ç« å­¦ä¹ ï¼Œä½ å°†æŒæ¡ï¼š
- LangGraph ä¸­æŒä¹…åŒ–æœºåˆ¶çš„æ ¸å¿ƒæ¦‚å¿µ
- æ£€æŸ¥ç‚¹ï¼ˆCheckpointï¼‰ç³»ç»Ÿçš„ä½¿ç”¨
- çŠ¶æ€æ¢å¤å’Œæ—¶é—´æ—…è¡ŒåŠŸèƒ½
- ç”Ÿäº§ç¯å¢ƒä¸­çš„æŒä¹…åŒ–æœ€ä½³å®è·µ

## ğŸ“š Persistence åŸºç¡€æ¦‚å¿µ

### ä»€ä¹ˆæ˜¯æŒä¹…åŒ–ï¼Ÿ

æŒä¹…åŒ–ï¼ˆPersistenceï¼‰æ˜¯æŒ‡å°†ç¨‹åºè¿è¡Œæ—¶çš„çŠ¶æ€ä¿å­˜åˆ°æŒä¹…å­˜å‚¨ä»‹è´¨ä¸­ï¼Œä»¥ä¾¿åœ¨ç¨‹åºé‡å¯æˆ–å‡ºç°æ•…éšœåèƒ½å¤Ÿæ¢å¤ä¹‹å‰çš„çŠ¶æ€ã€‚åœ¨ LangGraph ä¸­ï¼ŒæŒä¹…åŒ–ä¸»è¦é€šè¿‡æ£€æŸ¥ç‚¹ç³»ç»Ÿå®ç°ã€‚

### æ£€æŸ¥ç‚¹ç³»ç»Ÿ

æ£€æŸ¥ç‚¹ï¼ˆCheckpointï¼‰æ˜¯ LangGraph ä¸­çš„æ ¸å¿ƒæŒä¹…åŒ–æœºåˆ¶ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           æ£€æŸ¥ç‚¹ç³»ç»Ÿæ¶æ„            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  åº”ç”¨å±‚                             â”‚
â”‚  â”œâ”€ Graph Execution                 â”‚
â”‚  â””â”€ State Management                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  æ£€æŸ¥ç‚¹å±‚                           â”‚
â”‚  â”œâ”€ Checkpoint Creation             â”‚
â”‚  â”œâ”€ State Serialization             â”‚
â”‚  â””â”€ Recovery Management             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  å­˜å‚¨å±‚                             â”‚
â”‚  â”œâ”€ Memory (å¼€å‘)                   â”‚
â”‚  â”œâ”€ SQLite (å°è§„æ¨¡)                 â”‚
â”‚  â”œâ”€ PostgreSQL (ç”Ÿäº§)               â”‚
â”‚  â””â”€ Redis (ç¼“å­˜)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ’¾ åŸºç¡€æŒä¹…åŒ–å®ç°

### 1. å†…å­˜æ£€æŸ¥ç‚¹

```python
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
from typing import TypedDict
import time

class PersistentState(TypedDict):
    """æŒä¹…åŒ–çŠ¶æ€å®šä¹‰"""
    user_id: str
    conversation_id: str
    messages: list
    task_progress: dict
    last_checkpoint: str

def create_basic_persistent_graph():
    """åˆ›å»ºåŸºç¡€æŒä¹…åŒ–å›¾"""

    def save_checkpoint_node(state: PersistentState) -> PersistentState:
        """ä¿å­˜æ£€æŸ¥ç‚¹èŠ‚ç‚¹"""
        checkpoint_info = {
            "timestamp": time.time(),
            "node": "checkpoint_saver",
            "state_size": len(str(state)),
            "user_id": state.get("user_id")
        }

        state["last_checkpoint"] = f"checkpoint_{int(time.time())}"
        state.setdefault("task_progress", {})["last_saved"] = time.time()

        print(f"æ£€æŸ¥ç‚¹å·²ä¿å­˜: {state['last_checkpoint']}")
        return state

    def process_message_node(state: PersistentState) -> PersistentState:
        """å¤„ç†æ¶ˆæ¯èŠ‚ç‚¹"""
        messages = state.get("messages", [])

        if messages:
            latest_message = messages[-1]
            response = f"å¤„ç†æ¶ˆæ¯: {latest_message}"

            # æ·»åŠ å“åº”åˆ°æ¶ˆæ¯å†å²
            messages.append({
                "role": "assistant",
                "content": response,
                "timestamp": time.time()
            })

            state["messages"] = messages

        return state

    def task_processor_node(state: PersistentState) -> PersistentState:
        """ä»»åŠ¡å¤„ç†èŠ‚ç‚¹"""
        task_progress = state.get("task_progress", {})

        # æ¨¡æ‹Ÿé•¿æ—¶é—´è¿è¡Œçš„ä»»åŠ¡
        current_step = task_progress.get("current_step", 0)
        total_steps = task_progress.get("total_steps", 5)

        if current_step < total_steps:
            current_step += 1
            task_progress.update({
                "current_step": current_step,
                "total_steps": total_steps,
                "progress_percentage": (current_step / total_steps) * 100,
                "last_updated": time.time()
            })

            state["task_progress"] = task_progress

        return state

    # æ„å»ºæŒä¹…åŒ–å›¾
    graph = StateGraph(PersistentState)
    graph.add_node("save_checkpoint", save_checkpoint_node)
    graph.add_node("process_message", process_message_node)
    graph.add_node("task_processor", task_processor_node)

    graph.set_entry_point("save_checkpoint")
    graph.add_edge("save_checkpoint", "process_message")
    graph.add_edge("process_message", "task_processor")
    graph.add_edge("task_processor", END)

    # é…ç½®å†…å­˜æ£€æŸ¥ç‚¹
    memory_saver = MemorySaver()
    app = graph.compile(checkpointer=memory_saver)

    return app

# ä½¿ç”¨ç¤ºä¾‹
def use_persistent_graph():
    """ä½¿ç”¨æŒä¹…åŒ–å›¾çš„ç¤ºä¾‹"""
    app = create_basic_persistent_graph()

    # é…ç½®çº¿ç¨‹IDï¼ˆç”¨äºåŒºåˆ†ä¸åŒçš„æ‰§è¡Œæµï¼‰
    config = {"configurable": {"thread_id": "session_123"}}

    # ç¬¬ä¸€æ¬¡æ‰§è¡Œ
    initial_state = {
        "user_id": "user_001",
        "conversation_id": "conv_456",
        "messages": [{"role": "user", "content": "å¼€å§‹ä»»åŠ¡"}],
        "task_progress": {"current_step": 0, "total_steps": 5},
        "last_checkpoint": ""
    }

    result1 = app.invoke(initial_state, config=config)
    print("ç¬¬ä¸€æ¬¡æ‰§è¡Œç»“æœ:", result1)

    # ç¬¬äºŒæ¬¡æ‰§è¡Œï¼ˆä¼šè‡ªåŠ¨æ¢å¤ä¹‹å‰çš„çŠ¶æ€ï¼‰
    additional_state = {
        "messages": [{"role": "user", "content": "ç»§ç»­ä»»åŠ¡"}]
    }

    result2 = app.invoke(additional_state, config=config)
    print("ç¬¬äºŒæ¬¡æ‰§è¡Œç»“æœ:", result2)
```

### 2. SQLite æŒä¹…åŒ–

```python
from langgraph.checkpoint.sqlite import SqliteSaver
import sqlite3

def create_sqlite_persistent_graph():
    """åˆ›å»ºSQLiteæŒä¹…åŒ–å›¾"""

    class DatabaseState(TypedDict):
        user_data: dict
        session_info: dict
        processing_results: list
        error_log: list

    def database_operation_node(state: DatabaseState) -> DatabaseState:
        """æ•°æ®åº“æ“ä½œèŠ‚ç‚¹"""
        user_data = state.get("user_data", {})

        # æ¨¡æ‹Ÿæ•°æ®åº“æ“ä½œ
        operation_result = {
            "operation": "data_processing",
            "timestamp": time.time(),
            "user_id": user_data.get("user_id"),
            "status": "completed",
            "data_size": len(str(user_data))
        }

        processing_results = state.get("processing_results", [])
        processing_results.append(operation_result)
        state["processing_results"] = processing_results

        return state

    def error_handling_node(state: DatabaseState) -> DatabaseState:
        """é”™è¯¯å¤„ç†èŠ‚ç‚¹"""
        error_log = state.get("error_log", [])

        # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
        processing_results = state.get("processing_results", [])
        for result in processing_results:
            if result.get("status") == "error":
                error_entry = {
                    "error_id": f"err_{int(time.time())}",
                    "operation": result.get("operation"),
                    "timestamp": time.time(),
                    "error_message": result.get("error_message", "Unknown error")
                }
                error_log.append(error_entry)

        state["error_log"] = error_log
        return state

    def session_manager_node(state: DatabaseState) -> DatabaseState:
        """ä¼šè¯ç®¡ç†èŠ‚ç‚¹"""
        session_info = state.get("session_info", {})

        session_info.update({
            "last_activity": time.time(),
            "operation_count": len(state.get("processing_results", [])),
            "error_count": len(state.get("error_log", [])),
            "session_duration": time.time() - session_info.get("start_time", time.time())
        })

        state["session_info"] = session_info
        return state

    # æ„å»ºå›¾
    graph = StateGraph(DatabaseState)
    graph.add_node("database_operation", database_operation_node)
    graph.add_node("error_handling", error_handling_node)
    graph.add_node("session_manager", session_manager_node)

    graph.set_entry_point("database_operation")
    graph.add_edge("database_operation", "error_handling")
    graph.add_edge("error_handling", "session_manager")
    graph.add_edge("session_manager", END)

    # é…ç½®SQLiteæ£€æŸ¥ç‚¹
    db_path = "checkpoints.db"
    conn = sqlite3.connect(db_path, check_same_thread=False)
    sqlite_saver = SqliteSaver(conn)

    app = graph.compile(checkpointer=sqlite_saver)

    return app, conn

def advanced_sqlite_usage():
    """é«˜çº§SQLiteç”¨æ³•"""
    app, conn = create_sqlite_persistent_graph()

    try:
        # ä½¿ç”¨ç‰¹å®šçš„çº¿ç¨‹ID
        config = {"configurable": {"thread_id": "sqlite_session_001"}}

        # æ‰§è¡Œä»»åŠ¡
        state = {
            "user_data": {"user_id": "user123", "name": "å¼ ä¸‰"},
            "session_info": {"start_time": time.time()},
            "processing_results": [],
            "error_log": []
        }

        result = app.invoke(state, config=config)
        print("SQLiteæŒä¹…åŒ–ç»“æœ:", result)

        # æ£€æŸ¥æ£€æŸ¥ç‚¹å†å²
        checkpoints = list(app.get_state_history(config))
        print(f"æ£€æŸ¥ç‚¹å†å²æ•°é‡: {len(checkpoints)}")

        for i, checkpoint in enumerate(checkpoints[:3]):  # æ˜¾ç¤ºæœ€è¿‘3ä¸ª
            print(f"æ£€æŸ¥ç‚¹ {i}: {checkpoint.values}")

    finally:
        conn.close()
```

## ğŸ”„ çŠ¶æ€æ¢å¤å’Œæ—¶é—´æ—…è¡Œ

### 1. çŠ¶æ€æ¢å¤æœºåˆ¶

```python
class StateRecoverySystem:
    """çŠ¶æ€æ¢å¤ç³»ç»Ÿ"""

    def __init__(self, app, checkpointer):
        self.app = app
        self.checkpointer = checkpointer

    def recover_from_failure(self, thread_id: str, failure_point: str = None):
        """ä»æ•…éšœä¸­æ¢å¤"""
        config = {"configurable": {"thread_id": thread_id}}

        try:
            # è·å–æœ€æ–°çš„æ£€æŸ¥ç‚¹
            current_state = self.app.get_state(config)

            if current_state is None:
                print(f"æœªæ‰¾åˆ°çº¿ç¨‹ {thread_id} çš„çŠ¶æ€")
                return None

            print(f"æ¢å¤çŠ¶æ€: {current_state.values}")

            # æ£€æŸ¥æ˜¯å¦æœ‰æœªå®Œæˆçš„ä»»åŠ¡
            task_progress = current_state.values.get("task_progress", {})
            if task_progress.get("current_step", 0) < task_progress.get("total_steps", 0):
                print("å‘ç°æœªå®Œæˆçš„ä»»åŠ¡ï¼Œç»§ç»­æ‰§è¡Œ...")

                # ä»å½“å‰çŠ¶æ€ç»§ç»­æ‰§è¡Œ
                recovery_state = {
                    "recovery_mode": True,
                    "recovery_timestamp": time.time(),
                    "original_failure_point": failure_point
                }

                result = self.app.invoke(recovery_state, config=config)
                return result

            return current_state.values

        except Exception as e:
            print(f"æ¢å¤å¤±è´¥: {e}")
            return None

    def list_recovery_points(self, thread_id: str):
        """åˆ—å‡ºæ‰€æœ‰æ¢å¤ç‚¹"""
        config = {"configurable": {"thread_id": thread_id}}

        try:
            history = list(self.app.get_state_history(config))
            recovery_points = []

            for i, checkpoint in enumerate(history):
                recovery_point = {
                    "index": i,
                    "timestamp": checkpoint.created_at,
                    "node": checkpoint.metadata.get("step", "unknown"),
                    "state_preview": str(checkpoint.values)[:100] + "..."
                }
                recovery_points.append(recovery_point)

            return recovery_points

        except Exception as e:
            print(f"è·å–æ¢å¤ç‚¹å¤±è´¥: {e}")
            return []

    def recover_to_specific_point(self, thread_id: str, checkpoint_index: int):
        """æ¢å¤åˆ°ç‰¹å®šæ£€æŸ¥ç‚¹"""
        config = {"configurable": {"thread_id": thread_id}}

        try:
            history = list(self.app.get_state_history(config))

            if checkpoint_index >= len(history):
                print(f"æ£€æŸ¥ç‚¹ç´¢å¼• {checkpoint_index} è¶…å‡ºèŒƒå›´")
                return None

            target_checkpoint = history[checkpoint_index]
            print(f"æ¢å¤åˆ°æ£€æŸ¥ç‚¹: {target_checkpoint.created_at}")

            # ä»æŒ‡å®šæ£€æŸ¥ç‚¹æ¢å¤çŠ¶æ€
            recovered_state = target_checkpoint.values

            # æ·»åŠ æ¢å¤å…ƒæ•°æ®
            recovered_state["recovery_info"] = {
                "recovered_from": checkpoint_index,
                "recovery_timestamp": time.time(),
                "original_timestamp": target_checkpoint.created_at
            }

            return recovered_state

        except Exception as e:
            print(f"æ¢å¤åˆ°ç‰¹å®šç‚¹å¤±è´¥: {e}")
            return None

def create_recoverable_graph():
    """åˆ›å»ºå¯æ¢å¤çš„å›¾"""

    class RecoverableState(TypedDict):
        task_id: str
        steps_completed: list
        current_step: int
        total_steps: int
        recovery_info: dict
        error_info: dict

    def step_processor(state: RecoverableState) -> RecoverableState:
        """æ­¥éª¤å¤„ç†å™¨"""
        current_step = state.get("current_step", 0)
        total_steps = state.get("total_steps", 5)
        steps_completed = state.get("steps_completed", [])

        if current_step < total_steps:
            # æ¨¡æ‹Ÿå¯èƒ½å¤±è´¥çš„å¤„ç†
            import random
            if random.random() < 0.2:  # 20% å¤±è´¥æ¦‚ç‡
                error_info = {
                    "error_type": "processing_error",
                    "error_message": f"æ­¥éª¤ {current_step + 1} å¤„ç†å¤±è´¥",
                    "timestamp": time.time()
                }
                state["error_info"] = error_info
                return state

            # æ­£å¸¸å¤„ç†
            step_result = f"æ­¥éª¤_{current_step + 1}_å®Œæˆ"
            steps_completed.append(step_result)

            state["steps_completed"] = steps_completed
            state["current_step"] = current_step + 1

        return state

    def error_handler(state: RecoverableState) -> RecoverableState:
        """é”™è¯¯å¤„ç†å™¨"""
        error_info = state.get("error_info")

        if error_info:
            print(f"å¤„ç†é”™è¯¯: {error_info['error_message']}")

            # æ¸…é™¤é”™è¯¯ä¿¡æ¯ï¼Œå‡†å¤‡é‡è¯•
            state["error_info"] = {}

            # è®°å½•é”™è¯¯ä½†ä¸ä¸­æ–­æµç¨‹
            recovery_info = state.get("recovery_info", {})
            recovery_info.setdefault("error_history", []).append(error_info)
            state["recovery_info"] = recovery_info

        return state

    def completion_checker(state: RecoverableState) -> str:
        """å®Œæˆæ£€æŸ¥å™¨"""
        current_step = state.get("current_step", 0)
        total_steps = state.get("total_steps", 5)

        if state.get("error_info"):
            return "error_handler"
        elif current_step < total_steps:
            return "continue"
        else:
            return "complete"

    # æ„å»ºå¯æ¢å¤å›¾
    graph = StateGraph(RecoverableState)
    graph.add_node("step_processor", step_processor)
    graph.add_node("error_handler", error_handler)
    graph.add_node("complete", lambda state: state)

    graph.set_entry_point("step_processor")

    graph.add_conditional_edges(
        "step_processor",
        completion_checker,
        {
            "continue": "step_processor",
            "error_handler": "error_handler",
            "complete": "complete"
        }
    )

    graph.add_edge("error_handler", "step_processor")
    graph.add_edge("complete", END)

    # ä½¿ç”¨SQLiteæŒä¹…åŒ–
    conn = sqlite3.connect("recovery.db", check_same_thread=False)
    sqlite_saver = SqliteSaver(conn)
    app = graph.compile(checkpointer=sqlite_saver)

    return app, StateRecoverySystem(app, sqlite_saver), conn
```

### 2. æ—¶é—´æ—…è¡ŒåŠŸèƒ½

```python
class TimeTravelSystem:
    """æ—¶é—´æ—…è¡Œç³»ç»Ÿ"""

    def __init__(self, app):
        self.app = app

    def create_timeline(self, thread_id: str):
        """åˆ›å»ºæ—¶é—´çº¿"""
        config = {"configurable": {"thread_id": thread_id}}
        history = list(self.app.get_state_history(config))

        timeline = []
        for i, checkpoint in enumerate(history):
            timeline_entry = {
                "checkpoint_id": i,
                "timestamp": checkpoint.created_at,
                "step": checkpoint.metadata.get("step", "unknown"),
                "state_summary": self._summarize_state(checkpoint.values),
                "changes": self._detect_changes(
                    history[i+1].values if i+1 < len(history) else {},
                    checkpoint.values
                )
            }
            timeline.append(timeline_entry)

        return timeline

    def _summarize_state(self, state: dict) -> dict:
        """æ€»ç»“çŠ¶æ€"""
        summary = {}

        for key, value in state.items():
            if isinstance(value, list):
                summary[key] = f"list({len(value)} items)"
            elif isinstance(value, dict):
                summary[key] = f"dict({len(value)} keys)"
            elif isinstance(value, str) and len(value) > 50:
                summary[key] = value[:50] + "..."
            else:
                summary[key] = value

        return summary

    def _detect_changes(self, previous_state: dict, current_state: dict) -> list:
        """æ£€æµ‹çŠ¶æ€å˜åŒ–"""
        changes = []

        # æ£€æŸ¥æ–°å¢å­—æ®µ
        for key in current_state:
            if key not in previous_state:
                changes.append(f"Added: {key}")
            elif previous_state[key] != current_state[key]:
                changes.append(f"Changed: {key}")

        # æ£€æŸ¥åˆ é™¤å­—æ®µ
        for key in previous_state:
            if key not in current_state:
                changes.append(f"Removed: {key}")

        return changes

    def travel_to_checkpoint(self, thread_id: str, checkpoint_id: int):
        """æ—¶é—´æ—…è¡Œåˆ°æŒ‡å®šæ£€æŸ¥ç‚¹"""
        config = {"configurable": {"thread_id": thread_id}}
        history = list(self.app.get_state_history(config))

        if checkpoint_id >= len(history):
            raise ValueError(f"æ£€æŸ¥ç‚¹ {checkpoint_id} ä¸å­˜åœ¨")

        target_checkpoint = history[checkpoint_id]

        # åˆ›å»ºæ–°çš„åˆ†æ”¯ï¼ˆé¿å…ä¿®æ”¹åŸæœ‰å†å²ï¼‰
        branch_config = {
            "configurable": {
                "thread_id": f"{thread_id}_branch_{checkpoint_id}",
                "checkpoint_ns": f"branch_from_{checkpoint_id}"
            }
        }

        # ä»ç›®æ ‡æ£€æŸ¥ç‚¹çš„çŠ¶æ€å¼€å§‹æ–°çš„æ‰§è¡Œ
        branch_state = dict(target_checkpoint.values)
        branch_state["time_travel_info"] = {
            "source_thread": thread_id,
            "source_checkpoint": checkpoint_id,
            "branch_created": time.time()
        }

        return branch_state, branch_config

    def compare_timelines(self, thread_id1: str, thread_id2: str):
        """æ¯”è¾ƒä¸¤ä¸ªæ—¶é—´çº¿"""
        timeline1 = self.create_timeline(thread_id1)
        timeline2 = self.create_timeline(thread_id2)

        comparison = {
            "timeline1_length": len(timeline1),
            "timeline2_length": len(timeline2),
            "common_steps": [],
            "divergence_point": None,
            "unique_to_timeline1": [],
            "unique_to_timeline2": []
        }

        # æ‰¾åˆ°åˆ†æ­§ç‚¹
        min_length = min(len(timeline1), len(timeline2))
        for i in range(min_length):
            if timeline1[i]["step"] == timeline2[i]["step"]:
                comparison["common_steps"].append(timeline1[i]["step"])
            else:
                comparison["divergence_point"] = i
                break

        # è®°å½•ç‹¬æœ‰æ­¥éª¤
        if comparison["divergence_point"] is not None:
            comparison["unique_to_timeline1"] = [
                entry["step"] for entry in timeline1[comparison["divergence_point"]:]
            ]
            comparison["unique_to_timeline2"] = [
                entry["step"] for entry in timeline2[comparison["divergence_point"]:]
            ]

        return comparison

def advanced_time_travel_example():
    """é«˜çº§æ—¶é—´æ—…è¡Œç¤ºä¾‹"""
    app, recovery_system, conn = create_recoverable_graph()
    time_travel = TimeTravelSystem(app)

    try:
        # æ‰§è¡Œä¸€ä¸ªä»»åŠ¡
        config = {"configurable": {"thread_id": "time_travel_demo"}}
        initial_state = {
            "task_id": "demo_task",
            "steps_completed": [],
            "current_step": 0,
            "total_steps": 3,
            "recovery_info": {},
            "error_info": {}
        }

        result = app.invoke(initial_state, config=config)
        print("åŸå§‹æ‰§è¡Œå®Œæˆ")

        # åˆ›å»ºæ—¶é—´çº¿
        timeline = time_travel.create_timeline("time_travel_demo")
        print(f"æ—¶é—´çº¿åŒ…å« {len(timeline)} ä¸ªæ£€æŸ¥ç‚¹")

        # æ—¶é—´æ—…è¡Œåˆ°ä¸­é—´æŸä¸ªç‚¹
        if len(timeline) > 1:
            branch_state, branch_config = time_travel.travel_to_checkpoint(
                "time_travel_demo", 1
            )

            print("ä»æ£€æŸ¥ç‚¹1å¼€å§‹æ–°åˆ†æ”¯æ‰§è¡Œ")

            # ä¿®æ”¹çŠ¶æ€å¹¶ç»§ç»­æ‰§è¡Œ
            branch_state["total_steps"] = 5  # å¢åŠ æ­¥éª¤æ•°
            branch_result = app.invoke(branch_state, config=branch_config)

            # æ¯”è¾ƒä¸¤ä¸ªæ—¶é—´çº¿
            comparison = time_travel.compare_timelines(
                "time_travel_demo",
                "time_travel_demo_branch_1"
            )
            print("æ—¶é—´çº¿æ¯”è¾ƒç»“æœ:", comparison)

    finally:
        conn.close()
```

## ğŸš€ ç”Ÿäº§ç¯å¢ƒæŒä¹…åŒ–

### 1. PostgreSQL æŒä¹…åŒ–

```python
# æ³¨æ„ï¼šè¿™éœ€è¦é¢å¤–çš„ä¾èµ–åŒ…
# pip install langgraph[postgres]

from langgraph.checkpoint.postgres import PostgresSaver
import psycopg2

def create_production_persistent_graph():
    """åˆ›å»ºç”Ÿäº§ç¯å¢ƒæŒä¹…åŒ–å›¾"""

    # æ•°æ®åº“è¿æ¥é…ç½®
    DB_CONFIG = {
        "host": "localhost",
        "database": "langgraph_checkpoints",
        "user": "postgres",
        "password": "password",
        "port": 5432
    }

    class ProductionState(TypedDict):
        user_session: dict
        business_data: dict
        audit_trail: list
        performance_metrics: dict

    def business_logic_node(state: ProductionState) -> ProductionState:
        """ä¸šåŠ¡é€»è¾‘èŠ‚ç‚¹"""
        business_data = state.get("business_data", {})

        # æ¨¡æ‹Ÿå¤æ‚ä¸šåŠ¡å¤„ç†
        processing_start = time.time()

        # ä¸šåŠ¡é€»è¾‘
        result = {
            "processed_at": time.time(),
            "processing_time": time.time() - processing_start,
            "status": "completed",
            "result_data": f"å¤„ç†ç»“æœ_{int(time.time())}"
        }

        business_data["last_result"] = result
        state["business_data"] = business_data

        # æ›´æ–°æ€§èƒ½æŒ‡æ ‡
        metrics = state.get("performance_metrics", {})
        metrics.setdefault("processing_times", []).append(result["processing_time"])
        metrics["total_operations"] = metrics.get("total_operations", 0) + 1
        state["performance_metrics"] = metrics

        return state

    def audit_logger_node(state: ProductionState) -> ProductionState:
        """å®¡è®¡æ—¥å¿—èŠ‚ç‚¹"""
        audit_trail = state.get("audit_trail", [])

        audit_entry = {
            "timestamp": time.time(),
            "user_id": state.get("user_session", {}).get("user_id"),
            "action": "business_processing",
            "details": state.get("business_data", {}).get("last_result", {}),
            "session_id": state.get("user_session", {}).get("session_id")
        }

        audit_trail.append(audit_entry)
        state["audit_trail"] = audit_trail

        return state

    try:
        # åˆ›å»ºæ•°æ®åº“è¿æ¥
        conn = psycopg2.connect(**DB_CONFIG)

        # åˆ›å»ºPostgreSQLæ£€æŸ¥ç‚¹ä¿å­˜å™¨
        postgres_saver = PostgresSaver(conn)

        # ç¡®ä¿æ•°æ®åº“è¡¨å·²åˆ›å»º
        postgres_saver.setup()

        # æ„å»ºå›¾
        graph = StateGraph(ProductionState)
        graph.add_node("business_logic", business_logic_node)
        graph.add_node("audit_logger", audit_logger_node)

        graph.set_entry_point("business_logic")
        graph.add_edge("business_logic", "audit_logger")
        graph.add_edge("audit_logger", END)

        app = graph.compile(checkpointer=postgres_saver)

        return app, conn

    except Exception as e:
        print(f"PostgreSQLè¿æ¥å¤±è´¥: {e}")
        # å›é€€åˆ°SQLite
        conn = sqlite3.connect("fallback.db", check_same_thread=False)
        sqlite_saver = SqliteSaver(conn)
        app = graph.compile(checkpointer=sqlite_saver)
        return app, conn

def production_usage_example():
    """ç”Ÿäº§ç¯å¢ƒä½¿ç”¨ç¤ºä¾‹"""
    app, conn = create_production_persistent_graph()

    try:
        # æ¨¡æ‹Ÿå¤šç”¨æˆ·å¹¶å‘
        users = ["user_001", "user_002", "user_003"]

        for user_id in users:
            config = {"configurable": {"thread_id": f"session_{user_id}"}}

            state = {
                "user_session": {
                    "user_id": user_id,
                    "session_id": f"session_{user_id}_{int(time.time())}",
                    "start_time": time.time()
                },
                "business_data": {"user_input": f"æ¥è‡ª{user_id}çš„æ•°æ®"},
                "audit_trail": [],
                "performance_metrics": {}
            }

            result = app.invoke(state, config=config)
            print(f"ç”¨æˆ· {user_id} å¤„ç†å®Œæˆ")

        # æ£€æŸ¥æŒä¹…åŒ–çŠ¶æ€
        for user_id in users:
            config = {"configurable": {"thread_id": f"session_{user_id}"}}
            current_state = app.get_state(config)
            if current_state:
                metrics = current_state.values.get("performance_metrics", {})
                print(f"ç”¨æˆ· {user_id} æ€§èƒ½æŒ‡æ ‡: {metrics}")

    finally:
        conn.close()
```

### 2. æŒä¹…åŒ–æ€§èƒ½ä¼˜åŒ–

```python
class PersistenceOptimizer:
    """æŒä¹…åŒ–æ€§èƒ½ä¼˜åŒ–å™¨"""

    def __init__(self, app, checkpointer):
        self.app = app
        self.checkpointer = checkpointer
        self.performance_stats = {}

    def optimize_checkpoint_frequency(self, state_size_threshold: int = 1024):
        """ä¼˜åŒ–æ£€æŸ¥ç‚¹é¢‘ç‡"""
        def should_checkpoint(state: dict) -> bool:
            state_size = len(str(state))
            return state_size > state_size_threshold

        return should_checkpoint

    def implement_state_compression(self, state: dict) -> dict:
        """å®ç°çŠ¶æ€å‹ç¼©"""
        compressed_state = {}

        for key, value in state.items():
            if isinstance(value, list) and len(value) > 100:
                # å‹ç¼©å¤§åˆ—è¡¨ï¼Œåªä¿ç•™æœ€æ–°çš„50ä¸ªå…ƒç´ 
                compressed_state[key] = value[-50:]
                compressed_state[f"{key}_compressed"] = True
                compressed_state[f"{key}_original_size"] = len(value)
            elif isinstance(value, str) and len(value) > 5000:
                # å‹ç¼©é•¿å­—ç¬¦ä¸²
                compressed_state[key] = value[:5000] + "...[truncated]"
                compressed_state[f"{key}_compressed"] = True
                compressed_state[f"{key}_original_size"] = len(value)
            else:
                compressed_state[key] = value

        return compressed_state

    def cleanup_old_checkpoints(self, thread_id: str, keep_count: int = 10):
        """æ¸…ç†æ—§æ£€æŸ¥ç‚¹"""
        config = {"configurable": {"thread_id": thread_id}}

        try:
            history = list(self.app.get_state_history(config))

            if len(history) > keep_count:
                # è¿™é‡Œéœ€è¦æ ¹æ®å…·ä½“çš„æ£€æŸ¥ç‚¹å®ç°æ¥åˆ é™¤æ—§è®°å½•
                # ç¤ºä¾‹ä»£ç ï¼ˆå®é™…å®ç°å–å†³äºæ£€æŸ¥ç‚¹ç±»å‹ï¼‰
                print(f"å°†åˆ é™¤ {len(history) - keep_count} ä¸ªæ—§æ£€æŸ¥ç‚¹")

        except Exception as e:
            print(f"æ¸…ç†æ£€æŸ¥ç‚¹å¤±è´¥: {e}")

    def monitor_performance(self, operation_name: str, duration: float):
        """ç›‘æ§æ€§èƒ½æŒ‡æ ‡"""
        if operation_name not in self.performance_stats:
            self.performance_stats[operation_name] = {
                "count": 0,
                "total_time": 0,
                "max_time": 0,
                "min_time": float('inf')
            }

        stats = self.performance_stats[operation_name]
        stats["count"] += 1
        stats["total_time"] += duration
        stats["max_time"] = max(stats["max_time"], duration)
        stats["min_time"] = min(stats["min_time"], duration)

    def get_performance_report(self) -> dict:
        """è·å–æ€§èƒ½æŠ¥å‘Š"""
        report = {}

        for operation, stats in self.performance_stats.items():
            if stats["count"] > 0:
                report[operation] = {
                    "total_operations": stats["count"],
                    "average_time": stats["total_time"] / stats["count"],
                    "max_time": stats["max_time"],
                    "min_time": stats["min_time"],
                    "total_time": stats["total_time"]
                }

        return report
```

## ğŸ® å®è·µç»ƒä¹ 

### ç»ƒä¹  1ï¼šæ„å»ºæ•…éšœæ¢å¤ç³»ç»Ÿ

åˆ›å»ºä¸€ä¸ªå…·æœ‰å®Œæ•´æ•…éšœæ¢å¤èƒ½åŠ›çš„ç³»ç»Ÿï¼š

```python
def fault_tolerant_system():
    """
    ç»ƒä¹ ï¼šæ„å»ºæ•…éšœæ¢å¤ç³»ç»Ÿ

    è¦æ±‚ï¼š
    1. å®ç°è‡ªåŠ¨æ£€æŸ¥ç‚¹ä¿å­˜
    2. æ”¯æŒä»ä»»æ„æ£€æŸ¥ç‚¹æ¢å¤
    3. å¤„ç†å„ç§æ•…éšœåœºæ™¯
    4. æä¾›çŠ¶æ€ä¸€è‡´æ€§æ£€æŸ¥
    """
    # TODO: å®ç°ä½ çš„æ•…éšœæ¢å¤ç³»ç»Ÿ
    pass
```

### ç»ƒä¹  2ï¼šæ—¶é—´æ—…è¡Œè°ƒè¯•å™¨

å®ç°ä¸€ä¸ªåŸºäºæ—¶é—´æ—…è¡Œçš„è°ƒè¯•ç³»ç»Ÿï¼š

```python
def time_travel_debugger():
    """
    ç»ƒä¹ ï¼šæ—¶é—´æ—…è¡Œè°ƒè¯•å™¨

    è¦æ±‚ï¼š
    1. è®°å½•æ¯ä¸ªèŠ‚ç‚¹çš„æ‰§è¡ŒçŠ¶æ€
    2. æ”¯æŒå›é€€åˆ°ä»»æ„æ—¶é—´ç‚¹
    3. å…è®¸ä¿®æ”¹çŠ¶æ€å¹¶é‡æ–°æ‰§è¡Œ
    4. æä¾›çŠ¶æ€æ¯”è¾ƒå’Œåˆ†æåŠŸèƒ½
    """
    # TODO: å®ç°ä½ çš„æ—¶é—´æ—…è¡Œè°ƒè¯•å™¨
    pass
```

## ğŸš€ æœ€ä½³å®è·µ

### 1. æŒä¹…åŒ–ç­–ç•¥

- **é€‰æ‹©åˆé€‚çš„å­˜å‚¨**ï¼šå¼€å‘ç”¨å†…å­˜ï¼Œç”Ÿäº§ç”¨æ•°æ®åº“
- **æ§åˆ¶æ£€æŸ¥ç‚¹é¢‘ç‡**ï¼šå¹³è¡¡æ€§èƒ½å’Œæ¢å¤ç²’åº¦
- **å®ç°çŠ¶æ€å‹ç¼©**ï¼šå‡å°‘å­˜å‚¨ç©ºé—´å’ŒI/Oå¼€é”€
- **å®šæœŸæ¸…ç†**ï¼šé¿å…æ£€æŸ¥ç‚¹æ•°æ®æ— é™å¢é•¿

### 2. æ•…éšœæ¢å¤è®¾è®¡

- **å¹‚ç­‰æ“ä½œ**ï¼šç¡®ä¿é‡å¤æ‰§è¡Œçš„å®‰å…¨æ€§
- **çŠ¶æ€éªŒè¯**ï¼šæ¢å¤åéªŒè¯çŠ¶æ€å®Œæ•´æ€§
- **æ¸è¿›æ¢å¤**ï¼šæ”¯æŒéƒ¨åˆ†çŠ¶æ€æ¢å¤
- **å›é€€æœºåˆ¶**ï¼šæä¾›å®‰å…¨çš„å›é€€é€‰é¡¹

### 3. æ€§èƒ½ä¼˜åŒ–

- **å¼‚æ­¥æŒä¹…åŒ–**ï¼šé¿å…é˜»å¡ä¸»æ‰§è¡Œæµç¨‹
- **æ‰¹é‡æ“ä½œ**ï¼šå‡å°‘æ•°æ®åº“è®¿é—®æ¬¡æ•°
- **ç¼“å­˜ç­–ç•¥**ï¼šç¼“å­˜é¢‘ç¹è®¿é—®çš„çŠ¶æ€
- **ç›‘æ§æŒ‡æ ‡**ï¼šè·Ÿè¸ªæŒä¹…åŒ–æ€§èƒ½

## ğŸ“š æ¨èé˜…è¯»

- [LangGraph å®˜æ–¹æ–‡æ¡£ - Persistence](https://langchain-ai.github.io/langgraph/concepts/persistence/)
- [Checkpointing](https://langchain-ai.github.io/langgraph/how-tos/persistence/)
- [Time Travel](https://langchain-ai.github.io/langgraph/concepts/time-travel/)

---

**æ­å–œï¼** ä½ å·²ç»å®Œæˆäº† LangGraph è¿›é˜¶ç‰¹æ€§çš„å­¦ä¹ ã€‚è¿™äº›ç‰¹æ€§ä¸ºæ„å»ºç”Ÿäº§çº§çš„ AI åº”ç”¨æä¾›äº†å¼ºå¤§çš„åŸºç¡€ã€‚ä¸‹ä¸€æ­¥å¯ä»¥å¼€å§‹å®é™…é¡¹ç›®å¼€å‘ï¼Œå°†è¿™äº›ç‰¹æ€§ç»„åˆä½¿ç”¨ã€‚