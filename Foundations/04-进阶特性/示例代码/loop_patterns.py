#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¾ªç¯ç»“æ„ç¤ºä¾‹ä»£ç 
æ¼”ç¤º LangGraph ä¸­å„ç§å¾ªç¯æ¨¡å¼çš„å®ç°
"""

from langgraph.graph import StateGraph, END
from typing import TypedDict, List
import time
import random


class LoopState(TypedDict):
    """å¾ªç¯çŠ¶æ€å®šä¹‰"""
    task_name: str
    current_iteration: int
    max_iterations: int
    results: List[dict]
    error_count: int
    success_rate: float
    should_continue: bool
    performance_metrics: dict


def create_intelligent_retry_system():
    """åˆ›å»ºæ™ºèƒ½é‡è¯•ç³»ç»Ÿ"""

    def task_executor(state: LoopState) -> LoopState:
        """ä»»åŠ¡æ‰§è¡ŒèŠ‚ç‚¹"""
        iteration = state.get("current_iteration", 0)
        task_name = state.get("task_name", "æœªçŸ¥ä»»åŠ¡")

        print(f"ğŸ”„ æ‰§è¡Œç¬¬ {iteration + 1} æ¬¡è¿­ä»£: {task_name}")

        # æ¨¡æ‹Ÿä»»åŠ¡æ‰§è¡Œ
        start_time = time.time()

        # éšæœºæ¨¡æ‹ŸæˆåŠŸ/å¤±è´¥
        success_probability = 0.7 + (iteration * 0.1)  # é‡è¯•æ¬¡æ•°è¶Šå¤šï¼ŒæˆåŠŸç‡è¶Šé«˜
        is_success = random.random() < success_probability

        execution_time = time.time() - start_time

        # è®°å½•ç»“æœ
        result = {
            "iteration": iteration + 1,
            "success": is_success,
            "execution_time": execution_time,
            "timestamp": time.time(),
            "error_message": None if is_success else f"æ¨¡æ‹Ÿé”™è¯¯_{iteration + 1}"
        }

        results = state.get("results", [])
        results.append(result)
        state["results"] = results

        # æ›´æ–°è®¡æ•°å™¨
        state["current_iteration"] = iteration + 1

        if not is_success:
            error_count = state.get("error_count", 0)
            state["error_count"] = error_count + 1

        # æ›´æ–°æ€§èƒ½æŒ‡æ ‡
        metrics = state.get("performance_metrics", {})
        total_executions = len(results)
        successful_executions = sum(1 for r in results if r["success"])

        metrics.update({
            "total_executions": total_executions,
            "successful_executions": successful_executions,
            "success_rate": successful_executions / total_executions,
            "average_execution_time": sum(r["execution_time"] for r in results) / total_executions,
            "last_execution_time": execution_time
        })

        state["performance_metrics"] = metrics
        state["success_rate"] = metrics["success_rate"]

        return state

    def intelligent_continue_checker(state: LoopState) -> str:
        """æ™ºèƒ½ç»§ç»­æ£€æŸ¥å™¨"""
        current_iteration = state.get("current_iteration", 0)
        max_iterations = state.get("max_iterations", 5)
        results = state.get("results", [])
        error_count = state.get("error_count", 0)

        # æ£€æŸ¥åŸºæœ¬æ¡ä»¶
        if current_iteration >= max_iterations:
            print(f"â¹ï¸  è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•° {max_iterations}")
            return "max_iterations"

        # æ£€æŸ¥æœ€è¿‘çš„ç»“æœ
        if results and results[-1]["success"]:
            print("âœ… ä»»åŠ¡æ‰§è¡ŒæˆåŠŸ")
            return "success"

        # æ£€æŸ¥è¿ç»­å¤±è´¥æ¬¡æ•°
        consecutive_failures = 0
        for result in reversed(results):
            if not result["success"]:
                consecutive_failures += 1
            else:
                break

        if consecutive_failures >= 3:
            print("âŒ è¿ç»­å¤±è´¥æ¬¡æ•°è¿‡å¤šï¼Œåœæ­¢é‡è¯•")
            return "too_many_failures"

        # æ£€æŸ¥æ€»ä½“æˆåŠŸç‡
        if len(results) >= 3:  # è‡³å°‘æ‰§è¡Œ3æ¬¡åæ‰æ£€æŸ¥æˆåŠŸç‡
            success_rate = state.get("success_rate", 0.0)
            if success_rate < 0.2:  # æˆåŠŸç‡ä½äº20%
                print(f"ğŸ“‰ æˆåŠŸç‡è¿‡ä½ ({success_rate:.1%})ï¼Œåœæ­¢é‡è¯•")
                return "low_success_rate"

        print("ğŸ”„ ç»§ç»­é‡è¯•")
        return "continue"

    def delay_calculator(state: LoopState) -> LoopState:
        """å»¶è¿Ÿè®¡ç®—å™¨ï¼ˆæŒ‡æ•°é€€é¿ï¼‰"""
        current_iteration = state.get("current_iteration", 0)

        # æŒ‡æ•°é€€é¿ï¼š1s, 2s, 4s, 8s...
        delay = min(2 ** (current_iteration - 1), 30)  # æœ€å¤§å»¶è¿Ÿ30ç§’

        print(f"â° ç­‰å¾… {delay} ç§’åé‡è¯•...")
        time.sleep(delay)  # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œåº”è¯¥ä½¿ç”¨å¼‚æ­¥ç­‰å¾…

        return state

    def success_handler(state: LoopState) -> LoopState:
        """æˆåŠŸå¤„ç†å™¨"""
        task_name = state.get("task_name", "ä»»åŠ¡")
        current_iteration = state.get("current_iteration", 0)
        performance_metrics = state.get("performance_metrics", {})

        print(f"ğŸ‰ {task_name} æ‰§è¡ŒæˆåŠŸï¼")
        print(f"ğŸ“Š æ€»å…±å°è¯•äº† {current_iteration} æ¬¡")
        print(f"ğŸ“ˆ æˆåŠŸç‡: {performance_metrics.get('success_rate', 0):.1%}")

        state["should_continue"] = False
        return state

    def failure_handler(state: LoopState) -> LoopState:
        """å¤±è´¥å¤„ç†å™¨"""
        task_name = state.get("task_name", "ä»»åŠ¡")
        current_iteration = state.get("current_iteration", 0)
        error_count = state.get("error_count", 0)

        print(f"ğŸ’¥ {task_name} æœ€ç»ˆæ‰§è¡Œå¤±è´¥")
        print(f"ğŸ“Š æ€»å…±å°è¯•äº† {current_iteration} æ¬¡ï¼Œå¤±è´¥ {error_count} æ¬¡")

        state["should_continue"] = False
        return state

    # æ„å»ºæ™ºèƒ½é‡è¯•å›¾
    graph = StateGraph(LoopState)

    # æ·»åŠ èŠ‚ç‚¹
    graph.add_node("task_executor", task_executor)
    graph.add_node("delay_calculator", delay_calculator)
    graph.add_node("success_handler", success_handler)
    graph.add_node("failure_handler", failure_handler)

    # è®¾ç½®å…¥å£ç‚¹
    graph.set_entry_point("task_executor")

    # æ·»åŠ æ¡ä»¶è¾¹
    graph.add_conditional_edges(
        "task_executor",
        intelligent_continue_checker,
        {
            "continue": "delay_calculator",
            "success": "success_handler",
            "max_iterations": "failure_handler",
            "too_many_failures": "failure_handler",
            "low_success_rate": "failure_handler"
        }
    )

    # å»¶è¿Ÿåå›åˆ°æ‰§è¡Œ
    graph.add_edge("delay_calculator", "task_executor")

    # å¤„ç†å™¨ç»“æŸ
    graph.add_edge("success_handler", END)
    graph.add_edge("failure_handler", END)

    return graph.compile()


def create_data_processing_pipeline():
    """åˆ›å»ºæ•°æ®å¤„ç†ç®¡é“å¾ªç¯"""

    class PipelineState(TypedDict):
        raw_data: List[dict]
        processed_data: List[dict]
        quality_score: float
        processing_round: int
        max_rounds: int
        quality_threshold: float

    def data_validator(state: PipelineState) -> PipelineState:
        """æ•°æ®éªŒè¯å™¨"""
        raw_data = state.get("raw_data", [])
        processing_round = state.get("processing_round", 0)

        print(f"ğŸ” ç¬¬ {processing_round + 1} è½®: éªŒè¯ {len(raw_data)} æ¡æ•°æ®")

        # æ¨¡æ‹Ÿæ•°æ®éªŒè¯
        valid_data = []
        for item in raw_data:
            # ç®€å•éªŒè¯é€»è¾‘
            if len(str(item)) > 5 and "error" not in str(item).lower():
                valid_data.append(item)

        validation_rate = len(valid_data) / len(raw_data) if raw_data else 0
        print(f"   âœ… æ•°æ®éªŒè¯ç‡: {validation_rate:.1%}")

        state["raw_data"] = valid_data
        return state

    def data_processor(state: PipelineState) -> PipelineState:
        """æ•°æ®å¤„ç†å™¨"""
        raw_data = state.get("raw_data", [])

        print(f"âš™ï¸  å¤„ç† {len(raw_data)} æ¡æ•°æ®")

        # æ¨¡æ‹Ÿæ•°æ®å¤„ç†
        processed_data = []
        for item in raw_data:
            processed_item = {
                "original": item,
                "processed": f"processed_{item}",
                "timestamp": time.time(),
                "processing_round": state.get("processing_round", 0) + 1
            }
            processed_data.append(processed_item)

        state["processed_data"] = processed_data
        return state

    def quality_assessor(state: PipelineState) -> PipelineState:
        """è´¨é‡è¯„ä¼°å™¨"""
        processed_data = state.get("processed_data", [])
        processing_round = state.get("processing_round", 0)

        # æ¨¡æ‹Ÿè´¨é‡è¯„ä¼°
        quality_scores = []
        for item in processed_data:
            # éšæœºè´¨é‡åˆ†æ•°ï¼Œéšç€å¤„ç†è½®æ¬¡å¢åŠ è€Œæé«˜
            base_score = random.uniform(0.6, 0.9)
            round_bonus = processing_round * 0.05
            item_score = min(base_score + round_bonus, 1.0)
            quality_scores.append(item_score)

        overall_quality = sum(quality_scores) / len(quality_scores) if quality_scores else 0

        print(f"ğŸ“Š æ•°æ®è´¨é‡è¯„åˆ†: {overall_quality:.2f}")

        state["quality_score"] = overall_quality
        state["processing_round"] = processing_round + 1

        return state

    def quality_checker(state: PipelineState) -> str:
        """è´¨é‡æ£€æŸ¥å™¨"""
        quality_score = state.get("quality_score", 0.0)
        quality_threshold = state.get("quality_threshold", 0.85)
        processing_round = state.get("processing_round", 0)
        max_rounds = state.get("max_rounds", 3)

        if quality_score >= quality_threshold:
            print(f"ğŸ¯ è´¨é‡è¾¾æ ‡ ({quality_score:.2f} >= {quality_threshold})")
            return "quality_met"
        elif processing_round >= max_rounds:
            print(f"â° è¾¾åˆ°æœ€å¤§å¤„ç†è½®æ¬¡ ({processing_round}/{max_rounds})")
            return "max_rounds"
        else:
            print(f"ğŸ”„ è´¨é‡æœªè¾¾æ ‡ï¼Œç»§ç»­å¤„ç† ({quality_score:.2f} < {quality_threshold})")
            return "continue_processing"

    def pipeline_complete(state: PipelineState) -> PipelineState:
        """ç®¡é“å®Œæˆå¤„ç†å™¨"""
        processed_data = state.get("processed_data", [])
        quality_score = state.get("quality_score", 0.0)
        processing_round = state.get("processing_round", 0)

        print(f"âœ… æ•°æ®å¤„ç†ç®¡é“å®Œæˆï¼")
        print(f"ğŸ“¦ å¤„ç†äº† {len(processed_data)} æ¡æ•°æ®")
        print(f"ğŸ“Š æœ€ç»ˆè´¨é‡åˆ†æ•°: {quality_score:.2f}")
        print(f"ğŸ”„ æ€»å…±å¤„ç†è½®æ¬¡: {processing_round}")

        return state

    # æ„å»ºæ•°æ®å¤„ç†ç®¡é“
    graph = StateGraph(PipelineState)

    # æ·»åŠ èŠ‚ç‚¹
    graph.add_node("validator", data_validator)
    graph.add_node("processor", data_processor)
    graph.add_node("assessor", quality_assessor)
    graph.add_node("complete", pipeline_complete)

    # è®¾ç½®å…¥å£ç‚¹
    graph.set_entry_point("validator")

    # çº¿æ€§å¤„ç†æµç¨‹
    graph.add_edge("validator", "processor")
    graph.add_edge("processor", "assessor")

    # è´¨é‡æ£€æŸ¥çš„æ¡ä»¶è¾¹
    graph.add_conditional_edges(
        "assessor",
        quality_checker,
        {
            "continue_processing": "validator",  # å›åˆ°éªŒè¯å™¨å½¢æˆå¾ªç¯
            "quality_met": "complete",
            "max_rounds": "complete"
        }
    )

    graph.add_edge("complete", END)

    return graph.compile()


def demo_loop_patterns():
    """æ¼”ç¤ºå¾ªç¯æ¨¡å¼"""
    print("ğŸš€ å¾ªç¯æ¨¡å¼æ¼”ç¤ºå¼€å§‹")
    print("=" * 60)

    # æ¼”ç¤º1: æ™ºèƒ½é‡è¯•ç³»ç»Ÿ
    print("\nğŸ¯ æ¼”ç¤º1: æ™ºèƒ½é‡è¯•ç³»ç»Ÿ")
    print("-" * 40)

    retry_app = create_intelligent_retry_system()

    retry_state = {
        "task_name": "ç½‘ç»œAPIè°ƒç”¨",
        "current_iteration": 0,
        "max_iterations": 5,
        "results": [],
        "error_count": 0,
        "success_rate": 0.0,
        "should_continue": True,
        "performance_metrics": {}
    }

    result1 = retry_app.invoke(retry_state)

    # æ¼”ç¤º2: æ•°æ®å¤„ç†ç®¡é“
    print("\n\nğŸ¯ æ¼”ç¤º2: æ•°æ®å¤„ç†ç®¡é“å¾ªç¯")
    print("-" * 40)

    pipeline_app = create_data_processing_pipeline()

    # æ¨¡æ‹ŸåŸå§‹æ•°æ®
    raw_data = [
        {"id": 1, "value": "data_001"},
        {"id": 2, "value": "data_002"},
        {"id": 3, "value": "error_data"},  # è¿™ä¸ªä¼šè¢«è¿‡æ»¤
        {"id": 4, "value": "data_004"},
        {"id": 5, "value": "data_005"}
    ]

    pipeline_state = {
        "raw_data": raw_data,
        "processed_data": [],
        "quality_score": 0.0,
        "processing_round": 0,
        "max_rounds": 3,
        "quality_threshold": 0.85
    }

    result2 = pipeline_app.invoke(pipeline_state)

    print("\nğŸ‰ æ‰€æœ‰å¾ªç¯æ¨¡å¼æ¼”ç¤ºå®Œæˆï¼")


if __name__ == "__main__":
    demo_loop_patterns()