"""
é«˜çº§èŠå¤©æœºå™¨äºº - LangGraph å®Œæ•´é¡¹ç›®

è¿™æ˜¯ä¸€ä¸ªåŠŸèƒ½å®Œæ•´çš„èŠå¤©æœºå™¨äººå®ç°ï¼Œå±•ç¤ºäº† LangGraph çš„é«˜çº§ç‰¹æ€§ï¼š
- çœŸå® LLM é›†æˆ
- è®°å¿†ç®¡ç†ï¼ˆçŸ­æœŸå’Œé•¿æœŸï¼‰
- å·¥å…·è°ƒç”¨
- Human-in-the-Loop
- æµå¼è¾“å‡º
- æƒ…æ„Ÿåˆ†æ

é€‚åˆè¿›é˜¶å­¦ä¹ è€…ç†è§£ LangGraph çš„ç”Ÿäº§çº§åº”ç”¨ã€‚
"""

import os
import json
import asyncio
import datetime
from typing import TypedDict, List, Dict, Any, Optional, Annotated, AsyncIterator
from dataclasses import dataclass, asdict
from collections import deque

from dotenv import load_dotenv
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from langgraph.checkpoint.memory import MemorySaver
from langgraph.prebuilt import ToolNode

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# =============================================================================
# é…ç½®å’Œå¸¸é‡
# =============================================================================

@dataclass
class ChatbotConfig:
    """èŠå¤©æœºå™¨äººé…ç½®"""
    # LLM é…ç½®
    llm_provider: str = "openai"  # openai, anthropic
    model_name: str = "gpt-3.5-turbo"
    temperature: float = 0.7
    max_tokens: int = 1000

    # è®°å¿†é…ç½®
    short_term_memory_size: int = 10
    long_term_memory_threshold: float = 0.8

    # å·¥å…·é…ç½®
    enable_tools: bool = True
    enable_web_search: bool = False

    # Human-in-the-Loop
    enable_human_review: bool = True
    sensitive_keywords: List[str] = None

    # å…¶ä»–é…ç½®
    enable_emotion_analysis: bool = True
    max_conversation_turns: int = 50

    def __post_init__(self):
        if self.sensitive_keywords is None:
            self.sensitive_keywords = ["æŠ•è¯‰", "é€€æ¬¾", "æ³•å¾‹", "èµ·è¯‰"]


# =============================================================================
# æ•°æ®æ¨¡å‹
# =============================================================================

@dataclass
class UserProfile:
    """ç”¨æˆ·æ¡£æ¡ˆ"""
    user_id: str
    name: Optional[str] = None
    preferences: Dict[str, Any] = None
    conversation_count: int = 0
    last_interaction: Optional[datetime.datetime] = None
    satisfaction_score: float = 0.0

    def __post_init__(self):
        if self.preferences is None:
            self.preferences = {}
        if self.last_interaction is None:
            self.last_interaction = datetime.datetime.now()


@dataclass
class Memory:
    """è®°å¿†é¡¹"""
    content: str
    timestamp: datetime.datetime
    importance: float
    memory_type: str  # short_term, long_term
    tags: List[str] = None

    def __post_init__(self):
        if self.tags is None:
            self.tags = []


class AdvancedChatbotState(TypedDict):
    """é«˜çº§èŠå¤©æœºå™¨äººçŠ¶æ€"""
    # æ¶ˆæ¯ç®¡ç†
    messages: Annotated[List[BaseMessage], add_messages]

    # ç”¨æˆ·ä¿¡æ¯
    user_id: str
    user_profile: Optional[UserProfile]

    # å¯¹è¯ç®¡ç†
    conversation_id: str
    turn_count: int
    current_intent: str
    confidence_score: float

    # æƒ…æ„Ÿåˆ†æ
    user_emotion: str
    emotion_score: float

    # è®°å¿†ç®¡ç†
    short_term_memories: List[Memory]
    long_term_memories: List[Memory]

    # å·¥å…·å’Œå†³ç­–
    tool_calls_made: List[str]
    needs_human_review: bool
    escalation_reason: str

    # ç³»ç»ŸçŠ¶æ€
    last_response: str
    processing_time: float
    error_count: int


# =============================================================================
# å·¥å…·å®šä¹‰
# =============================================================================

@tool
def get_current_time() -> str:
    """è·å–å½“å‰æ—¶é—´"""
    return datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")


@tool
def calculate(expression: str) -> str:
    """æ‰§è¡Œç®€å•çš„æ•°å­¦è®¡ç®—

    Args:
        expression: æ•°å­¦è¡¨è¾¾å¼ï¼Œå¦‚ "2 + 3 * 4"
    """
    try:
        # å®‰å…¨çš„è®¡ç®—ï¼Œåªå…è®¸åŸºæœ¬æ•°å­¦æ“ä½œ
        allowed_chars = "0123456789+-*/.() "
        if not all(c in allowed_chars for c in expression):
            return "é”™è¯¯ï¼šè¡¨è¾¾å¼åŒ…å«ä¸å…è®¸çš„å­—ç¬¦"

        result = eval(expression)
        return f"{expression} = {result}"
    except Exception as e:
        return f"è®¡ç®—é”™è¯¯ï¼š{str(e)}"


@tool
def get_weather(city: str = "åŒ—äº¬") -> str:
    """è·å–å¤©æ°”ä¿¡æ¯ï¼ˆæ¨¡æ‹Ÿï¼‰

    Args:
        city: åŸå¸‚åç§°
    """
    import random

    weather_conditions = ["æ™´æœ—", "å¤šäº‘", "å°é›¨", "é˜´å¤©"]
    temperatures = list(range(15, 30))

    condition = random.choice(weather_conditions)
    temp = random.choice(temperatures)

    return f"{city}ä»Šå¤©å¤©æ°”{condition}ï¼Œæ¸©åº¦{temp}Â°C"


@tool
def search_knowledge_base(query: str) -> str:
    """æœç´¢çŸ¥è¯†åº“ï¼ˆæ¨¡æ‹Ÿï¼‰

    Args:
        query: æœç´¢æŸ¥è¯¢
    """
    # æ¨¡æ‹ŸçŸ¥è¯†åº“æœç´¢
    knowledge_base = {
        "äº§å“": "æˆ‘ä»¬çš„ä¸»è¦äº§å“åŒ…æ‹¬æ™ºèƒ½å®¢æœç³»ç»Ÿã€æ•°æ®åˆ†æå¹³å°ç­‰ã€‚",
        "ä»·æ ¼": "å…·ä½“ä»·æ ¼è¯·è”ç³»é”€å”®å›¢é˜Ÿï¼Œæˆ‘ä»¬æä¾›çµæ´»çš„å®šä»·æ–¹æ¡ˆã€‚",
        "æŠ€æœ¯æ”¯æŒ": "æˆ‘ä»¬æä¾›7x24å°æ—¶æŠ€æœ¯æ”¯æŒï¼Œå“åº”æ—¶é—´ä¸è¶…è¿‡2å°æ—¶ã€‚",
        "é€€æ¬¾": "äº§å“æ”¯æŒ30å¤©æ— ç†ç”±é€€æ¬¾ï¼Œè¯¦æƒ…è¯·æŸ¥çœ‹é€€æ¬¾æ”¿ç­–ã€‚"
    }

    for key, value in knowledge_base.items():
        if key in query:
            return f"æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ï¼š{value}"

    return "æŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚è¯·è”ç³»äººå·¥å®¢æœè·å–å¸®åŠ©ã€‚"


# å·¥å…·èŠ‚ç‚¹
tools = [get_current_time, calculate, get_weather, search_knowledge_base]
tool_node = ToolNode(tools)


# =============================================================================
# LLM é›†æˆ
# =============================================================================

class LLMManager:
    """LLM ç®¡ç†å™¨"""

    def __init__(self, config: ChatbotConfig):
        self.config = config
        self.llm = self._create_llm()

    def _create_llm(self):
        """åˆ›å»º LLM å®ä¾‹"""
        if self.config.llm_provider == "openai":
            return ChatOpenAI(
                model=self.config.model_name,
                temperature=self.config.temperature,
                max_tokens=self.config.max_tokens,
                api_key=os.getenv("OPENAI_API_KEY")
            )
        elif self.config.llm_provider == "anthropic":
            return ChatAnthropic(
                model=self.config.model_name,
                temperature=self.config.temperature,
                max_tokens=self.config.max_tokens,
                api_key=os.getenv("ANTHROPIC_API_KEY")
            )
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„LLMæä¾›å•†: {self.config.llm_provider}")

    def get_llm_with_tools(self):
        """è·å–ç»‘å®šå·¥å…·çš„LLM"""
        if self.config.enable_tools:
            return self.llm.bind_tools(tools)
        return self.llm


# =============================================================================
# è®°å¿†ç®¡ç†
# =============================================================================

class MemoryManager:
    """è®°å¿†ç®¡ç†å™¨"""

    def __init__(self, config: ChatbotConfig):
        self.config = config
        self.short_term_memory = deque(maxlen=config.short_term_memory_size)
        self.long_term_memory = []

    def add_memory(self, content: str, importance: float, memory_type: str = "short_term"):
        """æ·»åŠ è®°å¿†"""
        memory = Memory(
            content=content,
            timestamp=datetime.datetime.now(),
            importance=importance,
            memory_type=memory_type
        )

        if memory_type == "short_term":
            self.short_term_memory.append(memory)
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è½¬ä¸ºé•¿æœŸè®°å¿†
            if importance >= self.config.long_term_memory_threshold:
                self.promote_to_long_term(memory)
        else:
            self.long_term_memory.append(memory)

    def promote_to_long_term(self, memory: Memory):
        """æå‡ä¸ºé•¿æœŸè®°å¿†"""
        memory.memory_type = "long_term"
        self.long_term_memory.append(memory)

    def get_relevant_memories(self, query: str, max_count: int = 5) -> List[Memory]:
        """è·å–ç›¸å…³è®°å¿†"""
        # ç®€å•çš„å…³é”®è¯åŒ¹é…ï¼ˆç”Ÿäº§ç¯å¢ƒä¸­å¯ä»¥ä½¿ç”¨å‘é‡æœç´¢ï¼‰
        all_memories = list(self.short_term_memory) + self.long_term_memory
        relevant_memories = []

        for memory in all_memories:
            if any(word in memory.content.lower() for word in query.lower().split()):
                relevant_memories.append(memory)

        # æŒ‰é‡è¦æ€§æ’åº
        relevant_memories.sort(key=lambda m: m.importance, reverse=True)
        return relevant_memories[:max_count]


# =============================================================================
# æƒ…æ„Ÿåˆ†æ
# =============================================================================

class EmotionAnalyzer:
    """æƒ…æ„Ÿåˆ†æå™¨"""

    @staticmethod
    def analyze_emotion(text: str) -> tuple[str, float]:
        """åˆ†ææƒ…æ„Ÿï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        # æƒ…æ„Ÿè¯å…¸
        positive_words = ["é«˜å…´", "æ»¡æ„", "å¥½", "æ£’", "å–œæ¬¢", "æ„Ÿè°¢", "è°¢è°¢"]
        negative_words = ["ç”Ÿæ°”", "æ„¤æ€’", "ä¸æ»¡", "å·®", "ç³Ÿç³•", "è®¨åŒ", "æŠ•è¯‰"]
        neutral_words = ["è¯¢é—®", "æŸ¥è¯¢", "äº†è§£", "çŸ¥é“", "éœ€è¦"]

        text_lower = text.lower()

        positive_count = sum(1 for word in positive_words if word in text_lower)
        negative_count = sum(1 for word in negative_words if word in text_lower)
        neutral_count = sum(1 for word in neutral_words if word in text_lower)

        total_count = positive_count + negative_count + neutral_count

        if total_count == 0:
            return "neutral", 0.5

        if positive_count > negative_count:
            emotion = "positive"
            score = 0.5 + (positive_count / total_count) * 0.5
        elif negative_count > positive_count:
            emotion = "negative"
            score = 0.5 - (negative_count / total_count) * 0.5
        else:
            emotion = "neutral"
            score = 0.5

        return emotion, score


# =============================================================================
# èŠ‚ç‚¹å‡½æ•°
# =============================================================================

def input_analysis_node(state: AdvancedChatbotState) -> AdvancedChatbotState:
    """è¾“å…¥åˆ†æèŠ‚ç‚¹"""
    if not state["messages"]:
        return state

    last_message = state["messages"][-1]
    if isinstance(last_message, HumanMessage):
        user_input = last_message.content

        # æƒ…æ„Ÿåˆ†æ
        emotion, emotion_score = EmotionAnalyzer.analyze_emotion(user_input)

        # ç®€å•æ„å›¾è¯†åˆ«
        intent = "general"
        confidence = 0.5

        if any(word in user_input.lower() for word in ["è®¡ç®—", "ç®—", "æ•°å­¦"]):
            intent = "calculation"
            confidence = 0.8
        elif any(word in user_input.lower() for word in ["æ—¶é—´", "å‡ ç‚¹", "ç°åœ¨"]):
            intent = "time_query"
            confidence = 0.9
        elif any(word in user_input.lower() for word in ["å¤©æ°”", "æ¸©åº¦", "ä¸‹é›¨"]):
            intent = "weather_query"
            confidence = 0.8
        elif any(word in user_input.lower() for word in ["æŸ¥è¯¢", "æœç´¢", "çŸ¥è¯†"]):
            intent = "knowledge_search"
            confidence = 0.7

        # æ£€æŸ¥æ˜¯å¦éœ€è¦äººå·¥å®¡æ ¸
        sensitive_keywords = ["æŠ•è¯‰", "é€€æ¬¾", "æ³•å¾‹", "èµ·è¯‰"]
        needs_review = any(keyword in user_input for keyword in sensitive_keywords)

        return {
            **state,
            "current_intent": intent,
            "confidence_score": confidence,
            "user_emotion": emotion,
            "emotion_score": emotion_score,
            "needs_human_review": needs_review,
            "turn_count": state["turn_count"] + 1
        }

    return state


def memory_integration_node(state: AdvancedChatbotState) -> AdvancedChatbotState:
    """è®°å¿†é›†æˆèŠ‚ç‚¹"""
    # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œä¼šæŸ¥è¯¢å’Œæ›´æ–°è®°å¿†
    # ç°åœ¨åªæ˜¯æ¨¡æ‹Ÿ

    if state["messages"]:
        last_message = state["messages"][-1]
        if isinstance(last_message, HumanMessage):
            # åˆ›å»ºè®°å¿†
            importance = 0.6
            if state["user_emotion"] == "negative":
                importance = 0.9  # è´Ÿé¢æƒ…ç»ªçš„å¯¹è¯æ›´é‡è¦

            memory = Memory(
                content=last_message.content,
                timestamp=datetime.datetime.now(),
                importance=importance,
                memory_type="short_term"
            )

            # æ›´æ–°çŠ¶æ€ä¸­çš„è®°å¿†
            new_memories = state.get("short_term_memories", []) + [memory]

            return {
                **state,
                "short_term_memories": new_memories[-5:]  # åªä¿ç•™æœ€è¿‘5æ¡
            }

    return state


def llm_processing_node(state: AdvancedChatbotState) -> AdvancedChatbotState:
    """LLMå¤„ç†èŠ‚ç‚¹"""
    config = ChatbotConfig()
    llm_manager = LLMManager(config)
    llm = llm_manager.get_llm_with_tools()

    # æ„å»ºç³»ç»Ÿæç¤º
    system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½å®¢æœåŠ©æ‰‹ã€‚è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯å›å¤ç”¨æˆ·ï¼š

å½“å‰ç”¨æˆ·æƒ…æ„Ÿï¼š{state.get('user_emotion', 'neutral')} (åˆ†æ•°ï¼š{state.get('emotion_score', 0.5):.2f})
ç”¨æˆ·æ„å›¾ï¼š{state.get('current_intent', 'general')}
ç½®ä¿¡åº¦ï¼š{state.get('confidence_score', 0.5):.2f}

è¯·æä¾›ä¸“ä¸šã€å‹å¥½ã€æœ‰å¸®åŠ©çš„å›å¤ã€‚å¦‚æœç”¨æˆ·æƒ…ç»ªè´Ÿé¢ï¼Œè¯·ç‰¹åˆ«å…³æ³¨å¹¶æä¾›é¢å¤–çš„å…³æ€€ã€‚

è®°å¿†ä¸Šä¸‹æ–‡ï¼š
{json.dumps([m.content for m in state.get('short_term_memories', [])], ensure_ascii=False, indent=2)}

å¦‚æœéœ€è¦ä½¿ç”¨å·¥å…·ï¼Œè¯·è°ƒç”¨ç›¸åº”çš„å·¥å…·å‡½æ•°ã€‚"""

    # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
    messages = [SystemMessage(content=system_prompt)] + state["messages"]

    try:
        start_time = datetime.datetime.now()
        response = llm.invoke(messages)
        processing_time = (datetime.datetime.now() - start_time).total_seconds()

        # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
        tool_calls = []
        if hasattr(response, 'tool_calls') and response.tool_calls:
            tool_calls = [call['name'] for call in response.tool_calls]

        return {
            **state,
            "messages": state["messages"] + [response],
            "last_response": response.content if hasattr(response, 'content') else str(response),
            "processing_time": processing_time,
            "tool_calls_made": state.get("tool_calls_made", []) + tool_calls,
            "error_count": 0  # æˆåŠŸå¤„ç†ï¼Œé‡ç½®é”™è¯¯è®¡æ•°
        }

    except Exception as e:
        error_message = f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼š{str(e)}"
        error_response = AIMessage(content="æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›æŠ€æœ¯é—®é¢˜ã€‚è¯·ç¨åé‡è¯•æˆ–è”ç³»äººå·¥å®¢æœã€‚")

        return {
            **state,
            "messages": state["messages"] + [error_response],
            "last_response": error_response.content,
            "error_count": state.get("error_count", 0) + 1,
            "needs_human_review": True,
            "escalation_reason": "æŠ€æœ¯é”™è¯¯"
        }


def human_review_node(state: AdvancedChatbotState) -> AdvancedChatbotState:
    """äººå·¥å®¡æ ¸èŠ‚ç‚¹"""
    if state["needs_human_review"]:
        escalation_message = AIMessage(
            content="æ‚¨çš„é—®é¢˜å·²è½¬äº¤ç»™äººå·¥å®¢æœï¼Œä¸“ä¸šé¡¾é—®å°†å°½å¿«ä¸ºæ‚¨æœåŠ¡ã€‚è¯·ç¨å€™ç‰‡åˆ»ã€‚"
        )

        return {
            **state,
            "messages": state["messages"] + [escalation_message],
            "last_response": escalation_message.content
        }

    return state


def quality_assessment_node(state: AdvancedChatbotState) -> AdvancedChatbotState:
    """è´¨é‡è¯„ä¼°èŠ‚ç‚¹"""
    # ç®€å•çš„è´¨é‡è¯„ä¼°
    quality_score = 0.8  # é»˜è®¤è´¨é‡åˆ†æ•°

    # åŸºäºå„ç§å› ç´ è°ƒæ•´è´¨é‡åˆ†æ•°
    if state.get("error_count", 0) > 2:
        quality_score -= 0.3

    if state.get("user_emotion") == "positive":
        quality_score += 0.1
    elif state.get("user_emotion") == "negative":
        quality_score -= 0.2

    if state.get("confidence_score", 0) > 0.8:
        quality_score += 0.1

    # å¦‚æœè´¨é‡åˆ†æ•°è¿‡ä½ï¼Œå»ºè®®äººå·¥æ¥å…¥
    if quality_score < 0.5:
        return {
            **state,
            "needs_human_review": True,
            "escalation_reason": "è´¨é‡åˆ†æ•°è¿‡ä½"
        }

    return state


# =============================================================================
# è·¯ç”±å‡½æ•°
# =============================================================================

def should_use_tools(state: AdvancedChatbotState) -> str:
    """åˆ¤æ–­æ˜¯å¦éœ€è¦ä½¿ç”¨å·¥å…·"""
    if not state["messages"]:
        return "llm_processing"

    last_message = state["messages"][-1]
    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
        return "tools"

    return "quality_assessment"


def should_escalate(state: AdvancedChatbotState) -> str:
    """åˆ¤æ–­æ˜¯å¦éœ€è¦å‡çº§åˆ°äººå·¥"""
    if state["needs_human_review"]:
        return "human_review"

    return "end"


# =============================================================================
# å›¾æ„å»º
# =============================================================================

def create_advanced_chatbot_graph() -> StateGraph:
    """åˆ›å»ºé«˜çº§èŠå¤©æœºå™¨äººå›¾"""
    graph = StateGraph(AdvancedChatbotState)

    # æ·»åŠ èŠ‚ç‚¹
    graph.add_node("input_analysis", input_analysis_node)
    graph.add_node("memory_integration", memory_integration_node)
    graph.add_node("llm_processing", llm_processing_node)
    graph.add_node("tools", tool_node)
    graph.add_node("quality_assessment", quality_assessment_node)
    graph.add_node("human_review", human_review_node)

    # è®¾ç½®å…¥å£ç‚¹
    graph.set_entry_point("input_analysis")

    # æ·»åŠ è¾¹
    graph.add_edge("input_analysis", "memory_integration")
    graph.add_edge("memory_integration", "llm_processing")

    # æ¡ä»¶è¾¹ï¼šLLMå¤„ç†åå¯èƒ½éœ€è¦å·¥å…·è°ƒç”¨
    graph.add_conditional_edges(
        "llm_processing",
        should_use_tools,
        {
            "tools": "tools",
            "quality_assessment": "quality_assessment"
        }
    )

    # å·¥å…·è°ƒç”¨åå›åˆ°LLMå¤„ç†
    graph.add_edge("tools", "llm_processing")

    # è´¨é‡è¯„ä¼°åå¯èƒ½éœ€è¦äººå·¥æ¥å…¥
    graph.add_conditional_edges(
        "quality_assessment",
        should_escalate,
        {
            "human_review": "human_review",
            "end": END
        }
    )

    # äººå·¥å®¡æ ¸åç»“æŸ
    graph.add_edge("human_review", END)

    return graph


# =============================================================================
# ä¸»è¦åŠŸèƒ½ç±»
# =============================================================================

class AdvancedChatbot:
    """é«˜çº§èŠå¤©æœºå™¨äºº"""

    def __init__(self, config: ChatbotConfig = None):
        """åˆå§‹åŒ–"""
        self.config = config or ChatbotConfig()
        self.graph = create_advanced_chatbot_graph()
        self.memory_saver = MemorySaver()
        self.app = self.graph.compile(checkpointer=self.memory_saver)
        self.memory_manager = MemoryManager(self.config)

        print("ğŸ¤– é«˜çº§èŠå¤©æœºå™¨äººå·²å¯åŠ¨")
        print(f"ğŸ“Š é…ç½®: {self.config.llm_provider} | {self.config.model_name}")

    def create_initial_state(self, user_id: str = "default_user") -> AdvancedChatbotState:
        """åˆ›å»ºåˆå§‹çŠ¶æ€"""
        return {
            "messages": [],
            "user_id": user_id,
            "user_profile": None,
            "conversation_id": f"conv_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}",
            "turn_count": 0,
            "current_intent": "",
            "confidence_score": 0.0,
            "user_emotion": "neutral",
            "emotion_score": 0.5,
            "short_term_memories": [],
            "long_term_memories": [],
            "tool_calls_made": [],
            "needs_human_review": False,
            "escalation_reason": "",
            "last_response": "",
            "processing_time": 0.0,
            "error_count": 0
        }

    async def chat_async(self, message: str, conversation_id: str = None) -> Dict[str, Any]:
        """å¼‚æ­¥èŠå¤©"""
        if not conversation_id:
            conversation_id = f"conv_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}"

        # é…ç½®
        config = {"configurable": {"thread_id": conversation_id}}

        # åˆ›å»ºç”¨æˆ·æ¶ˆæ¯
        user_message = HumanMessage(content=message)

        # è·å–å½“å‰çŠ¶æ€æˆ–åˆ›å»ºæ–°çŠ¶æ€
        try:
            current_state = await self.app.aget_state(config)
            if current_state.values:
                state = current_state.values
                state["messages"] = state.get("messages", []) + [user_message]
            else:
                state = self.create_initial_state()
                state["messages"] = [user_message]
        except:
            state = self.create_initial_state()
            state["messages"] = [user_message]

        # æ‰§è¡Œå›¾
        result = await self.app.ainvoke(state, config)

        # æå–å“åº”
        if result["messages"]:
            last_message = result["messages"][-1]
            if isinstance(last_message, AIMessage):
                response = last_message.content
            else:
                response = str(last_message)
        else:
            response = "æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰ç†è§£æ‚¨çš„é—®é¢˜ã€‚"

        return {
            "response": response,
            "conversation_id": conversation_id,
            "intent": result.get("current_intent", ""),
            "emotion": result.get("user_emotion", "neutral"),
            "confidence": result.get("confidence_score", 0.0),
            "needs_human_review": result.get("needs_human_review", False),
            "processing_time": result.get("processing_time", 0.0),
            "tool_calls": result.get("tool_calls_made", [])
        }

    def chat(self, message: str, conversation_id: str = None) -> Dict[str, Any]:
        """åŒæ­¥èŠå¤©"""
        return asyncio.run(self.chat_async(message, conversation_id))

    async def stream_chat(self, message: str, conversation_id: str = None) -> AsyncIterator[str]:
        """æµå¼èŠå¤©"""
        # ç®€åŒ–çš„æµå¼å®ç°
        result = await self.chat_async(message, conversation_id)
        response = result["response"]

        # æ¨¡æ‹Ÿæ‰“å­—æœºæ•ˆæœ
        for char in response:
            yield char
            await asyncio.sleep(0.05)  # è°ƒæ•´å»¶è¿Ÿä»¥æ§åˆ¶é€Ÿåº¦

    def interactive_chat(self):
        """äº¤äº’å¼èŠå¤©"""
        print("ğŸ¤– é«˜çº§æ™ºèƒ½å®¢æœå¯åŠ¨ï¼è¾“å…¥ 'quit' é€€å‡ºï¼Œ'help' æŸ¥çœ‹å¸®åŠ©ã€‚\n")

        conversation_id = f"conv_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}"

        while True:
            try:
                user_input = input("æ‚¨: ").strip()

                if user_input.lower() in ['quit', 'exit', 'é€€å‡º']:
                    print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ï¼Œå†è§ï¼")
                    break

                if user_input.lower() == 'help':
                    print("""
ğŸ“‹ å¯ç”¨åŠŸèƒ½ï¼š
- åŸºæœ¬å¯¹è¯ï¼šç›´æ¥è¾“å…¥é—®é¢˜
- æ—¶é—´æŸ¥è¯¢ï¼šé—®"ç°åœ¨å‡ ç‚¹"
- è®¡ç®—ï¼šè¾“å…¥æ•°å­¦è¡¨è¾¾å¼ï¼Œå¦‚"è®¡ç®— 2+3*4"
- å¤©æ°”æŸ¥è¯¢ï¼šé—®"åŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·"
- çŸ¥è¯†æœç´¢ï¼šæœç´¢äº§å“ã€ä»·æ ¼ç­‰ä¿¡æ¯
- é€€å‡ºï¼šè¾“å…¥ quit æˆ– exit
                    """)
                    continue

                if not user_input:
                    print("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ã€‚")
                    continue

                # è·å–å›å¤
                print("ğŸ¤– æ­£åœ¨æ€è€ƒ...")
                result = self.chat(user_input, conversation_id)

                # æ˜¾ç¤ºå›å¤
                print(f"ğŸ¤– {result['response']}")

                # æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
                print(f"ğŸ’­ [æ„å›¾: {result['intent']}, æƒ…æ„Ÿ: {result['emotion']}, "
                      f"ç½®ä¿¡åº¦: {result['confidence']:.2f}, "
                      f"å¤„ç†æ—¶é—´: {result['processing_time']:.2f}s]")

                if result['tool_calls']:
                    print(f"ğŸ› ï¸ [ä½¿ç”¨å·¥å…·: {', '.join(result['tool_calls'])}]")

                if result['needs_human_review']:
                    print("âš ï¸ [å·²æ ‡è®°éœ€è¦äººå·¥å®¡æ ¸]")

                print()

            except KeyboardInterrupt:
                print("\nğŸ‘‹ å¯¹è¯ç»“æŸï¼")
                break
            except Exception as e:
                print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")


# =============================================================================
# æ¼”ç¤ºå’Œæµ‹è¯•
# =============================================================================

def demo_basic_features():
    """æ¼”ç¤ºåŸºæœ¬åŠŸèƒ½"""
    print("=== åŸºæœ¬åŠŸèƒ½æ¼”ç¤º ===\n")

    config = ChatbotConfig(
        llm_provider="openai",  # å¦‚æœæ²¡æœ‰API keyï¼Œä¼šä½¿ç”¨æ¨¡æ‹Ÿå›å¤
        enable_tools=True,
        enable_emotion_analysis=True
    )

    chatbot = AdvancedChatbot(config)

    test_cases = [
        "ä½ å¥½ï¼Œæˆ‘æƒ³äº†è§£ä¸€ä¸‹ä½ ä»¬çš„äº§å“",
        "è®¡ç®— 15 * 8 + 20",
        "ç°åœ¨å‡ ç‚¹äº†ï¼Ÿ",
        "åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ",
        "æˆ‘å¯¹æœåŠ¡ä¸æ»¡æ„ï¼Œè¦æŠ•è¯‰ï¼",
        "æœç´¢ä»·æ ¼ä¿¡æ¯"
    ]

    conversation_id = "demo_conversation"

    for i, message in enumerate(test_cases, 1):
        print(f"æµ‹è¯• {i}: {message}")
        try:
            result = chatbot.chat(message, conversation_id)
            print(f"å›å¤: {result['response']}")
            print(f"åˆ†æ: æ„å›¾={result['intent']}, æƒ…æ„Ÿ={result['emotion']}, "
                  f"ç½®ä¿¡åº¦={result['confidence']:.2f}")
            if result['tool_calls']:
                print(f"å·¥å…·è°ƒç”¨: {result['tool_calls']}")
            print("-" * 60)
        except Exception as e:
            print(f"é”™è¯¯: {e}")
            print("-" * 60)


async def demo_streaming():
    """æ¼”ç¤ºæµå¼è¾“å‡º"""
    print("=== æµå¼è¾“å‡ºæ¼”ç¤º ===\n")

    config = ChatbotConfig(enable_tools=False)  # ç®€åŒ–é…ç½®
    chatbot = AdvancedChatbot(config)

    print("ç”¨æˆ·: ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ çš„åŠŸèƒ½")
    print("ğŸ¤–: ", end="", flush=True)

    async for chunk in chatbot.stream_chat("ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ çš„åŠŸèƒ½"):
        print(chunk, end="", flush=True)

    print("\n")


def demo_memory_persistence():
    """æ¼”ç¤ºè®°å¿†æŒä¹…åŒ–"""
    print("=== è®°å¿†æŒä¹…åŒ–æ¼”ç¤º ===\n")

    chatbot = AdvancedChatbot()
    conversation_id = "memory_demo"

    # ç¬¬ä¸€è½®å¯¹è¯
    print("ç¬¬ä¸€è½®å¯¹è¯:")
    result1 = chatbot.chat("æˆ‘å«å¼ ä¸‰ï¼Œä½åœ¨åŒ—äº¬", conversation_id)
    print(f"ç”¨æˆ·: æˆ‘å«å¼ ä¸‰ï¼Œä½åœ¨åŒ—äº¬")
    print(f"ğŸ¤–: {result1['response']}")

    # ç¬¬äºŒè½®å¯¹è¯
    print("\nç¬¬äºŒè½®å¯¹è¯:")
    result2 = chatbot.chat("ä½ è¿˜è®°å¾—æˆ‘çš„åå­—å—ï¼Ÿ", conversation_id)
    print(f"ç”¨æˆ·: ä½ è¿˜è®°å¾—æˆ‘çš„åå­—å—ï¼Ÿ")
    print(f"ğŸ¤–: {result2['response']}")


# =============================================================================
# ä¸»ç¨‹åº
# =============================================================================

def main():
    """ä¸»ç¨‹åº"""
    print("ğŸš€ é«˜çº§èŠå¤©æœºå™¨äºº - LangGraph å®Œæ•´ç¤ºä¾‹")
    print("=" * 50)

    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    if not (os.getenv("OPENAI_API_KEY") or os.getenv("ANTHROPIC_API_KEY")):
        print("âš ï¸ è­¦å‘Šï¼šæœªè®¾ç½® API Keyï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
        print("è¯·è®¾ç½® OPENAI_API_KEY æˆ– ANTHROPIC_API_KEY ç¯å¢ƒå˜é‡ä»¥ä½¿ç”¨çœŸå® LLM\n")

    while True:
        print("\né€‰æ‹©æ¨¡å¼:")
        print("1. äº¤äº’å¼èŠå¤©")
        print("2. åŸºæœ¬åŠŸèƒ½æ¼”ç¤º")
        print("3. æµå¼è¾“å‡ºæ¼”ç¤º")
        print("4. è®°å¿†æŒä¹…åŒ–æ¼”ç¤º")
        print("5. é€€å‡º")

        choice = input("\nè¯·é€‰æ‹© (1-5): ").strip()

        if choice == "1":
            chatbot = AdvancedChatbot()
            chatbot.interactive_chat()

        elif choice == "2":
            demo_basic_features()

        elif choice == "3":
            asyncio.run(demo_streaming())

        elif choice == "4":
            demo_memory_persistence()

        elif choice == "5":
            print("ğŸ‘‹ å†è§ï¼")
            break

        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡è¯•ã€‚")


if __name__ == "__main__":
    main()


# =============================================================================
# å­¦ä¹ æŒ‡å—å’Œæœ€ä½³å®è·µ
# =============================================================================

"""
ğŸ¯ é«˜çº§èŠå¤©æœºå™¨äººå­¦ä¹ è¦ç‚¹:

1. **æ¶æ„è®¾è®¡**:
   - æ¨¡å—åŒ–èŠ‚ç‚¹è®¾è®¡ï¼Œæ¯ä¸ªèŠ‚ç‚¹æœ‰å•ä¸€èŒè´£
   - ä½¿ç”¨ TypedDict å®šä¹‰å¤æ‚çŠ¶æ€ç»“æ„
   - é…ç½®é©±åŠ¨çš„çµæ´»æ€§è®¾è®¡

2. **è®°å¿†ç®¡ç†**:
   - çŸ­æœŸè®°å¿†ç”¨äºä¼šè¯ä¸Šä¸‹æ–‡
   - é•¿æœŸè®°å¿†å­˜å‚¨é‡è¦ä¿¡æ¯
   - åŸºäºé‡è¦æ€§çš„è®°å¿†æå‡æœºåˆ¶

3. **å·¥å…·é›†æˆ**:
   - ä½¿ç”¨ @tool è£…é¥°å™¨å®šä¹‰å·¥å…·
   - ToolNode è‡ªåŠ¨å¤„ç†å·¥å…·è°ƒç”¨
   - å·¥å…·è°ƒç”¨çš„å®‰å…¨æ€§è€ƒè™‘

4. **LLM é›†æˆ**:
   - æ”¯æŒå¤šä¸ª LLM æä¾›å•†
   - åŠ¨æ€æç¤ºè¯æ„å»º
   - é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶

5. **Human-in-the-Loop**:
   - åŸºäºå…³é”®è¯å’Œæƒ…æ„Ÿçš„è‡ªåŠ¨å‡çº§
   - è´¨é‡è¯„ä¼°æœºåˆ¶
   - äººå·¥æ¥å…¥çš„ä¼˜é›…å¤„ç†

6. **çŠ¶æ€ç®¡ç†**:
   - ä½¿ç”¨ MemorySaver è¿›è¡ŒæŒä¹…åŒ–
   - æ”¯æŒå¤šè½®å¯¹è¯çš„ä¸Šä¸‹æ–‡ä¿æŒ
   - çŠ¶æ€çš„ç‰ˆæœ¬åŒ–å’Œå›æ»š

7. **ç”¨æˆ·ä½“éªŒ**:
   - æµå¼è¾“å‡ºæå‡äº¤äº’æ€§
   - æƒ…æ„Ÿè¯†åˆ«å’Œä¸ªæ€§åŒ–å›å¤
   - è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯

ğŸ”§ æ‰©å±•å»ºè®®:

1. **é«˜çº§è®°å¿†**: ä½¿ç”¨å‘é‡æ•°æ®åº“è¿›è¡Œè¯­ä¹‰æœç´¢
2. **å¤šæ¨¡æ€**: æ”¯æŒå›¾ç‰‡ã€è¯­éŸ³è¾“å…¥
3. **ä¸ªæ€§åŒ–**: åŸºäºç”¨æˆ·ç”»åƒè°ƒæ•´å›å¤é£æ ¼
4. **åˆ†æä»ªè¡¨æ¿**: å®æ—¶ç›‘æ§å¯¹è¯è´¨é‡å’Œç”¨æˆ·æ»¡æ„åº¦
5. **A/Bæµ‹è¯•**: æ”¯æŒä¸åŒæç¤ºè¯å’Œæ¨¡å‹çš„æ•ˆæœå¯¹æ¯”

è¿™ä¸ªé«˜çº§ç‰ˆæœ¬å±•ç¤ºäº†å¦‚ä½•æ„å»ºç”Ÿäº§çº§çš„ AI å®¢æœç³»ç»Ÿï¼
"""