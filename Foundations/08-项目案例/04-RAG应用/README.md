# RAGåº”ç”¨ç³»ç»Ÿé¡¹ç›®æ¡ˆä¾‹

> ğŸ¯ **é¡¹ç›®ç›®æ ‡**ï¼šæ„å»ºæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç³»ç»Ÿï¼Œç»“åˆçŸ¥è¯†åº“æ£€ç´¢å’Œå¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆ

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

è¿™ä¸ªRAGåº”ç”¨å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨LangGraphæ„å»ºæ™ºèƒ½çš„çŸ¥è¯†é—®ç­”ç³»ç»Ÿã€‚ç³»ç»Ÿé€šè¿‡å‘é‡æ£€ç´¢æŠ€æœ¯ä»çŸ¥è¯†åº“ä¸­æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ï¼Œç„¶åç»“åˆå¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆå‡†ç¡®ã€æœ‰æ ¹æ®çš„å›ç­”ã€‚

## ğŸ—ï¸ é¡¹ç›®ç»“æ„

```
04-RAGåº”ç”¨/
â”œâ”€â”€ README.md                    # é¡¹ç›®è¯´æ˜
â”œâ”€â”€ rag_system.py               # ä¸»RAGç³»ç»Ÿ
â”œâ”€â”€ document_loader.py          # æ–‡æ¡£åŠ è½½å™¨
â”œâ”€â”€ vector_store.py             # å‘é‡å­˜å‚¨ç®¡ç†
â”œâ”€â”€ requirements.txt            # ä¾èµ–åˆ—è¡¨
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ rag_config.py          # RAGé…ç½®
â”‚   â”œâ”€â”€ embedding_config.py     # åµŒå…¥æ¨¡å‹é…ç½®
â”‚   â””â”€â”€ retrieval_prompts.py    # æ£€ç´¢æç¤ºè¯
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ sample_docs.md         # ç¤ºä¾‹æ–‡æ¡£
â”‚   â”œâ”€â”€ knowledge_base/        # çŸ¥è¯†åº“æ–‡æ¡£
â”‚   â””â”€â”€ vector_db/            # å‘é‡æ•°æ®åº“æ–‡ä»¶
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ text_processing.py     # æ–‡æœ¬å¤„ç†å·¥å…·
â”‚   â”œâ”€â”€ chunk_strategies.py    # åˆ†å—ç­–ç•¥
â”‚   â””â”€â”€ retrieval_metrics.py   # æ£€ç´¢æŒ‡æ ‡
â””â”€â”€ examples/
    â”œâ”€â”€ simple_qa.py          # ç®€å•é—®ç­”ç¤ºä¾‹
    â”œâ”€â”€ document_chat.py      # æ–‡æ¡£å¯¹è¯ç¤ºä¾‹
    â””â”€â”€ batch_processing.py   # æ‰¹é‡å¤„ç†ç¤ºä¾‹
```

## ğŸ¯ å­¦ä¹ ç›®æ ‡

é€šè¿‡è¿™ä¸ªé¡¹ç›®ï¼Œä½ å°†å­¦ä¼šï¼š

1. **æ–‡æ¡£å¤„ç†**ï¼šæ–‡æ¡£åŠ è½½ã€åˆ†å—å’Œé¢„å¤„ç†
2. **å‘é‡åŒ–æŠ€æœ¯**ï¼šæ–‡æœ¬åµŒå…¥å’Œå‘é‡å­˜å‚¨
3. **ç›¸ä¼¼åº¦æ£€ç´¢**ï¼šåŸºäºè¯­ä¹‰çš„ä¿¡æ¯æ£€ç´¢
4. **ä¸Šä¸‹æ–‡ç”Ÿæˆ**ï¼šç»“åˆæ£€ç´¢ç»“æœç”Ÿæˆå›ç­”
5. **å¼•ç”¨è¿½è¸ª**ï¼šå›ç­”æ¥æºçš„å¯è¿½æº¯æ€§
6. **æ£€ç´¢ä¼˜åŒ–**ï¼šæå‡æ£€ç´¢è´¨é‡å’Œæ•ˆç‡

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å‰ç½®æ¡ä»¶

- âœ… å®Œæˆå‰é¢çš„é¡¹ç›®å­¦ä¹ 
- âœ… ç†è§£å‘é‡æ•°æ®åº“æ¦‚å¿µ
- âœ… åŸºæœ¬çš„NLPçŸ¥è¯†

### å®‰è£…ä¾èµ–

```bash
cd Foundations/08-é¡¹ç›®æ¡ˆä¾‹/04-RAGåº”ç”¨/
pip install -r requirements.txt
```

### åˆå§‹åŒ–çŸ¥è¯†åº“

```bash
# åŠ è½½ç¤ºä¾‹æ–‡æ¡£åˆ°å‘é‡æ•°æ®åº“
python document_loader.py --init

# éªŒè¯å‘é‡æ•°æ®åº“
python vector_store.py --verify
```

### è¿è¡ŒRAGç³»ç»Ÿ

```bash
# è®¾ç½®APIå¯†é’¥
export OPENAI_API_KEY="your-api-key"

# å¯åŠ¨RAGç³»ç»Ÿ
python rag_system.py
```

## ğŸ“Š ç³»ç»Ÿæ¶æ„

```mermaid
graph TD
    A[ç”¨æˆ·é—®é¢˜] --> B[é—®é¢˜ç†è§£]
    B --> C[å‘é‡æ£€ç´¢]
    C --> D[ç›¸å…³æ–‡æ¡£]
    D --> E[é‡æ’åº]
    E --> F[ä¸Šä¸‹æ–‡æ„å»º]
    F --> G[LLMç”Ÿæˆ]
    G --> H[ç­”æ¡ˆç”Ÿæˆ]
    H --> I[å¼•ç”¨æ ‡æ³¨]
    I --> J[æœ€ç»ˆå›ç­”]

    K[æ–‡æ¡£åº“] --> L[æ–‡æ¡£åˆ†å—]
    L --> M[å‘é‡åŒ–]
    M --> N[å‘é‡å­˜å‚¨]
    N --> C

    O[åé¦ˆå¾ªç¯] --> B
    J --> O
```

## ğŸ”§ æ ¸å¿ƒç»„ä»¶

### 1. æ–‡æ¡£åŠ è½½å™¨ (Document Loader)

**åŠŸèƒ½**ï¼š
- æ”¯æŒå¤šç§æ–‡æ¡£æ ¼å¼ï¼ˆPDFã€Wordã€Markdownã€TXTï¼‰
- æ™ºèƒ½æ–‡æ¡£åˆ†å—
- å…ƒæ•°æ®æå–
- é‡å¤å†…å®¹æ£€æµ‹

**ç¤ºä¾‹**ï¼š
```python
from document_loader import DocumentLoader

loader = DocumentLoader()
documents = loader.load_directory("./data/knowledge_base/")
chunks = loader.chunk_documents(documents, strategy="semantic")
```

### 2. å‘é‡å­˜å‚¨ (Vector Store)

**åŠŸèƒ½**ï¼š
- é«˜æ•ˆçš„å‘é‡ç›¸ä¼¼åº¦æœç´¢
- å…ƒæ•°æ®è¿‡æ»¤
- å¢é‡æ›´æ–°
- æŒä¹…åŒ–å­˜å‚¨

**ç¤ºä¾‹**ï¼š
```python
from vector_store import ChromaVectorStore

vector_store = ChromaVectorStore()
vector_store.add_documents(chunks)
results = vector_store.similarity_search(query, k=5)
```

### 3. RAGç³»ç»Ÿ (RAG System)

**åŠŸèƒ½**ï¼š
- æ™ºèƒ½æŸ¥è¯¢ç†è§£
- å¤šé˜¶æ®µæ£€ç´¢
- ä¸Šä¸‹æ–‡æ’åº
- ç”Ÿæˆè´¨é‡è¯„ä¼°

## ğŸ“ ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€é—®ç­”

```python
from rag_system import RAGSystem

rag = RAGSystem()

# ç®€å•é—®ç­”
question = "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ"
answer = rag.ask(question)
print(f"é—®é¢˜: {question}")
print(f"å›ç­”: {answer.content}")
print(f"æ¥æº: {answer.sources}")
```

### æ–‡æ¡£å¯¹è¯

```python
# åŸºäºç‰¹å®šæ–‡æ¡£çš„å¯¹è¯
rag.load_document("./data/ml_handbook.pdf")

conversation = [
    "è§£é‡Šä¸€ä¸‹ç›‘ç£å­¦ä¹ å’Œæ— ç›‘ç£å­¦ä¹ çš„åŒºåˆ«",
    "æ·±åº¦å­¦ä¹ ç®—æ³•æœ‰å“ªäº›ï¼Ÿ",
    "å¦‚ä½•è¯„ä¼°æœºå™¨å­¦ä¹ æ¨¡å‹çš„æ€§èƒ½ï¼Ÿ"
]

for question in conversation:
    answer = rag.ask(question, context_aware=True)
    print(f"Q: {question}")
    print(f"A: {answer.content}\n")
```

### æ‰¹é‡å¤„ç†

```python
# æ‰¹é‡é—®ç­”å¤„ç†
questions = [
    "ä»€ä¹ˆæ˜¯è‡ªç„¶è¯­è¨€å¤„ç†ï¼Ÿ",
    "æ¨èç³»ç»Ÿæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ",
    "è®¡ç®—æœºè§†è§‰çš„ä¸»è¦åº”ç”¨æ˜¯ä»€ä¹ˆï¼Ÿ"
]

results = rag.batch_ask(questions)
for q, a in results:
    print(f"Q: {q}")
    print(f"A: {a.content}")
    print(f"ç½®ä¿¡åº¦: {a.confidence}")
    print("-" * 50)
```

## ğŸ“ˆ æ£€ç´¢ç­–ç•¥

### 1. å¯†é›†æ£€ç´¢ (Dense Retrieval)

```python
# åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦çš„æ£€ç´¢
retriever = DenseRetriever(
    embedding_model="text-embedding-ada-002",
    similarity_threshold=0.7,
    max_results=10
)
```

### 2. æ··åˆæ£€ç´¢ (Hybrid Retrieval)

```python
# ç»“åˆå…³é”®è¯å’Œè¯­ä¹‰æ£€ç´¢
retriever = HybridRetriever(
    dense_weight=0.7,
    sparse_weight=0.3,
    fusion_method="rrf"  # Reciprocal Rank Fusion
)
```

### 3. é‡æ’åº (Re-ranking)

```python
# æ£€ç´¢ç»“æœé‡æ’åº
reranker = CrossEncoderReranker(
    model="ms-marco-MiniLM-L-6-v2",
    top_k=5
)
```

## ğŸ¯ ä¼˜åŒ–æŠ€å·§

### 1. åˆ†å—ç­–ç•¥ä¼˜åŒ–

```python
# è¯­ä¹‰åˆ†å—
semantic_chunker = SemanticChunker(
    chunk_size=512,
    overlap_size=50,
    similarity_threshold=0.6
)

# å›ºå®šé•¿åº¦åˆ†å—
fixed_chunker = FixedSizeChunker(
    chunk_size=1000,
    overlap_size=200
)

# ç»“æ„åŒ–åˆ†å—
structural_chunker = StructuralChunker(
    respect_sentences=True,
    respect_paragraphs=True
)
```

### 2. æŸ¥è¯¢å¢å¼º

```python
# æŸ¥è¯¢æ‰©å±•
query_expander = QueryExpander(
    methods=["synonyms", "related_terms", "paraphrasing"]
)

# æŸ¥è¯¢é‡å†™
query_rewriter = QueryRewriter(
    model="gpt-3.5-turbo",
    max_rewrites=3
)
```

### 3. ä¸Šä¸‹æ–‡ä¼˜åŒ–

```python
# ä¸Šä¸‹æ–‡å‹ç¼©
context_compressor = ContextCompressor(
    max_tokens=2000,
    preservation_strategy="importance_ranking"
)

# ä¸Šä¸‹æ–‡å»é‡
context_deduplicator = ContextDeduplicator(
    similarity_threshold=0.8
)
```

## ğŸ“Š è¯„ä¼°æŒ‡æ ‡

### æ£€ç´¢è´¨é‡æŒ‡æ ‡

```python
from utils.retrieval_metrics import RetrievalMetrics

metrics = RetrievalMetrics()

# è®¡ç®—æ£€ç´¢æŒ‡æ ‡
precision = metrics.precision_at_k(retrieved_docs, relevant_docs, k=5)
recall = metrics.recall_at_k(retrieved_docs, relevant_docs, k=5)
f1_score = metrics.f1_score(precision, recall)
mrr = metrics.mean_reciprocal_rank(retrieved_docs, relevant_docs)

print(f"Precision@5: {precision:.3f}")
print(f"Recall@5: {recall:.3f}")
print(f"F1 Score: {f1_score:.3f}")
print(f"MRR: {mrr:.3f}")
```

### ç”Ÿæˆè´¨é‡æŒ‡æ ‡

```python
from utils.generation_metrics import GenerationMetrics

gen_metrics = GenerationMetrics()

# è®¡ç®—ç”ŸæˆæŒ‡æ ‡
bleu_score = gen_metrics.bleu_score(generated_answer, reference_answer)
rouge_score = gen_metrics.rouge_score(generated_answer, reference_answer)
bertscore = gen_metrics.bert_score(generated_answer, reference_answer)

print(f"BLEU Score: {bleu_score:.3f}")
print(f"ROUGE-L: {rouge_score['rouge-l']:.3f}")
print(f"BERTScore F1: {bertscore['f1']:.3f}")
```

## ğŸ›¡ï¸ è´¨é‡æ§åˆ¶

### 1. ç­”æ¡ˆéªŒè¯

```python
class AnswerValidator:
    def validate_answer(self, question, answer, sources):
        checks = {
            "relevance": self.check_relevance(question, answer),
            "consistency": self.check_consistency(answer, sources),
            "completeness": self.check_completeness(question, answer),
            "factuality": self.check_factuality(answer)
        }
        return checks
```

### 2. å¼•ç”¨å‡†ç¡®æ€§

```python
class CitationValidator:
    def validate_citations(self, answer, sources):
        citations = self.extract_citations(answer)
        accuracy_scores = []

        for citation in citations:
            score = self.verify_citation(citation, sources)
            accuracy_scores.append(score)

        return {
            "citation_accuracy": np.mean(accuracy_scores),
            "citation_coverage": len(citations) / len(sources)
        }
```

## ğŸ”„ å®æ—¶æ›´æ–°

### å¢é‡ç´¢å¼•

```python
# å¢é‡æ·»åŠ æ–‡æ¡£
def add_documents_incrementally(new_documents):
    processed_docs = document_processor.process(new_documents)
    embeddings = embedding_model.embed_documents(processed_docs)
    vector_store.add_embeddings(embeddings, processed_docs)

    # æ›´æ–°ç´¢å¼•
    vector_store.update_index()
```

### åœ¨çº¿å­¦ä¹ 

```python
# åŸºäºç”¨æˆ·åé¦ˆä¼˜åŒ–
def update_from_feedback(question, answer, feedback):
    if feedback == "helpful":
        # å¢å¼ºç›¸å…³æ–‡æ¡£çš„æƒé‡
        enhancer.boost_relevant_docs(question, answer.sources)
    elif feedback == "not_helpful":
        # é™ä½ç›¸å…³æ–‡æ¡£çš„æƒé‡
        enhancer.demote_irrelevant_docs(question, answer.sources)
```

## ğŸ“± Webç•Œé¢

### Streamlitç•Œé¢

```python
import streamlit as st
from rag_system import RAGSystem

st.title("æ™ºèƒ½çŸ¥è¯†é—®ç­”ç³»ç»Ÿ")

# åˆå§‹åŒ–RAGç³»ç»Ÿ
if 'rag' not in st.session_state:
    st.session_state.rag = RAGSystem()

# é—®é¢˜è¾“å…¥
question = st.text_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼š")

if st.button("æé—®"):
    with st.spinner("æ­£åœ¨æ€è€ƒ..."):
        answer = st.session_state.rag.ask(question)

        st.write("### å›ç­”")
        st.write(answer.content)

        st.write("### å‚è€ƒæ¥æº")
        for i, source in enumerate(answer.sources, 1):
            st.write(f"{i}. {source.title} (ç›¸ä¼¼åº¦: {source.similarity:.3f})")
```

## ğŸš§ å¸¸è§é—®é¢˜

### Q: å¦‚ä½•æé«˜æ£€ç´¢å‡†ç¡®æ€§ï¼Ÿ

A: å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹æ³•ï¼š
1. ä¼˜åŒ–æ–‡æ¡£åˆ†å—ç­–ç•¥
2. ä½¿ç”¨æ›´å¥½çš„åµŒå…¥æ¨¡å‹
3. å®æ–½æŸ¥è¯¢å¢å¼ºæŠ€æœ¯
4. æ·»åŠ é‡æ’åºæœºåˆ¶

### Q: å¦‚ä½•å¤„ç†å¤šè¯­è¨€æ–‡æ¡£ï¼Ÿ

A: ä½¿ç”¨å¤šè¯­è¨€åµŒå…¥æ¨¡å‹ï¼Œæˆ–è€…ä¸ºä¸åŒè¯­è¨€åˆ†åˆ«å»ºç«‹ç´¢å¼•ã€‚

### Q: å¦‚ä½•ä¿è¯ç­”æ¡ˆçš„æ—¶æ•ˆæ€§ï¼Ÿ

A: å®æ–½å¢é‡æ›´æ–°æœºåˆ¶ï¼Œå®šæœŸåˆ·æ–°çŸ¥è¯†åº“ï¼Œæ ‡è®°æ–‡æ¡£çš„æ—¶é—´æˆ³ã€‚

## ğŸ¯ ç»ƒä¹ å»ºè®®

### åˆçº§ç»ƒä¹ 

1. **æ‰©å±•æ–‡æ¡£æ ¼å¼**ï¼šæ”¯æŒæ›´å¤šæ–‡æ¡£æ ¼å¼ï¼ˆExcelã€PowerPointï¼‰
2. **æ”¹è¿›åˆ†å—**ï¼šå®ç°æ›´æ™ºèƒ½çš„æ–‡æ¡£åˆ†å—ç­–ç•¥
3. **æ·»åŠ è¿‡æ»¤**ï¼šåŸºäºå…ƒæ•°æ®çš„æ–‡æ¡£è¿‡æ»¤åŠŸèƒ½

### ä¸­çº§ç»ƒä¹ 

1. **å¤šæ¨¡æ€RAG**ï¼šæ”¯æŒå›¾ç‰‡å’Œè¡¨æ ¼çš„æ£€ç´¢
2. **å¯¹è¯å†å²**ï¼šå®ç°å¤šè½®å¯¹è¯çš„ä¸Šä¸‹æ–‡ç®¡ç†
3. **ä¸ªæ€§åŒ–**ï¼šåŸºäºç”¨æˆ·åå¥½çš„ä¸ªæ€§åŒ–æ£€ç´¢

### é«˜çº§ç»ƒä¹ 

1. **åˆ†å¸ƒå¼éƒ¨ç½²**ï¼šæ”¯æŒå¤§è§„æ¨¡åˆ†å¸ƒå¼æ£€ç´¢
2. **å®æ—¶æ›´æ–°**ï¼šå®ç°æ–‡æ¡£çš„å®æ—¶ç´¢å¼•æ›´æ–°
3. **å¼ºåŒ–å­¦ä¹ **ï¼šåŸºäºç”¨æˆ·åé¦ˆçš„æ£€ç´¢ä¼˜åŒ–

## ğŸ‰ å®Œæˆæ ‡å¿—

å½“ä½ èƒ½å¤Ÿï¼š

- âœ… æ„å»ºå®Œæ•´çš„RAGç³»ç»Ÿæµç¨‹
- âœ… å®ç°é«˜è´¨é‡çš„æ–‡æ¡£æ£€ç´¢
- âœ… ç”Ÿæˆå‡†ç¡®ä¸”æœ‰ä¾æ®çš„å›ç­”
- âœ… ä¼˜åŒ–æ£€ç´¢å’Œç”Ÿæˆæ€§èƒ½
- âœ… å¤„ç†å¤æ‚çš„çŸ¥è¯†é—®ç­”åœºæ™¯

æ­å–œï¼ä½ å·²ç»æŒæ¡äº†æ„å»ºç”Ÿäº§çº§RAGç³»ç»Ÿçš„èƒ½åŠ›ï¼

## ğŸš€ ä¸‹ä¸€æ­¥

å®ŒæˆRAGåº”ç”¨åï¼Œä½ å¯ä»¥ï¼š
- æ¢ç´¢æ›´é«˜çº§çš„RAGæŠ€æœ¯ï¼ˆGraphRAGã€Multi-hop RAGï¼‰
- é›†æˆåˆ°ç°æœ‰çš„åº”ç”¨ç³»ç»Ÿä¸­
- éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒå¹¶è¿›è¡Œæ€§èƒ½ç›‘æ§

---

*é€šè¿‡è¿™ä¸ªé¡¹ç›®ï¼Œä½ å°†å­¦ä¼šå¦‚ä½•æ„å»ºæ™ºèƒ½çš„çŸ¥è¯†é—®ç­”ç³»ç»Ÿï¼* ğŸš€