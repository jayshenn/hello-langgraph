# 01-æœ¬åœ°å¼€å‘

## æ¦‚è¿°

æœ¬åœ°å¼€å‘æ˜¯ LangGraph åº”ç”¨å¼€å‘çš„èµ·ç‚¹ï¼Œé€šè¿‡ LangGraph CLI å’Œ Studio æä¾›å®Œæ•´çš„å¼€å‘è°ƒè¯•ç¯å¢ƒã€‚æœ¬åœ°ç¯å¢ƒæ”¯æŒå¿«é€Ÿè¿­ä»£ã€å®æ—¶è°ƒè¯•å’Œå¯è§†åŒ–å›¾å½¢ç¼–è¾‘ã€‚

## å¼€å‘å·¥å…·æ ˆ

### LangGraph CLI
å‘½ä»¤è¡Œå·¥å…·ï¼Œç”¨äºåˆ›å»ºã€ç®¡ç†å’Œè¿è¡Œ LangGraph åº”ç”¨

### LangGraph Studio
å¯è§†åŒ– IDEï¼Œæä¾›å›¾å½¢ç•Œé¢è¿›è¡Œè°ƒè¯•å’Œäº¤äº’

### æœ¬åœ°æœåŠ¡å™¨
åœ¨æœ¬åœ°è¿è¡Œå®Œæ•´çš„ LangGraph æœåŠ¡ï¼Œæ”¯æŒ API è°ƒç”¨å’Œ WebUI

## ç¯å¢ƒå‡†å¤‡

### ç³»ç»Ÿè¦æ±‚
- Python 3.8+
- Node.js 16+ (å¯é€‰ï¼Œç”¨äºå‰ç«¯å¼€å‘)
- Git
- è‡³å°‘ 4GB å¯ç”¨å†…å­˜

### æ ¸å¿ƒä¾èµ–å®‰è£…
```bash
# å®‰è£… LangGraph CLI
pip install langgraph-cli

# éªŒè¯å®‰è£…
langgraph --version

# å®‰è£…æ ¸å¿ƒä¾èµ–
pip install langgraph langchain_openai python-dotenv
```

## å¿«é€Ÿå¼€å§‹

### 1. åˆ›å»ºæ–°é¡¹ç›®
```bash
# ä½¿ç”¨æ¨¡æ¿åˆ›å»ºé¡¹ç›®
langgraph new my-agent --template=react-agent

# è¿›å…¥é¡¹ç›®ç›®å½•
cd my-agent

# æŸ¥çœ‹é¡¹ç›®ç»“æ„
tree .
```

### 2. é¡¹ç›®ç»“æ„è§£æ
```
my-agent/
â”œâ”€â”€ langgraph.json          # é¡¹ç›®é…ç½®æ–‡ä»¶
â”œâ”€â”€ requirements.txt        # Pythonä¾èµ–
â”œâ”€â”€ .env.example           # ç¯å¢ƒå˜é‡æ¨¡æ¿
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ my_agent/
â”‚   â”‚   â”œâ”€â”€ graph.py       # å›¾å®šä¹‰
â”‚   â”‚   â””â”€â”€ state.py       # çŠ¶æ€å®šä¹‰
â”‚   â””â”€â”€ __init__.py
â””â”€â”€ tests/                 # æµ‹è¯•æ–‡ä»¶
```

### 3. é…ç½®ç¯å¢ƒå˜é‡
```bash
# å¤åˆ¶ç¯å¢ƒå˜é‡æ¨¡æ¿
cp .env.example .env

# ç¼–è¾‘ç¯å¢ƒå˜é‡
nano .env
```

**`.env` æ–‡ä»¶ç¤ºä¾‹ï¼š**
```bash
# OpenAI APIé…ç½®
OPENAI_API_KEY=your_openai_api_key_here

# LangSmithè¿½è¸ªï¼ˆå¯é€‰ï¼‰
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=your_langsmith_api_key
LANGCHAIN_PROJECT=my-agent-local

# å…¶ä»–é…ç½®
DEBUG=true
LOG_LEVEL=INFO
```

### 4. å®‰è£…é¡¹ç›®ä¾èµ–
```bash
# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# æˆ–ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒ
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# .venv\Scripts\activate   # Windows
pip install -r requirements.txt
```

## LangGraph CLI ä½¿ç”¨

### æ ¸å¿ƒå‘½ä»¤
```bash
# åˆ›å»ºæ–°åº”ç”¨
langgraph new <app_name> [--template=<template_name>]

# å¯åŠ¨å¼€å‘æœåŠ¡å™¨
langgraph dev

# æ„å»ºåº”ç”¨
langgraph build

# è¿è¡Œæµ‹è¯•
langgraph test

# æŸ¥çœ‹é¡¹ç›®ä¿¡æ¯
langgraph info

# å‡çº§CLI
langgraph update
```

### å¼€å‘æœåŠ¡å™¨
```bash
# å¯åŠ¨å¸¦çƒ­é‡è½½çš„å¼€å‘æœåŠ¡å™¨
langgraph dev

# æŒ‡å®šç«¯å£
langgraph dev --port 8123

# å¯ç”¨è°ƒè¯•æ¨¡å¼
langgraph dev --debug

# ç›‘å¬æ‰€æœ‰æ¥å£
langgraph dev --host 0.0.0.0
```

**è¾“å‡ºç¤ºä¾‹ï¼š**
```
ğŸš€ LangGraph Server starting...
ğŸ“Š LangGraph Studio: http://localhost:8123
ğŸ”§ API Endpoint: http://localhost:8123/api
ğŸ“ Documentation: http://localhost:8123/docs
âœ… Server ready! Watching for changes...
```

## LangGraph Studio ä½¿ç”¨

### è®¿é—® Studio
1. å¯åŠ¨å¼€å‘æœåŠ¡å™¨ï¼š`langgraph dev`
2. æ‰“å¼€æµè§ˆå™¨è®¿é—®ï¼š`http://localhost:8123`
3. é€‰æ‹©å·¥ä½œæ¨¡å¼ï¼šGraph æ¨¡å¼æˆ– Chat æ¨¡å¼

### Graph æ¨¡å¼
å¯è§†åŒ–å›¾å½¢ç¼–è¾‘å’Œè°ƒè¯•æ¨¡å¼

**ä¸»è¦åŠŸèƒ½ï¼š**
- å›¾å½¢å¯è§†åŒ–å±•ç¤º
- èŠ‚ç‚¹çŠ¶æ€æ£€æŸ¥
- æ‰§è¡Œæµç¨‹è¿½è¸ª
- æ–­ç‚¹è°ƒè¯•
- çŠ¶æ€æ—¶é—´æ—…è¡Œ

**ä½¿ç”¨æ­¥éª¤ï¼š**
1. åœ¨å·¦ä¾§é¢æ¿é€‰æ‹©å›¾
2. åœ¨è¾“å…¥æ¡†ä¸­è¾“å…¥æµ‹è¯•æ•°æ®
3. ç‚¹å‡» "Run" æ‰§è¡Œå›¾
4. åœ¨å³ä¾§æŸ¥çœ‹æ‰§è¡Œç»“æœå’Œæ—¥å¿—

### Chat æ¨¡å¼
å¯¹è¯å¼äº¤äº’æ¨¡å¼

**ä¸»è¦åŠŸèƒ½ï¼š**
- å®æ—¶å¯¹è¯æµ‹è¯•
- æ¶ˆæ¯å†å²ç®¡ç†
- å¤šè½®å¯¹è¯æ”¯æŒ
- å·¥å…·è°ƒç”¨å±•ç¤º

## æœ¬åœ°é…ç½®æ–‡ä»¶

### langgraph.json
é¡¹ç›®çš„æ ¸å¿ƒé…ç½®æ–‡ä»¶

```json
{
  "dependencies": ["."],
  "graphs": {
    "my_agent": "./src/my_agent/graph.py:graph"
  },
  "env": ".env",
  "python_version": "3.11",
  "pip_config_file": "./pyproject.toml",
  "dockerfile_lines": [
    "RUN apt-get update && apt-get install -y git"
  ]
}
```

**é…ç½®é¡¹è¯´æ˜ï¼š**
- `dependencies`: ä¾èµ–è·¯å¾„
- `graphs`: å›¾å®šä¹‰æ˜ å°„
- `env`: ç¯å¢ƒå˜é‡æ–‡ä»¶
- `python_version`: Pythonç‰ˆæœ¬
- `pip_config_file`: pipé…ç½®æ–‡ä»¶
- `dockerfile_lines`: è‡ªå®šä¹‰DockeræŒ‡ä»¤

### requirements.txt
```txt
langgraph>=0.2.0
langchain>=0.3.0
langchain_openai>=0.2.0
python-dotenv>=1.0.0
pydantic>=2.0.0
typing-extensions>=4.0.0
```

## è°ƒè¯•æŠ€å·§

### 1. æ—¥å¿—é…ç½®
```python
import logging

# é…ç½®æ—¥å¿—çº§åˆ«
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

# åœ¨èŠ‚ç‚¹ä¸­æ·»åŠ æ—¥å¿—
def my_node(state):
    logging.info(f"å¤„ç†çŠ¶æ€: {state}")
    # èŠ‚ç‚¹é€»è¾‘
    return {"output": "processed"}
```

### 2. æ–­ç‚¹è°ƒè¯•
```python
# åœ¨å›¾ç¼–è¯‘æ—¶è®¾ç½®æ–­ç‚¹
app = graph.compile(
    checkpointer=memory,
    interrupt_before=["human_review"],  # åœ¨æŒ‡å®šèŠ‚ç‚¹å‰ä¸­æ–­
    interrupt_after=["data_processing"]  # åœ¨æŒ‡å®šèŠ‚ç‚¹åä¸­æ–­
)

# è¿è¡Œæ—¶è®¾ç½®æ–­ç‚¹
app.invoke(
    {"input": "test"},
    config={"configurable": {"thread_id": "1"}},
    debug=True  # å¯ç”¨è°ƒè¯•æ¨¡å¼
)
```

### 3. çŠ¶æ€æ£€æŸ¥
```python
# è·å–å½“å‰çŠ¶æ€
state = app.get_state(config={"configurable": {"thread_id": "1"}})
print(f"å½“å‰çŠ¶æ€: {state.values}")
print(f"ä¸‹ä¸€æ­¥: {state.next}")

# çŠ¶æ€å†å²
history = app.get_state_history(
    config={"configurable": {"thread_id": "1"}}
)
for checkpoint in history:
    print(f"æ­¥éª¤ {checkpoint.metadata['step']}: {checkpoint.values}")
```

## çƒ­é‡è½½å¼€å‘

### ä»£ç å˜æ›´æ£€æµ‹
```bash
# å¯åŠ¨å¼€å‘æœåŠ¡å™¨ï¼ˆè‡ªåŠ¨çƒ­é‡è½½ï¼‰
langgraph dev

# ç›‘æ§ç‰¹å®šæ–‡ä»¶
langgraph dev --watch src/
```

**æ”¯æŒçƒ­é‡è½½çš„æ–‡ä»¶ç±»å‹ï¼š**
- `.py` Pythonæºæ–‡ä»¶
- `langgraph.json` é…ç½®æ–‡ä»¶
- `.env` ç¯å¢ƒå˜é‡æ–‡ä»¶
- `requirements.txt` ä¾èµ–æ–‡ä»¶

### å¼€å‘å·¥ä½œæµ
1. ä¿®æ”¹ä»£ç æ–‡ä»¶
2. ä¿å­˜æ–‡ä»¶ï¼ˆè§¦å‘çƒ­é‡è½½ï¼‰
3. åœ¨ Studio ä¸­æµ‹è¯•å˜æ›´
4. æŸ¥çœ‹æ—¥å¿—è¾“å‡º
5. é‡å¤è¿­ä»£

## æ€§èƒ½ä¼˜åŒ–

### 1. ä¾èµ–ç¼“å­˜
```bash
# ä½¿ç”¨pipç¼“å­˜
pip install --cache-dir .pip-cache -r requirements.txt

# æ¸…ç†ç¼“å­˜
pip cache purge
```

### 2. å¹¶å‘é…ç½®
```python
# åœ¨å›¾é…ç½®ä¸­è®¾ç½®å¹¶å‘
app = graph.compile(
    checkpointer=memory,
    max_concurrency=4  # æœ€å¤§å¹¶å‘æ•°
)
```

### 3. å†…å­˜ç®¡ç†
```python
import gc

def memory_intensive_node(state):
    # å¤„ç†å¤§é‡æ•°æ®
    result = process_large_data(state["data"])

    # æ‰‹åŠ¨è§¦å‘åƒåœ¾å›æ”¶
    gc.collect()

    return {"result": result}
```

## ç¯å¢ƒéš”ç¦»

### è™šæ‹Ÿç¯å¢ƒ
```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv langgraph-env

# æ¿€æ´»ç¯å¢ƒ
source langgraph-env/bin/activate  # Linux/Mac
# langgraph-env\Scripts\activate    # Windows

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# éªŒè¯ç¯å¢ƒ
which python
pip list
```

### Docker å¼€å‘ç¯å¢ƒ
```dockerfile
# Dockerfile.dev
FROM python:3.11-slim

WORKDIR /app

# å®‰è£…å¼€å‘ä¾èµ–
COPY requirements.txt .
RUN pip install -r requirements.txt

# å¤åˆ¶æºç 
COPY . .

# æš´éœ²ç«¯å£
EXPOSE 8123

# å¯åŠ¨å¼€å‘æœåŠ¡å™¨
CMD ["langgraph", "dev", "--host", "0.0.0.0"]
```

```bash
# æ„å»ºå¼€å‘é•œåƒ
docker build -f Dockerfile.dev -t my-agent-dev .

# è¿è¡Œå¼€å‘å®¹å™¨
docker run -p 8123:8123 -v $(pwd):/app my-agent-dev
```

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. ä¾èµ–å†²çª
```bash
# æ£€æŸ¥ä¾èµ–
pip check

# åˆ›å»ºæ–°çš„è™šæ‹Ÿç¯å¢ƒ
rm -rf .venv
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

#### 2. ç«¯å£è¢«å ç”¨
```bash
# æŸ¥æ‰¾å ç”¨ç«¯å£çš„è¿›ç¨‹
lsof -i :8123

# æ€æ­»è¿›ç¨‹
kill -9 <PID>

# ä½¿ç”¨å…¶ä»–ç«¯å£
langgraph dev --port 8124
```

#### 3. ç¯å¢ƒå˜é‡æœªç”Ÿæ•ˆ
```bash
# æ£€æŸ¥ç¯å¢ƒå˜é‡
printenv | grep OPENAI

# æ‰‹åŠ¨åŠ è½½ç¯å¢ƒå˜é‡
export $(cat .env | xargs)

# éªŒè¯é…ç½®
python -c "import os; print(os.getenv('OPENAI_API_KEY'))"
```

#### 4. å›¾æ— æ³•åŠ è½½
```python
# æ£€æŸ¥å›¾å®šä¹‰
python -c "from src.my_agent.graph import graph; print(graph)"

# éªŒè¯å›¾ç»“æ„
graph.get_graph().print_ascii()
```

## å¼€å‘æœ€ä½³å®è·µ

### 1. é¡¹ç›®ç»“æ„
```
my-agent/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/           # Agentå®šä¹‰
â”‚   â”œâ”€â”€ tools/           # å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ graphs/          # å›¾å®šä¹‰
â”‚   â”œâ”€â”€ states/          # çŠ¶æ€ç±»
â”‚   â””â”€â”€ utils/           # å·¥å…·å‡½æ•°
â”œâ”€â”€ tests/               # æµ‹è¯•ä»£ç 
â”œâ”€â”€ docs/               # æ–‡æ¡£
â”œâ”€â”€ data/               # æ•°æ®æ–‡ä»¶
â””â”€â”€ logs/               # æ—¥å¿—æ–‡ä»¶
```

### 2. ä»£ç ç»„ç»‡
```python
# states.py - ç»Ÿä¸€çŠ¶æ€å®šä¹‰
from typing import TypedDict, List
from langgraph.graph import add_messages

class AgentState(TypedDict):
    messages: List[dict]
    user_input: str
    result: str

# nodes.py - èŠ‚ç‚¹å‡½æ•°
def process_input_node(state: AgentState) -> AgentState:
    """å¤„ç†ç”¨æˆ·è¾“å…¥"""
    return {"processed_input": state["user_input"].strip()}

# graph.py - å›¾å®šä¹‰
from langgraph.graph import StateGraph, END
from .states import AgentState
from .nodes import process_input_node

def create_graph():
    graph = StateGraph(AgentState)
    graph.add_node("process", process_input_node)
    graph.add_edge("process", END)
    graph.set_entry_point("process")
    return graph.compile()
```

### 3. æµ‹è¯•é©±åŠ¨å¼€å‘
```python
# tests/test_graph.py
import pytest
from src.my_agent.graph import create_graph

def test_basic_flow():
    app = create_graph()
    result = app.invoke({"user_input": "Hello"})
    assert "processed_input" in result
    assert result["processed_input"] == "Hello"

def test_empty_input():
    app = create_graph()
    result = app.invoke({"user_input": ""})
    assert result["processed_input"] == ""
```

### 4. ç‰ˆæœ¬æ§åˆ¶
```gitignore
# .gitignore
.env
.venv/
__pycache__/
*.pyc
.pytest_cache/
logs/
.DS_Store
*.log
```

## ä¸‹ä¸€æ­¥

- ğŸ“– å­¦ä¹  [02-äº‘éƒ¨ç½²](./02-äº‘éƒ¨ç½².md) - å°†åº”ç”¨éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ
- ğŸ”§ æ¢ç´¢ [04-ç›‘æ§ä¸è¿½è¸ª](./04-ç›‘æ§ä¸è¿½è¸ª.md) - æ·»åŠ ç›‘æ§å’Œè°ƒè¯•åŠŸèƒ½
- ğŸ³ äº†è§£ [06-Dockerå®¹å™¨åŒ–](./06-Dockerå®¹å™¨åŒ–.md) - å®¹å™¨åŒ–éƒ¨ç½²æ–¹æ¡ˆ

## ç›¸å…³é“¾æ¥

- [LangGraph CLI å®˜æ–¹æ–‡æ¡£](https://langchain-ai.github.io/langgraph/concepts/langgraph_cli/)
- [LangGraph Studio æŒ‡å—](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/)
- [æ¨¡æ¿åº”ç”¨](https://langchain-ai.github.io/langgraph/concepts/template_applications/)
- [åº”ç”¨ç»“æ„è§„èŒƒ](https://langchain-ai.github.io/langgraph/concepts/application_structure/)