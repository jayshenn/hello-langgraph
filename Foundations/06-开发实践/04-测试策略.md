# LangGraph æµ‹è¯•ç­–ç•¥

> ğŸ¯ **å­¦ä¹ ç›®æ ‡**ï¼šæŒæ¡ LangGraph åº”ç”¨çš„å…¨é¢æµ‹è¯•æ–¹æ³•ï¼ŒåŒ…æ‹¬å•å…ƒæµ‹è¯•ã€é›†æˆæµ‹è¯•ã€LLM è¯„ä¼°ç­‰

## ğŸ§ª æµ‹è¯•ç¯å¢ƒæ­å»º

### 1. æµ‹è¯•æ¡†æ¶é€‰æ‹©

```python
import unittest
import pytest
import asyncio
from unittest.mock import Mock, patch, MagicMock
from typing import TypedDict, List, Dict, Any
from langgraph import StateGraph, START, END

# æµ‹è¯•ç”¨çš„çŠ¶æ€å®šä¹‰
class TestState(TypedDict):
    input_data: str
    processed_data: str
    step_count: int
    test_results: Dict[str, Any]

# åŸºç¡€æµ‹è¯•ç±»
class LangGraphTestCase(unittest.TestCase):
    """LangGraph æµ‹è¯•åŸºç±»"""

    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        self.test_state = {
            "input_data": "æµ‹è¯•è¾“å…¥",
            "processed_data": "",
            "step_count": 0,
            "test_results": {}
        }

    def tearDown(self):
        """æµ‹è¯•åæ¸…ç†"""
        # æ¸…ç†ä»»ä½•å…¨å±€çŠ¶æ€
        pass

    def create_test_graph(self, nodes: Dict[str, callable]) -> StateGraph:
        """åˆ›å»ºæµ‹è¯•å›¾çš„è¾…åŠ©æ–¹æ³•"""
        graph = StateGraph(TestState)

        for node_name, node_func in nodes.items():
            graph.add_node(node_name, node_func)

        return graph

    def assert_state_contains(self, state: dict, expected_keys: List[str]):
        """æ–­è¨€çŠ¶æ€åŒ…å«æŒ‡å®šé”®"""
        for key in expected_keys:
            self.assertIn(key, state, f"çŠ¶æ€ä¸­ç¼ºå°‘é”®: {key}")

    def assert_state_values(self, state: dict, expected_values: Dict[str, Any]):
        """æ–­è¨€çŠ¶æ€å€¼"""
        for key, expected_value in expected_values.items():
            self.assertEqual(
                state.get(key),
                expected_value,
                f"é”® {key} çš„å€¼ä¸åŒ¹é…: æœŸæœ› {expected_value}, å®é™… {state.get(key)}"
            )
```

### 2. æµ‹è¯•æ•°æ®ç®¡ç†

```python
import json
import os
from pathlib import Path

class TestDataManager:
    """æµ‹è¯•æ•°æ®ç®¡ç†å™¨"""

    def __init__(self, data_dir: str = "test_data"):
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(exist_ok=True)

    def load_test_data(self, filename: str) -> dict:
        """åŠ è½½æµ‹è¯•æ•°æ®"""
        filepath = self.data_dir / filename
        if not filepath.exists():
            raise FileNotFoundError(f"æµ‹è¯•æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")

        with open(filepath, 'r', encoding='utf-8') as f:
            return json.load(f)

    def save_test_data(self, filename: str, data: dict):
        """ä¿å­˜æµ‹è¯•æ•°æ®"""
        filepath = self.data_dir / filename
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)

    def create_test_cases(self, scenario: str) -> List[dict]:
        """åˆ›å»ºæµ‹è¯•ç”¨ä¾‹"""
        test_cases = {
            "basic_processing": [
                {
                    "name": "æ­£å¸¸è¾“å…¥",
                    "input": {"input_data": "æ­£å¸¸æ•°æ®", "step_count": 0},
                    "expected": {"processed_data": "æ­£å¸¸æ•°æ®_å·²å¤„ç†", "step_count": 1}
                },
                {
                    "name": "ç©ºè¾“å…¥",
                    "input": {"input_data": "", "step_count": 0},
                    "expected": {"processed_data": "_å·²å¤„ç†", "step_count": 1}
                },
                {
                    "name": "é•¿æ–‡æœ¬è¾“å…¥",
                    "input": {"input_data": "å¾ˆé•¿çš„æ–‡æœ¬" * 100, "step_count": 0},
                    "expected": {"step_count": 1}
                }
            ],
            "error_scenarios": [
                {
                    "name": "æ— æ•ˆè¾“å…¥ç±»å‹",
                    "input": {"input_data": 123, "step_count": 0},
                    "should_raise": TypeError
                },
                {
                    "name": "ç¼ºå°‘å¿…éœ€å­—æ®µ",
                    "input": {"step_count": 0},
                    "should_raise": KeyError
                }
            ]
        }

        return test_cases.get(scenario, [])

# å…¨å±€æµ‹è¯•æ•°æ®ç®¡ç†å™¨
test_data_manager = TestDataManager()
```

## ğŸ”¬ å•å…ƒæµ‹è¯•

### 1. èŠ‚ç‚¹å‡½æ•°æµ‹è¯•

```python
def simple_processing_node(state: TestState) -> TestState:
    """ç®€å•å¤„ç†èŠ‚ç‚¹"""
    return {
        "input_data": state["input_data"],
        "processed_data": f"{state['input_data']}_å·²å¤„ç†",
        "step_count": state["step_count"] + 1,
        "test_results": state["test_results"]
    }

def conditional_node(state: TestState) -> TestState:
    """æ¡ä»¶å¤„ç†èŠ‚ç‚¹"""
    if len(state["input_data"]) > 10:
        processed = f"é•¿æ–‡æœ¬:{state['input_data'][:10]}..."
    else:
        processed = f"çŸ­æ–‡æœ¬:{state['input_data']}"

    return {
        "input_data": state["input_data"],
        "processed_data": processed,
        "step_count": state["step_count"] + 1,
        "test_results": state["test_results"]
    }

class TestNodeFunctions(LangGraphTestCase):
    """èŠ‚ç‚¹å‡½æ•°æµ‹è¯•"""

    def test_simple_processing_node(self):
        """æµ‹è¯•ç®€å•å¤„ç†èŠ‚ç‚¹"""
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        input_state = {
            "input_data": "æµ‹è¯•æ•°æ®",
            "processed_data": "",
            "step_count": 0,
            "test_results": {}
        }

        # æ‰§è¡ŒèŠ‚ç‚¹
        result = simple_processing_node(input_state)

        # éªŒè¯ç»“æœ
        self.assertEqual(result["processed_data"], "æµ‹è¯•æ•°æ®_å·²å¤„ç†")
        self.assertEqual(result["step_count"], 1)
        self.assertEqual(result["input_data"], "æµ‹è¯•æ•°æ®")

    def test_conditional_node_short_text(self):
        """æµ‹è¯•æ¡ä»¶èŠ‚ç‚¹ - çŸ­æ–‡æœ¬"""
        input_state = {
            "input_data": "çŸ­æ–‡æœ¬",
            "processed_data": "",
            "step_count": 0,
            "test_results": {}
        }

        result = conditional_node(input_state)

        self.assertEqual(result["processed_data"], "çŸ­æ–‡æœ¬:çŸ­æ–‡æœ¬")

    def test_conditional_node_long_text(self):
        """æµ‹è¯•æ¡ä»¶èŠ‚ç‚¹ - é•¿æ–‡æœ¬"""
        input_state = {
            "input_data": "è¿™æ˜¯ä¸€ä¸ªå¾ˆé•¿çš„æ–‡æœ¬è¾“å…¥ç”¨äºæµ‹è¯•",
            "processed_data": "",
            "step_count": 0,
            "test_results": {}
        }

        result = conditional_node(input_state)

        self.assertEqual(result["processed_data"], "é•¿æ–‡æœ¬:è¿™æ˜¯ä¸€ä¸ªå¾ˆé•¿çš„æ–‡æœ¬...")

    def test_node_with_invalid_input(self):
        """æµ‹è¯•æ— æ•ˆè¾“å…¥"""
        input_state = {
            "input_data": None,  # æ— æ•ˆè¾“å…¥
            "processed_data": "",
            "step_count": 0,
            "test_results": {}
        }

        with self.assertRaises(TypeError):
            conditional_node(input_state)

    @pytest.mark.parametrize("input_text,expected_prefix", [
        ("short", "çŸ­æ–‡æœ¬:"),
        ("this is a very long text", "é•¿æ–‡æœ¬:"),
        ("", "çŸ­æ–‡æœ¬:")
    ])
    def test_conditional_node_parametrized(self, input_text, expected_prefix):
        """å‚æ•°åŒ–æµ‹è¯•æ¡ä»¶èŠ‚ç‚¹"""
        input_state = {
            "input_data": input_text,
            "processed_data": "",
            "step_count": 0,
            "test_results": {}
        }

        result = conditional_node(input_state)
        self.assertTrue(result["processed_data"].startswith(expected_prefix))
```

### 2. æ¨¡æ‹Ÿå’Œæ¡©æµ‹è¯•

```python
def external_api_node(state: TestState) -> TestState:
    """è°ƒç”¨å¤–éƒ¨APIçš„èŠ‚ç‚¹"""
    import requests

    try:
        # æ¨¡æ‹ŸAPIè°ƒç”¨
        response = requests.get("https://api.example.com/process",
                              json={"data": state["input_data"]})
        api_result = response.json()

        return {
            "input_data": state["input_data"],
            "processed_data": api_result["result"],
            "step_count": state["step_count"] + 1,
            "test_results": {"api_status": "success"}
        }
    except Exception as e:
        return {
            "input_data": state["input_data"],
            "processed_data": "APIè°ƒç”¨å¤±è´¥",
            "step_count": state["step_count"] + 1,
            "test_results": {"api_status": "failed", "error": str(e)}
        }

class TestExternalAPICalls(LangGraphTestCase):
    """å¤–éƒ¨APIè°ƒç”¨æµ‹è¯•"""

    @patch('requests.get')
    def test_external_api_success(self, mock_get):
        """æµ‹è¯•APIè°ƒç”¨æˆåŠŸ"""
        # è®¾ç½®æ¨¡æ‹Ÿå“åº”
        mock_response = Mock()
        mock_response.json.return_value = {"result": "APIå¤„ç†ç»“æœ"}
        mock_get.return_value = mock_response

        input_state = {
            "input_data": "æµ‹è¯•æ•°æ®",
            "processed_data": "",
            "step_count": 0,
            "test_results": {}
        }

        result = external_api_node(input_state)

        # éªŒè¯APIè¢«æ­£ç¡®è°ƒç”¨
        mock_get.assert_called_once_with(
            "https://api.example.com/process",
            json={"data": "æµ‹è¯•æ•°æ®"}
        )

        # éªŒè¯ç»“æœ
        self.assertEqual(result["processed_data"], "APIå¤„ç†ç»“æœ")
        self.assertEqual(result["test_results"]["api_status"], "success")

    @patch('requests.get')
    def test_external_api_failure(self, mock_get):
        """æµ‹è¯•APIè°ƒç”¨å¤±è´¥"""
        # è®¾ç½®æ¨¡æ‹Ÿå¼‚å¸¸
        mock_get.side_effect = requests.exceptions.ConnectionError("è¿æ¥å¤±è´¥")

        input_state = {
            "input_data": "æµ‹è¯•æ•°æ®",
            "processed_data": "",
            "step_count": 0,
            "test_results": {}
        }

        result = external_api_node(input_state)

        # éªŒè¯é”™è¯¯å¤„ç†
        self.assertEqual(result["processed_data"], "APIè°ƒç”¨å¤±è´¥")
        self.assertEqual(result["test_results"]["api_status"], "failed")
        self.assertIn("è¿æ¥å¤±è´¥", result["test_results"]["error"])

    def test_api_node_with_mock_context(self):
        """ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨çš„æ¨¡æ‹Ÿæµ‹è¯•"""
        with patch('requests.get') as mock_get:
            # è®¾ç½®å¤šæ¬¡è°ƒç”¨çš„ä¸åŒå“åº”
            mock_get.side_effect = [
                Mock(json=lambda: {"result": "ç¬¬ä¸€æ¬¡è°ƒç”¨"}),
                Mock(json=lambda: {"result": "ç¬¬äºŒæ¬¡è°ƒç”¨"})
            ]

            # ç¬¬ä¸€æ¬¡è°ƒç”¨
            result1 = external_api_node(self.test_state)
            self.assertEqual(result1["processed_data"], "ç¬¬ä¸€æ¬¡è°ƒç”¨")

            # ç¬¬äºŒæ¬¡è°ƒç”¨
            result2 = external_api_node(self.test_state)
            self.assertEqual(result2["processed_data"], "ç¬¬äºŒæ¬¡è°ƒç”¨")

            # éªŒè¯è°ƒç”¨æ¬¡æ•°
            self.assertEqual(mock_get.call_count, 2)
```

## ğŸ”§ é›†æˆæµ‹è¯•

### 1. å›¾æ‰§è¡Œæµ‹è¯•

```python
def create_processing_graph():
    """åˆ›å»ºå¤„ç†å›¾"""
    graph = StateGraph(TestState)

    graph.add_node("process", simple_processing_node)
    graph.add_node("condition", conditional_node)

    graph.add_edge(START, "process")
    graph.add_edge("process", "condition")
    graph.add_edge("condition", END)

    return graph.compile()

class TestGraphExecution(LangGraphTestCase):
    """å›¾æ‰§è¡Œæµ‹è¯•"""

    def setUp(self):
        super().setUp()
        self.app = create_processing_graph()

    def test_complete_graph_execution(self):
        """æµ‹è¯•å®Œæ•´å›¾æ‰§è¡Œ"""
        initial_state = {
            "input_data": "é›†æˆæµ‹è¯•",
            "processed_data": "",
            "step_count": 0,
            "test_results": {}
        }

        result = self.app.invoke(initial_state)

        # éªŒè¯æ•´ä¸ªæµç¨‹
        self.assertEqual(result["step_count"], 2)  # ä¸¤ä¸ªèŠ‚ç‚¹éƒ½æ‰§è¡Œäº†
        self.assertIn("å·²å¤„ç†", result["processed_data"])
        self.assertIn("çŸ­æ–‡æœ¬:", result["processed_data"])

    def test_graph_with_different_inputs(self):
        """æµ‹è¯•ä¸åŒè¾“å…¥çš„å›¾æ‰§è¡Œ"""
        test_cases = [
            {
                "input": "çŸ­è¾“å…¥",
                "expected_contains": ["çŸ­æ–‡æœ¬:", "å·²å¤„ç†"]
            },
            {
                "input": "è¿™æ˜¯ä¸€ä¸ªå¾ˆé•¿çš„è¾“å…¥æ•°æ®ç”¨äºæµ‹è¯•å›¾çš„æ‰§è¡Œ",
                "expected_contains": ["é•¿æ–‡æœ¬:", "å·²å¤„ç†"]
            }
        ]

        for case in test_cases:
            with self.subTest(input_data=case["input"]):
                initial_state = {
                    "input_data": case["input"],
                    "processed_data": "",
                    "step_count": 0,
                    "test_results": {}
                }

                result = self.app.invoke(initial_state)

                for expected in case["expected_contains"]:
                    self.assertIn(expected, result["processed_data"])

    def test_graph_streaming(self):
        """æµ‹è¯•å›¾çš„æµå¼æ‰§è¡Œ"""
        initial_state = {
            "input_data": "æµå¼æµ‹è¯•",
            "processed_data": "",
            "step_count": 0,
            "test_results": {}
        }

        events = list(self.app.stream(initial_state))

        # éªŒè¯æµå¼è¾“å‡º
        self.assertGreater(len(events), 0)

        # éªŒè¯æ¯ä¸ªäº‹ä»¶
        node_names = []
        for event in events:
            self.assertIsInstance(event, dict)
            node_names.extend(event.keys())

        self.assertIn("process", node_names)
        self.assertIn("condition", node_names)

    async def test_async_graph_execution(self):
        """æµ‹è¯•å¼‚æ­¥å›¾æ‰§è¡Œ"""
        initial_state = {
            "input_data": "å¼‚æ­¥æµ‹è¯•",
            "processed_data": "",
            "step_count": 0,
            "test_results": {}
        }

        result = await self.app.ainvoke(initial_state)

        self.assertEqual(result["step_count"], 2)
        self.assertIn("å·²å¤„ç†", result["processed_data"])
```

### 2. æ¡ä»¶è·¯ç”±æµ‹è¯•

```python
def routing_condition(state: TestState) -> str:
    """è·¯ç”±æ¡ä»¶å‡½æ•°"""
    if state["step_count"] < 2:
        return "continue"
    elif len(state["input_data"]) > 10:
        return "long_processing"
    else:
        return "short_processing"

def long_processing_node(state: TestState) -> TestState:
    """é•¿æ–‡æœ¬å¤„ç†èŠ‚ç‚¹"""
    return {
        **state,
        "processed_data": f"é•¿æ–‡æœ¬å¤„ç†: {state['input_data'][:20]}...",
        "step_count": state["step_count"] + 1
    }

def short_processing_node(state: TestState) -> TestState:
    """çŸ­æ–‡æœ¬å¤„ç†èŠ‚ç‚¹"""
    return {
        **state,
        "processed_data": f"çŸ­æ–‡æœ¬å¤„ç†: {state['input_data']}",
        "step_count": state["step_count"] + 1
    }

def create_conditional_graph():
    """åˆ›å»ºæ¡ä»¶è·¯ç”±å›¾"""
    graph = StateGraph(TestState)

    graph.add_node("initial", simple_processing_node)
    graph.add_node("long_proc", long_processing_node)
    graph.add_node("short_proc", short_processing_node)

    graph.add_edge(START, "initial")
    graph.add_conditional_edges(
        "initial",
        routing_condition,
        {
            "continue": "initial",  # å¾ªç¯
            "long_processing": "long_proc",
            "short_processing": "short_proc"
        }
    )
    graph.add_edge("long_proc", END)
    graph.add_edge("short_proc", END)

    return graph.compile()

class TestConditionalRouting(LangGraphTestCase):
    """æ¡ä»¶è·¯ç”±æµ‹è¯•"""

    def setUp(self):
        super().setUp()
        self.app = create_conditional_graph()

    def test_short_text_routing(self):
        """æµ‹è¯•çŸ­æ–‡æœ¬è·¯ç”±"""
        initial_state = {
            "input_data": "çŸ­æ–‡æœ¬",
            "processed_data": "",
            "step_count": 0,
            "test_results": {}
        }

        result = self.app.invoke(initial_state)

        self.assertIn("çŸ­æ–‡æœ¬å¤„ç†:", result["processed_data"])
        self.assertEqual(result["step_count"], 3)  # initialæ‰§è¡Œ2æ¬¡ + short_procæ‰§è¡Œ1æ¬¡

    def test_long_text_routing(self):
        """æµ‹è¯•é•¿æ–‡æœ¬è·¯ç”±"""
        initial_state = {
            "input_data": "è¿™æ˜¯ä¸€ä¸ªå¾ˆé•¿çš„æ–‡æœ¬ç”¨äºæµ‹è¯•æ¡ä»¶è·¯ç”±åŠŸèƒ½",
            "processed_data": "",
            "step_count": 0,
            "test_results": {}
        }

        result = self.app.invoke(initial_state)

        self.assertIn("é•¿æ–‡æœ¬å¤„ç†:", result["processed_data"])
        self.assertEqual(result["step_count"], 3)

    def test_routing_condition_directly(self):
        """ç›´æ¥æµ‹è¯•è·¯ç”±æ¡ä»¶å‡½æ•°"""
        # æµ‹è¯•ä¸åŒçš„è·¯ç”±æ¡ä»¶
        test_cases = [
            {
                "state": {"step_count": 0, "input_data": "test"},
                "expected": "continue"
            },
            {
                "state": {"step_count": 1, "input_data": "test"},
                "expected": "continue"
            },
            {
                "state": {"step_count": 2, "input_data": "short"},
                "expected": "short_processing"
            },
            {
                "state": {"step_count": 2, "input_data": "very long text for testing"},
                "expected": "long_processing"
            }
        ]

        for case in test_cases:
            with self.subTest(state=case["state"]):
                result = routing_condition(case["state"])
                self.assertEqual(result, case["expected"])
```

## ğŸ¤– LLM é›†æˆæµ‹è¯•

### 1. æ¨¡æ‹Ÿ LLM å“åº”

```python
from langchain_core.messages import HumanMessage, AIMessage
from unittest.mock import AsyncMock

class MockLLM:
    """æ¨¡æ‹Ÿ LLM"""

    def __init__(self, responses: List[str]):
        self.responses = responses
        self.call_count = 0

    def invoke(self, messages):
        """åŒæ­¥è°ƒç”¨"""
        if self.call_count < len(self.responses):
            response = self.responses[self.call_count]
            self.call_count += 1
            return AIMessage(content=response)
        else:
            return AIMessage(content="é»˜è®¤å“åº”")

    async def ainvoke(self, messages):
        """å¼‚æ­¥è°ƒç”¨"""
        return self.invoke(messages)

def llm_processing_node(state: TestState) -> TestState:
    """LLM å¤„ç†èŠ‚ç‚¹"""
    from langchain_openai import ChatOpenAI

    # åœ¨å®é™…ä½¿ç”¨ä¸­ä¼šæ˜¯çœŸå®çš„LLM
    # llm = ChatOpenAI(model="gpt-3.5-turbo")

    # æµ‹è¯•ä¸­ä½¿ç”¨æ¨¡æ‹ŸLLM
    llm = state.get("mock_llm")
    if not llm:
        raise ValueError("æµ‹è¯•ä¸­éœ€è¦æä¾›mock_llm")

    messages = [HumanMessage(content=f"å¤„ç†è¿™ä¸ªæ–‡æœ¬: {state['input_data']}")]
    response = llm.invoke(messages)

    return {
        **state,
        "processed_data": response.content,
        "step_count": state["step_count"] + 1
    }

class TestLLMIntegration(LangGraphTestCase):
    """LLM é›†æˆæµ‹è¯•"""

    def test_llm_node_with_mock(self):
        """æµ‹è¯•å¸¦æ¨¡æ‹ŸLLMçš„èŠ‚ç‚¹"""
        mock_llm = MockLLM(["è¿™æ˜¯æ¨¡æ‹Ÿçš„LLMå“åº”"])

        input_state = {
            "input_data": "æµ‹è¯•è¾“å…¥",
            "processed_data": "",
            "step_count": 0,
            "test_results": {},
            "mock_llm": mock_llm
        }

        result = llm_processing_node(input_state)

        self.assertEqual(result["processed_data"], "è¿™æ˜¯æ¨¡æ‹Ÿçš„LLMå“åº”")
        self.assertEqual(mock_llm.call_count, 1)

    def test_llm_node_multiple_calls(self):
        """æµ‹è¯•å¤šæ¬¡LLMè°ƒç”¨"""
        mock_llm = MockLLM([
            "ç¬¬ä¸€æ¬¡å“åº”",
            "ç¬¬äºŒæ¬¡å“åº”",
            "ç¬¬ä¸‰æ¬¡å“åº”"
        ])

        base_state = {
            "input_data": "æµ‹è¯•",
            "processed_data": "",
            "step_count": 0,
            "test_results": {},
            "mock_llm": mock_llm
        }

        # å¤šæ¬¡è°ƒç”¨
        for i, expected_response in enumerate(["ç¬¬ä¸€æ¬¡å“åº”", "ç¬¬äºŒæ¬¡å“åº”", "ç¬¬ä¸‰æ¬¡å“åº”"]):
            with self.subTest(call_number=i+1):
                result = llm_processing_node(base_state)
                self.assertEqual(result["processed_data"], expected_response)

    @patch('langchain_openai.ChatOpenAI')
    def test_llm_with_real_integration(self, mock_openai):
        """æµ‹è¯•ä¸çœŸå®LLMçš„é›†æˆï¼ˆä½¿ç”¨patchï¼‰"""
        # è®¾ç½®æ¨¡æ‹Ÿçš„ChatOpenAI
        mock_instance = Mock()
        mock_instance.invoke.return_value = AIMessage(content="çœŸå®é›†æˆæµ‹è¯•å“åº”")
        mock_openai.return_value = mock_instance

        # ä¿®æ”¹èŠ‚ç‚¹ä»¥ä½¿ç”¨çœŸå®LLM
        def real_llm_node(state: TestState) -> TestState:
            from langchain_openai import ChatOpenAI
            llm = ChatOpenAI(model="gpt-3.5-turbo")
            messages = [HumanMessage(content=f"å¤„ç†: {state['input_data']}")]
            response = llm.invoke(messages)

            return {
                **state,
                "processed_data": response.content,
                "step_count": state["step_count"] + 1
            }

        result = real_llm_node(self.test_state)

        # éªŒè¯ChatOpenAIè¢«æ­£ç¡®è°ƒç”¨
        mock_openai.assert_called_once_with(model="gpt-3.5-turbo")
        self.assertEqual(result["processed_data"], "çœŸå®é›†æˆæµ‹è¯•å“åº”")
```

### 2. LLM å“åº”è´¨é‡æµ‹è¯•

```python
import re
from typing import List, Dict

class LLMResponseValidator:
    """LLMå“åº”éªŒè¯å™¨"""

    @staticmethod
    def validate_response_format(response: str, expected_format: str) -> bool:
        """éªŒè¯å“åº”æ ¼å¼"""
        format_patterns = {
            "json": r'^\s*\{.*\}\s*$',
            "list": r'^\s*\[.*\]\s*$',
            "numbered_list": r'^\s*\d+\..*',
            "bullet_list": r'^\s*[-*â€¢].*'
        }

        pattern = format_patterns.get(expected_format)
        if not pattern:
            return True  # æœªçŸ¥æ ¼å¼ï¼Œè·³è¿‡éªŒè¯

        return bool(re.search(pattern, response, re.DOTALL))

    @staticmethod
    def validate_response_content(response: str, required_keywords: List[str]) -> Dict[str, bool]:
        """éªŒè¯å“åº”å†…å®¹"""
        results = {}
        response_lower = response.lower()

        for keyword in required_keywords:
            results[keyword] = keyword.lower() in response_lower

        return results

    @staticmethod
    def validate_response_length(response: str, min_length: int = 10, max_length: int = 1000) -> bool:
        """éªŒè¯å“åº”é•¿åº¦"""
        return min_length <= len(response) <= max_length

def llm_quality_test_node(state: TestState) -> TestState:
    """LLMè´¨é‡æµ‹è¯•èŠ‚ç‚¹"""
    mock_llm = state.get("mock_llm")
    validator = LLMResponseValidator()

    messages = [HumanMessage(content=f"åˆ†æè¿™ä¸ªæ–‡æœ¬: {state['input_data']}")]
    response = mock_llm.invoke(messages)

    # è´¨é‡éªŒè¯
    quality_results = {
        "format_valid": validator.validate_response_format(response.content, "text"),
        "length_valid": validator.validate_response_length(response.content),
        "content_check": validator.validate_response_content(
            response.content,
            ["åˆ†æ", "æ–‡æœ¬", "ç»“æœ"]
        )
    }

    return {
        **state,
        "processed_data": response.content,
        "test_results": {"quality": quality_results},
        "step_count": state["step_count"] + 1
    }

class TestLLMResponseQuality(LangGraphTestCase):
    """LLMå“åº”è´¨é‡æµ‹è¯•"""

    def test_response_format_validation(self):
        """æµ‹è¯•å“åº”æ ¼å¼éªŒè¯"""
        validator = LLMResponseValidator()

        test_cases = [
            ("{'key': 'value'}", "json", True),
            ("[1, 2, 3]", "list", True),
            ("1. ç¬¬ä¸€é¡¹\\n2. ç¬¬äºŒé¡¹", "numbered_list", True),
            ("â€¢ é¡¹ç›®ä¸€\\nâ€¢ é¡¹ç›®äºŒ", "bullet_list", True),
            ("æ™®é€šæ–‡æœ¬", "json", False)
        ]

        for response, format_type, expected in test_cases:
            with self.subTest(response=response, format_type=format_type):
                result = validator.validate_response_format(response, format_type)
                self.assertEqual(result, expected)

    def test_response_content_validation(self):
        """æµ‹è¯•å“åº”å†…å®¹éªŒè¯"""
        validator = LLMResponseValidator()

        response = "è¿™æ˜¯ä¸€ä¸ªå…³äºæ–‡æœ¬åˆ†æçš„è¯¦ç»†ç»“æœæŠ¥å‘Š"
        required_keywords = ["æ–‡æœ¬", "åˆ†æ", "ç»“æœ", "æŠ¥å‘Š"]

        results = validator.validate_response_content(response, required_keywords)

        # éªŒè¯æ‰€æœ‰å…³é”®è¯éƒ½è¢«æ‰¾åˆ°
        for keyword in required_keywords:
            self.assertTrue(results[keyword], f"å…³é”®è¯ '{keyword}' æœªæ‰¾åˆ°")

    def test_llm_quality_node(self):
        """æµ‹è¯•LLMè´¨é‡èŠ‚ç‚¹"""
        mock_llm = MockLLM([
            "è¿™æ˜¯ä¸€ä¸ªè¯¦ç»†çš„æ–‡æœ¬åˆ†æç»“æœï¼ŒåŒ…å«äº†å¤šé¡¹é‡è¦ä¿¡æ¯"
        ])

        input_state = {
            "input_data": "å¾…åˆ†æçš„æ–‡æœ¬",
            "processed_data": "",
            "step_count": 0,
            "test_results": {},
            "mock_llm": mock_llm
        }

        result = llm_quality_test_node(input_state)

        # éªŒè¯è´¨é‡æ£€æŸ¥ç»“æœ
        quality = result["test_results"]["quality"]
        self.assertTrue(quality["format_valid"])
        self.assertTrue(quality["length_valid"])

        # éªŒè¯å†…å®¹æ£€æŸ¥
        content_check = quality["content_check"]
        self.assertTrue(content_check["åˆ†æ"])
        self.assertTrue(content_check["æ–‡æœ¬"])
        self.assertTrue(content_check["ç»“æœ"])
```

## ğŸ“Š æ€§èƒ½æµ‹è¯•

### 1. æ‰§è¡Œæ—¶é—´æµ‹è¯•

```python
import time
from concurrent.futures import ThreadPoolExecutor, as_completed

class PerformanceTestCase(LangGraphTestCase):
    """æ€§èƒ½æµ‹è¯•åŸºç±»"""

    def time_execution(self, func, *args, **kwargs):
        """æµ‹é‡æ‰§è¡Œæ—¶é—´"""
        start_time = time.time()
        result = func(*args, **kwargs)
        execution_time = time.time() - start_time
        return result, execution_time

    def assert_execution_time(self, func, max_time: float, *args, **kwargs):
        """æ–­è¨€æ‰§è¡Œæ—¶é—´"""
        result, execution_time = self.time_execution(func, *args, **kwargs)
        self.assertLessEqual(
            execution_time,
            max_time,
            f"æ‰§è¡Œæ—¶é—´ {execution_time:.3f}s è¶…è¿‡é™åˆ¶ {max_time}s"
        )
        return result

class TestGraphPerformance(PerformanceTestCase):
    """å›¾æ€§èƒ½æµ‹è¯•"""

    def test_single_execution_performance(self):
        """æµ‹è¯•å•æ¬¡æ‰§è¡Œæ€§èƒ½"""
        app = create_processing_graph()

        def execute_graph():
            return app.invoke({
                "input_data": "æ€§èƒ½æµ‹è¯•æ•°æ®",
                "processed_data": "",
                "step_count": 0,
                "test_results": {}
            })

        # æ‰§è¡Œæ—¶é—´åº”è¯¥åœ¨1ç§’å†…
        result = self.assert_execution_time(execute_graph, 1.0)
        self.assertEqual(result["step_count"], 2)

    def test_batch_execution_performance(self):
        """æµ‹è¯•æ‰¹é‡æ‰§è¡Œæ€§èƒ½"""
        app = create_processing_graph()

        def execute_batch(batch_size: int):
            results = []
            for i in range(batch_size):
                result = app.invoke({
                    "input_data": f"æµ‹è¯•æ•°æ®_{i}",
                    "processed_data": "",
                    "step_count": 0,
                    "test_results": {}
                })
                results.append(result)
            return results

        # 10æ¬¡æ‰§è¡Œåº”è¯¥åœ¨5ç§’å†…å®Œæˆ
        results = self.assert_execution_time(execute_batch, 5.0, 10)
        self.assertEqual(len(results), 10)

    def test_concurrent_execution_performance(self):
        """æµ‹è¯•å¹¶å‘æ‰§è¡Œæ€§èƒ½"""
        app = create_processing_graph()

        def single_execution(index: int):
            return app.invoke({
                "input_data": f"å¹¶å‘æµ‹è¯•_{index}",
                "processed_data": "",
                "step_count": 0,
                "test_results": {}
            })

        def concurrent_execution(num_threads: int):
            with ThreadPoolExecutor(max_workers=num_threads) as executor:
                futures = [executor.submit(single_execution, i) for i in range(num_threads)]
                results = [future.result() for future in as_completed(futures)]
            return results

        # 5ä¸ªå¹¶å‘æ‰§è¡Œåº”è¯¥åœ¨3ç§’å†…å®Œæˆ
        results = self.assert_execution_time(concurrent_execution, 3.0, 5)
        self.assertEqual(len(results), 5)
```

### 2. å†…å­˜ä½¿ç”¨æµ‹è¯•

```python
import psutil
import gc

class MemoryTestCase(LangGraphTestCase):
    """å†…å­˜æµ‹è¯•åŸºç±»"""

    def setUp(self):
        super().setUp()
        gc.collect()  # å¼ºåˆ¶åƒåœ¾å›æ”¶
        self.initial_memory = self.get_memory_usage()

    def get_memory_usage(self) -> float:
        """è·å–å½“å‰å†…å­˜ä½¿ç”¨é‡ï¼ˆMBï¼‰"""
        process = psutil.Process()
        return process.memory_info().rss / 1024 / 1024

    def assert_memory_increase(self, func, max_increase_mb: float, *args, **kwargs):
        """æ–­è¨€å†…å­˜å¢é•¿"""
        memory_before = self.get_memory_usage()
        result = func(*args, **kwargs)
        gc.collect()
        memory_after = self.get_memory_usage()

        memory_increase = memory_after - memory_before
        self.assertLessEqual(
            memory_increase,
            max_increase_mb,
            f"å†…å­˜å¢é•¿ {memory_increase:.2f}MB è¶…è¿‡é™åˆ¶ {max_increase_mb}MB"
        )
        return result

class TestGraphMemoryUsage(MemoryTestCase):
    """å›¾å†…å­˜ä½¿ç”¨æµ‹è¯•"""

    def test_single_execution_memory(self):
        """æµ‹è¯•å•æ¬¡æ‰§è¡Œå†…å­˜ä½¿ç”¨"""
        app = create_processing_graph()

        def execute_with_large_data():
            large_data = "å¤§æ•°æ®" * 10000  # åˆ›å»ºè¾ƒå¤§çš„æ•°æ®
            return app.invoke({
                "input_data": large_data,
                "processed_data": "",
                "step_count": 0,
                "test_results": {}
            })

        # å†…å­˜å¢é•¿åº”è¯¥ä¸è¶…è¿‡10MB
        result = self.assert_memory_increase(execute_with_large_data, 10.0)
        self.assertIn("å·²å¤„ç†", result["processed_data"])

    def test_repeated_execution_memory_leak(self):
        """æµ‹è¯•é‡å¤æ‰§è¡Œçš„å†…å­˜æ³„æ¼"""
        app = create_processing_graph()

        def repeated_execution(count: int):
            results = []
            for i in range(count):
                result = app.invoke({
                    "input_data": f"é‡å¤æµ‹è¯•_{i}",
                    "processed_data": "",
                    "step_count": 0,
                    "test_results": {}
                })
                results.append(result)

                # å®šæœŸæ¸…ç†
                if i % 10 == 0:
                    gc.collect()

            return results

        # 100æ¬¡é‡å¤æ‰§è¡Œï¼Œå†…å­˜å¢é•¿åº”è¯¥æ§åˆ¶åœ¨20MBå†…
        results = self.assert_memory_increase(repeated_execution, 20.0, 100)
        self.assertEqual(len(results), 100)
```

## ğŸš€ æŒç»­é›†æˆæµ‹è¯•

### 1. æµ‹è¯•é…ç½®æ–‡ä»¶

```python
# pytest.ini é…ç½®
"""
[tool:pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
addopts =
    --verbose
    --tb=short
    --cov=src
    --cov-report=html
    --cov-report=term
    --asyncio-mode=auto
markers =
    unit: å•å…ƒæµ‹è¯•
    integration: é›†æˆæµ‹è¯•
    performance: æ€§èƒ½æµ‹è¯•
    llm: LLMç›¸å…³æµ‹è¯•
"""

# conftest.py - pytesté…ç½®
import pytest
import asyncio
from typing import Generator

@pytest.fixture(scope="session")
def event_loop() -> Generator:
    """åˆ›å»ºäº‹ä»¶å¾ªç¯"""
    loop = asyncio.get_event_loop_policy().new_event_loop()
    yield loop
    loop.close()

@pytest.fixture
def test_data_manager():
    """æµ‹è¯•æ•°æ®ç®¡ç†å™¨å¤¹å…·"""
    return TestDataManager()

@pytest.fixture
def mock_llm():
    """æ¨¡æ‹ŸLLMå¤¹å…·"""
    return MockLLM(["é»˜è®¤æµ‹è¯•å“åº”"])

@pytest.fixture(autouse=True)
def setup_test_environment():
    """è‡ªåŠ¨è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
    # æµ‹è¯•å‰è®¾ç½®
    import os
    os.environ["TESTING"] = "true"

    yield

    # æµ‹è¯•åæ¸…ç†
    if "TESTING" in os.environ:
        del os.environ["TESTING"]
```

### 2. GitHub Actions é…ç½®

```yaml
# .github/workflows/test.yml
name: LangGraph Tests

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.9, 3.10, 3.11]

    steps:
    - uses: actions/checkout@v3

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v3
      with:
        python-version: ${{ matrix.python-version }}

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pytest pytest-cov pytest-asyncio
        pip install -r requirements.txt

    - name: Run unit tests
      run: |
        pytest tests/unit -m "unit" --cov=src --cov-report=xml

    - name: Run integration tests
      run: |
        pytest tests/integration -m "integration"

    - name: Run performance tests
      run: |
        pytest tests/performance -m "performance" --timeout=60

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
```

## ğŸ“ˆ æµ‹è¯•æŒ‡æ ‡å’ŒæŠ¥å‘Š

### 1. æµ‹è¯•è¦†ç›–ç‡åˆ†æ

```python
import coverage
import json
from pathlib import Path

class TestCoverageAnalyzer:
    """æµ‹è¯•è¦†ç›–ç‡åˆ†æå™¨"""

    def __init__(self):
        self.cov = coverage.Coverage()

    def start_coverage(self):
        """å¼€å§‹è¦†ç›–ç‡æµ‹é‡"""
        self.cov.start()

    def stop_coverage(self):
        """åœæ­¢è¦†ç›–ç‡æµ‹é‡"""
        self.cov.stop()
        self.cov.save()

    def generate_report(self, output_dir: str = "coverage_report"):
        """ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š"""
        Path(output_dir).mkdir(exist_ok=True)

        # HTMLæŠ¥å‘Š
        self.cov.html_report(directory=output_dir)

        # JSONæŠ¥å‘Š
        json_file = Path(output_dir) / "coverage.json"
        with open(json_file, 'w') as f:
            json.dump(self.cov.get_data().to_json(), f, indent=2)

        # æ§åˆ¶å°æŠ¥å‘Š
        print("\nğŸ“Š æµ‹è¯•è¦†ç›–ç‡æŠ¥å‘Š:")
        self.cov.report()

    def get_coverage_summary(self) -> dict:
        """è·å–è¦†ç›–ç‡æ‘˜è¦"""
        report = self.cov.report(show_missing=False)
        return {
            "statements": self.cov.get_data().line_counts(),
            "missing": self.cov.get_data().missing_lines(),
            "coverage_percent": report
        }

# ä½¿ç”¨ç¤ºä¾‹
def run_tests_with_coverage():
    """è¿è¡Œå¸¦è¦†ç›–ç‡çš„æµ‹è¯•"""
    analyzer = TestCoverageAnalyzer()

    analyzer.start_coverage()

    try:
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        import unittest
        loader = unittest.TestLoader()
        suite = loader.discover('tests')
        runner = unittest.TextTestRunner(verbosity=2)
        result = runner.run(suite)

    finally:
        analyzer.stop_coverage()
        analyzer.generate_report()
        summary = analyzer.get_coverage_summary()
        print(f"æ€»ä½“è¦†ç›–ç‡: {summary['coverage_percent']}%")
```

### 2. æµ‹è¯•æŠ¥å‘Šç”Ÿæˆ

```python
import json
import html
from datetime import datetime
from typing import List, Dict

class TestReportGenerator:
    """æµ‹è¯•æŠ¥å‘Šç”Ÿæˆå™¨"""

    def __init__(self):
        self.test_results = []
        self.start_time = None
        self.end_time = None

    def start_test_run(self):
        """å¼€å§‹æµ‹è¯•è¿è¡Œ"""
        self.start_time = datetime.now()
        self.test_results = []

    def add_test_result(self, test_name: str, status: str, duration: float,
                       error_message: str = None, details: dict = None):
        """æ·»åŠ æµ‹è¯•ç»“æœ"""
        result = {
            "test_name": test_name,
            "status": status,  # "passed", "failed", "skipped"
            "duration": duration,
            "timestamp": datetime.now().isoformat(),
            "error_message": error_message,
            "details": details or {}
        }
        self.test_results.append(result)

    def end_test_run(self):
        """ç»“æŸæµ‹è¯•è¿è¡Œ"""
        self.end_time = datetime.now()

    def generate_html_report(self, output_file: str = "test_report.html"):
        """ç”ŸæˆHTMLæµ‹è¯•æŠ¥å‘Š"""
        total_tests = len(self.test_results)
        passed_tests = len([r for r in self.test_results if r["status"] == "passed"])
        failed_tests = len([r for r in self.test_results if r["status"] == "failed"])
        skipped_tests = len([r for r in self.test_results if r["status"] == "skipped"])

        total_duration = sum(r["duration"] for r in self.test_results)
        run_duration = (self.end_time - self.start_time).total_seconds() if self.end_time else 0

        html_content = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>LangGraph æµ‹è¯•æŠ¥å‘Š</title>
            <style>
                body {{ font-family: Arial, sans-serif; margin: 20px; }}
                .summary {{ background-color: #f0f0f0; padding: 15px; margin-bottom: 20px; }}
                .passed {{ color: green; }}
                .failed {{ color: red; }}
                .skipped {{ color: orange; }}
                table {{ border-collapse: collapse; width: 100%; }}
                th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
                th {{ background-color: #f2f2f2; }}
                .error {{ background-color: #ffe6e6; }}
            </style>
        </head>
        <body>
            <h1>LangGraph æµ‹è¯•æŠ¥å‘Š</h1>

            <div class="summary">
                <h2>æµ‹è¯•æ‘˜è¦</h2>
                <p><strong>æ€»æµ‹è¯•æ•°:</strong> {total_tests}</p>
                <p><strong class="passed">é€šè¿‡:</strong> {passed_tests}</p>
                <p><strong class="failed">å¤±è´¥:</strong> {failed_tests}</p>
                <p><strong class="skipped">è·³è¿‡:</strong> {skipped_tests}</p>
                <p><strong>æˆåŠŸç‡:</strong> {(passed_tests/total_tests*100):.1f}%</p>
                <p><strong>æ€»æ‰§è¡Œæ—¶é—´:</strong> {total_duration:.2f}s</p>
                <p><strong>è¿è¡Œæ—¶é—´:</strong> {run_duration:.2f}s</p>
                <p><strong>å¼€å§‹æ—¶é—´:</strong> {self.start_time.strftime('%Y-%m-%d %H:%M:%S')}</p>
                <p><strong>ç»“æŸæ—¶é—´:</strong> {self.end_time.strftime('%Y-%m-%d %H:%M:%S') if self.end_time else 'N/A'}</p>
            </div>

            <h2>è¯¦ç»†ç»“æœ</h2>
            <table>
                <tr>
                    <th>æµ‹è¯•åç§°</th>
                    <th>çŠ¶æ€</th>
                    <th>æ‰§è¡Œæ—¶é—´ (s)</th>
                    <th>é”™è¯¯ä¿¡æ¯</th>
                </tr>
        """

        for result in self.test_results:
            status_class = result["status"]
            error_display = html.escape(result["error_message"] or "") if result["error_message"] else ""

            html_content += f"""
                <tr class="{status_class}">
                    <td>{html.escape(result['test_name'])}</td>
                    <td><strong class="{status_class}">{result['status'].upper()}</strong></td>
                    <td>{result['duration']:.3f}</td>
                    <td class="{'error' if result['error_message'] else ''}">{error_display}</td>
                </tr>
            """

        html_content += """
            </table>
        </body>
        </html>
        """

        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(html_content)

        print(f"ğŸ“„ HTMLæŠ¥å‘Šå·²ç”Ÿæˆ: {output_file}")

    def generate_json_report(self, output_file: str = "test_report.json"):
        """ç”ŸæˆJSONæµ‹è¯•æŠ¥å‘Š"""
        report = {
            "start_time": self.start_time.isoformat() if self.start_time else None,
            "end_time": self.end_time.isoformat() if self.end_time else None,
            "total_duration": (self.end_time - self.start_time).total_seconds() if self.end_time and self.start_time else 0,
            "summary": {
                "total": len(self.test_results),
                "passed": len([r for r in self.test_results if r["status"] == "passed"]),
                "failed": len([r for r in self.test_results if r["status"] == "failed"]),
                "skipped": len([r for r in self.test_results if r["status"] == "skipped"])
            },
            "results": self.test_results
        }

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)

        print(f"ğŸ“Š JSONæŠ¥å‘Šå·²ç”Ÿæˆ: {output_file}")
```

## ğŸ¯ æµ‹è¯•æœ€ä½³å®è·µæ€»ç»“

### 1. æµ‹è¯•ç­–ç•¥æ£€æŸ¥æ¸…å•

```python
def testing_strategy_checklist():
    """æµ‹è¯•ç­–ç•¥æ£€æŸ¥æ¸…å•"""
    checklist = [
        "âœ… æ¯ä¸ªèŠ‚ç‚¹å‡½æ•°éƒ½æœ‰å•å…ƒæµ‹è¯•",
        "âœ… å›¾çš„æ‰§è¡Œè·¯å¾„éƒ½æœ‰é›†æˆæµ‹è¯•",
        "âœ… æ¡ä»¶è·¯ç”±é€»è¾‘éƒ½æœ‰æµ‹è¯•è¦†ç›–",
        "âœ… å¤–éƒ¨ä¾èµ–éƒ½ä½¿ç”¨äº†æ¨¡æ‹Ÿ",
        "âœ… LLMå“åº”è´¨é‡æœ‰éªŒè¯æœºåˆ¶",
        "âœ… æ€§èƒ½å…³é”®è·¯å¾„æœ‰æ€§èƒ½æµ‹è¯•",
        "âœ… å†…å­˜ä½¿ç”¨æœ‰ç›‘æ§å’Œé™åˆ¶",
        "âœ… é”™è¯¯æƒ…å†µéƒ½æœ‰æµ‹è¯•è¦†ç›–",
        "âœ… å¼‚æ­¥æ‰§è¡Œæœ‰ä¸“é—¨æµ‹è¯•",
        "âœ… æµ‹è¯•æ•°æ®ç®¡ç†è§„èŒƒåŒ–",
        "âœ… æŒç»­é›†æˆé…ç½®å®Œå–„",
        "âœ… æµ‹è¯•æŠ¥å‘Šè‡ªåŠ¨ç”Ÿæˆ"
    ]

    print("ğŸ§ª æµ‹è¯•ç­–ç•¥æ£€æŸ¥æ¸…å•:")
    for item in checklist:
        print(f"  {item}")

testing_strategy_checklist()
```

## ğŸ“š å»¶ä¼¸é˜…è¯»

- [pytest å®˜æ–¹æ–‡æ¡£](https://docs.pytest.org/)
- [Python unittest æŒ‡å—](https://docs.python.org/3/library/unittest.html)
- [LangSmith è¯„ä¼°æ–‡æ¡£](https://docs.smith.langchain.com/)
- [è½¯ä»¶æµ‹è¯•æœ€ä½³å®è·µ](https://testing.googleblog.com/)

---

ğŸ’¡ **å°è´´å£«**ï¼šå¥½çš„æµ‹è¯•æ˜¯ä»£ç è´¨é‡çš„ä¿è¯ã€‚æŠ•å…¥æ—¶é—´ç¼–å†™å…¨é¢çš„æµ‹è¯•ï¼Œä¼šåœ¨é•¿æœŸå¼€å‘ä¸­èŠ‚çœå¤§é‡è°ƒè¯•æ—¶é—´ï¼