#!/usr/bin/env python3
"""
LangGraph æ€§èƒ½æµ‹è¯•ç¤ºä¾‹ä»£ç 

æ¼”ç¤ºæ€§èƒ½ä¼˜åŒ–æŠ€å·§å’Œæ€§èƒ½æµ‹è¯•æ–¹æ³•ã€‚
"""

from typing import TypedDict, List, Dict, Any, Annotated
from langgraph import StateGraph, START, END
import time
import asyncio
import threading
import psutil
import gc
from operator import add
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass
from datetime import datetime
import json

# æ€§èƒ½æµ‹è¯•çŠ¶æ€
class PerformanceState(TypedDict):
    input_data: str
    results: Annotated[List[str], add]  # ä½¿ç”¨ reducer æ”¯æŒå¹¶è¡Œ
    performance_metrics: Dict[str, Any]
    execution_count: int

@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡"""
    execution_time: float
    memory_usage_mb: float
    cpu_percent: float
    node_name: str
    timestamp: str

class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨"""

    def __init__(self):
        self.metrics: List[PerformanceMetrics] = []
        self.start_memory = None

    def start_monitoring(self):
        """å¼€å§‹ç›‘æ§"""
        gc.collect()  # å¼ºåˆ¶åƒåœ¾å›æ”¶
        self.start_memory = psutil.virtual_memory().used / 1024 / 1024

    def record_metrics(self, node_name: str, execution_time: float):
        """è®°å½•æ€§èƒ½æŒ‡æ ‡"""
        current_memory = psutil.virtual_memory().used / 1024 / 1024
        memory_usage = current_memory - (self.start_memory or current_memory)

        metrics = PerformanceMetrics(
            execution_time=execution_time,
            memory_usage_mb=memory_usage,
            cpu_percent=psutil.cpu_percent(),
            node_name=node_name,
            timestamp=datetime.now().isoformat()
        )

        self.metrics.append(metrics)
        return metrics

    def get_summary(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æ‘˜è¦"""
        if not self.metrics:
            return {}

        total_time = sum(m.execution_time for m in self.metrics)
        avg_memory = sum(m.memory_usage_mb for m in self.metrics) / len(self.metrics)
        max_memory = max(m.memory_usage_mb for m in self.metrics)

        return {
            "total_execution_time": total_time,
            "average_memory_usage_mb": avg_memory,
            "peak_memory_usage_mb": max_memory,
            "total_measurements": len(self.metrics),
            "node_performance": self._get_node_performance()
        }

    def _get_node_performance(self) -> Dict[str, Dict[str, float]]:
        """è·å–èŠ‚ç‚¹æ€§èƒ½åˆ†æ"""
        node_metrics = {}

        for metric in self.metrics:
            if metric.node_name not in node_metrics:
                node_metrics[metric.node_name] = {
                    "total_time": 0,
                    "count": 0,
                    "max_time": 0,
                    "min_time": float('inf')
                }

            node_data = node_metrics[metric.node_name]
            node_data["total_time"] += metric.execution_time
            node_data["count"] += 1
            node_data["max_time"] = max(node_data["max_time"], metric.execution_time)
            node_data["min_time"] = min(node_data["min_time"], metric.execution_time)

        # è®¡ç®—å¹³å‡å€¼
        for node_name, data in node_metrics.items():
            data["avg_time"] = data["total_time"] / data["count"]

        return node_metrics

# å…¨å±€æ€§èƒ½ç›‘æ§å™¨
perf_monitor = PerformanceMonitor()

def performance_test(node_name: str):
    """æ€§èƒ½æµ‹è¯•è£…é¥°å™¨"""
    def decorator(func):
        def wrapper(state):
            start_time = time.time()

            try:
                result = func(state)
                execution_time = time.time() - start_time

                # è®°å½•æ€§èƒ½æŒ‡æ ‡
                metrics = perf_monitor.record_metrics(node_name, execution_time)

                # æ·»åŠ æ€§èƒ½æ•°æ®åˆ°çŠ¶æ€
                performance_metrics = result.get('performance_metrics', {})
                performance_metrics[node_name] = {
                    "execution_time": execution_time,
                    "memory_usage_mb": metrics.memory_usage_mb,
                    "timestamp": metrics.timestamp
                }
                result['performance_metrics'] = performance_metrics

                return result

            except Exception as e:
                execution_time = time.time() - start_time
                perf_monitor.record_metrics(f"{node_name}_failed", execution_time)
                raise

        return wrapper
    return decorator

@performance_test("cpu_intensive")
def cpu_intensive_node(state: PerformanceState) -> PerformanceState:
    """CPUå¯†é›†å‹èŠ‚ç‚¹"""
    print(f"ğŸ”„ CPUå¯†é›†å‹å¤„ç†å¼€å§‹...")

    # æ¨¡æ‹ŸCPUå¯†é›†å‹æ“ä½œ
    result = 0
    iterations = 1000000

    for i in range(iterations):
        result += i * i

    # æ¨¡æ‹Ÿæ›´å¤æ‚çš„è®¡ç®—
    data = state.get('input_data', '')
    processed_result = f"CPUå¤„ç†ç»“æœ: {result}, æ•°æ®é•¿åº¦: {len(data)}"

    return {
        **state,
        "results": [processed_result],
        "execution_count": state.get("execution_count", 0) + 1
    }

@performance_test("optimized_cpu")
def optimized_cpu_node(state: PerformanceState) -> PerformanceState:
    """ä¼˜åŒ–åçš„CPUå¯†é›†å‹èŠ‚ç‚¹"""
    print(f"âš¡ ä¼˜åŒ–CPUå¤„ç†å¼€å§‹...")

    # ä½¿ç”¨æ•°å­¦å…¬å¼ä»£æ›¿å¾ªç¯
    n = 1000000
    result = n * (n - 1) * (2 * n - 1) // 6  # å¹³æ–¹å’Œå…¬å¼

    data = state.get('input_data', '')
    processed_result = f"ä¼˜åŒ–CPUå¤„ç†ç»“æœ: {result}, æ•°æ®é•¿åº¦: {len(data)}"

    return {
        **state,
        "results": [processed_result],
        "execution_count": state.get("execution_count", 0) + 1
    }

@performance_test("io_intensive")
def io_intensive_node(state: PerformanceState) -> PerformanceState:
    """IOå¯†é›†å‹èŠ‚ç‚¹"""
    print(f"ğŸ’¾ IOå¯†é›†å‹å¤„ç†å¼€å§‹...")

    # æ¨¡æ‹ŸIOæ“ä½œ
    time.sleep(0.5)  # æ¨¡æ‹Ÿç½‘ç»œIO

    # æ¨¡æ‹Ÿæ–‡ä»¶æ“ä½œ
    import tempfile
    import os

    temp_data = state.get('input_data', '') * 1000
    with tempfile.NamedTemporaryFile(mode='w', delete=False) as f:
        f.write(temp_data)
        temp_file = f.name

    # è¯»å–æ–‡ä»¶
    with open(temp_file, 'r') as f:
        file_content = f.read()

    # æ¸…ç†
    os.unlink(temp_file)

    processed_result = f"IOå¤„ç†ç»“æœ: å¤„ç†äº† {len(file_content)} å­—ç¬¦"

    return {
        **state,
        "results": [processed_result],
        "execution_count": state.get("execution_count", 0) + 1
    }

@performance_test("parallel_a")
def parallel_node_a(state: PerformanceState) -> PerformanceState:
    """å¹¶è¡ŒèŠ‚ç‚¹ A"""
    thread_id = threading.current_thread().ident
    print(f"ğŸ…°ï¸  å¹¶è¡ŒèŠ‚ç‚¹Aå¼€å§‹ (çº¿ç¨‹: {thread_id})")

    # æ¨¡æ‹Ÿå¤„ç†
    time.sleep(1)

    result = f"å¹¶è¡ŒAç»“æœ (çº¿ç¨‹: {thread_id})"

    return {
        **state,
        "results": [result],
        "execution_count": state.get("execution_count", 0) + 1
    }

@performance_test("parallel_b")
def parallel_node_b(state: PerformanceState) -> PerformanceState:
    """å¹¶è¡ŒèŠ‚ç‚¹ B"""
    thread_id = threading.current_thread().ident
    print(f"ğŸ…±ï¸  å¹¶è¡ŒèŠ‚ç‚¹Bå¼€å§‹ (çº¿ç¨‹: {thread_id})")

    # æ¨¡æ‹Ÿä¸åŒçš„å¤„ç†æ—¶é—´
    time.sleep(0.8)

    result = f"å¹¶è¡ŒBç»“æœ (çº¿ç¨‹: {thread_id})"

    return {
        **state,
        "results": [result],
        "execution_count": state.get("execution_count", 0) + 1
    }

@performance_test("memory_intensive")
def memory_intensive_node(state: PerformanceState) -> PerformanceState:
    """å†…å­˜å¯†é›†å‹èŠ‚ç‚¹"""
    print(f"ğŸ§  å†…å­˜å¯†é›†å‹å¤„ç†å¼€å§‹...")

    # åˆ›å»ºå¤§é‡æ•°æ®
    large_data = []
    for i in range(100000):
        large_data.append(f"æ•°æ®é¡¹_{i}_" + "x" * 100)

    # å¤„ç†æ•°æ®
    processed_count = len(large_data)
    processed_result = f"å†…å­˜å¤„ç†ç»“æœ: å¤„ç†äº† {processed_count} ä¸ªæ•°æ®é¡¹"

    # ä¸»åŠ¨æ¸…ç†å¤§æ•°æ®ï¼ˆæ¼”ç¤ºå†…å­˜ç®¡ç†ï¼‰
    del large_data
    gc.collect()

    return {
        **state,
        "results": [processed_result],
        "execution_count": state.get("execution_count", 0) + 1
    }

@performance_test("streaming")
def streaming_node(state: PerformanceState) -> PerformanceState:
    """æµå¼å¤„ç†èŠ‚ç‚¹"""
    print(f"ğŸ“¡ æµå¼å¤„ç†å¼€å§‹...")

    # æ¨¡æ‹Ÿæµå¼å¤„ç†
    chunks = []
    input_data = state.get('input_data', '')

    # åˆ†å—å¤„ç†
    chunk_size = 10
    for i in range(0, len(input_data), chunk_size):
        chunk = input_data[i:i+chunk_size]
        processed_chunk = f"æµå¼å—_{i//chunk_size}: {chunk}"
        chunks.append(processed_chunk)

        # æ¨¡æ‹Ÿæµå¼å»¶è¿Ÿ
        time.sleep(0.01)

    processed_result = f"æµå¼å¤„ç†ç»“æœ: {len(chunks)} ä¸ªå—"

    return {
        **state,
        "results": [processed_result],
        "execution_count": state.get("execution_count", 0) + 1
    }

def create_performance_test_graphs():
    """åˆ›å»ºæ€§èƒ½æµ‹è¯•å›¾"""
    graphs = {}

    # é¡ºåºå¤„ç†å›¾
    sequential_graph = StateGraph(PerformanceState)
    sequential_graph.add_node("cpu", cpu_intensive_node)
    sequential_graph.add_node("io", io_intensive_node)
    sequential_graph.add_node("memory", memory_intensive_node)

    sequential_graph.add_edge(START, "cpu")
    sequential_graph.add_edge("cpu", "io")
    sequential_graph.add_edge("io", "memory")
    sequential_graph.add_edge("memory", END)

    graphs["sequential"] = sequential_graph.compile()

    # å¹¶è¡Œå¤„ç†å›¾
    parallel_graph = StateGraph(PerformanceState)
    parallel_graph.add_node("parallel_a", parallel_node_a)
    parallel_graph.add_node("parallel_b", parallel_node_b)

    parallel_graph.add_edge(START, "parallel_a")
    parallel_graph.add_edge(START, "parallel_b")
    parallel_graph.add_edge("parallel_a", END)
    parallel_graph.add_edge("parallel_b", END)

    graphs["parallel"] = parallel_graph.compile()

    # ä¼˜åŒ–å¯¹æ¯”å›¾
    optimization_graph = StateGraph(PerformanceState)
    optimization_graph.add_node("original", cpu_intensive_node)
    optimization_graph.add_node("optimized", optimized_cpu_node)

    optimization_graph.add_edge(START, "original")
    optimization_graph.add_edge("original", "optimized")
    optimization_graph.add_edge("optimized", END)

    graphs["optimization"] = optimization_graph.compile()

    # æµå¼å¤„ç†å›¾
    streaming_graph = StateGraph(PerformanceState)
    streaming_graph.add_node("streaming", streaming_node)

    streaming_graph.add_edge(START, "streaming")
    streaming_graph.add_edge("streaming", END)

    graphs["streaming"] = streaming_graph.compile()

    return graphs

def run_performance_benchmarks():
    """è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•"""
    print("ğŸš€ æ€§èƒ½åŸºå‡†æµ‹è¯•")
    print("="*40)

    graphs = create_performance_test_graphs()

    test_data = {
        'input_data': 'performance test data ' * 100,
        'results': [],
        'performance_metrics': {},
        'execution_count': 0
    }

    benchmarks = [
        ("é¡ºåºå¤„ç†", "sequential"),
        ("å¹¶è¡Œå¤„ç†", "parallel"),
        ("ä¼˜åŒ–å¯¹æ¯”", "optimization"),
        ("æµå¼å¤„ç†", "streaming")
    ]

    for name, graph_type in benchmarks:
        print(f"\nğŸ“Š æµ‹è¯•: {name}")
        print("-" * 30)

        perf_monitor.start_monitoring()
        start_time = time.time()

        try:
            result = graphs[graph_type].invoke(test_data.copy())
            total_time = time.time() - start_time

            print(f"âœ… æ‰§è¡Œå®Œæˆ")
            print(f"   æ€»æ—¶é—´: {total_time:.3f}s")
            print(f"   ç»“æœæ•°: {len(result['results'])}")
            print(f"   æ‰§è¡Œæ¬¡æ•°: {result['execution_count']}")

            # æ˜¾ç¤ºæ€§èƒ½æŒ‡æ ‡
            if result['performance_metrics']:
                print(f"   èŠ‚ç‚¹æ€§èƒ½:")
                for node, metrics in result['performance_metrics'].items():
                    print(f"     {node}: {metrics['execution_time']:.3f}s")

        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")

    # æ˜¾ç¤ºæ€»ä½“æ€§èƒ½æ‘˜è¦
    print(f"\nğŸ“ˆ æ€§èƒ½æ‘˜è¦")
    print("="*20)
    summary = perf_monitor.get_summary()

    if summary:
        print(f"æ€»æ‰§è¡Œæ—¶é—´: {summary['total_execution_time']:.3f}s")
        print(f"å¹³å‡å†…å­˜ä½¿ç”¨: {summary['average_memory_usage_mb']:.2f}MB")
        print(f"å³°å€¼å†…å­˜ä½¿ç”¨: {summary['peak_memory_usage_mb']:.2f}MB")
        print(f"æ€»æµ‹é‡æ¬¡æ•°: {summary['total_measurements']}")

        print(f"\nèŠ‚ç‚¹æ€§èƒ½åˆ†æ:")
        for node, perf in summary['node_performance'].items():
            print(f"  {node}:")
            print(f"    å¹³å‡æ—¶é—´: {perf['avg_time']:.3f}s")
            print(f"    æœ€å¤§æ—¶é—´: {perf['max_time']:.3f}s")
            print(f"    æœ€å°æ—¶é—´: {perf['min_time']:.3f}s")
            print(f"    æ‰§è¡Œæ¬¡æ•°: {perf['count']}")

def run_concurrent_stress_test():
    """è¿è¡Œå¹¶å‘å‹åŠ›æµ‹è¯•"""
    print(f"\nğŸ”¥ å¹¶å‘å‹åŠ›æµ‹è¯•")
    print("="*25)

    graphs = create_performance_test_graphs()
    app = graphs["parallel"]

    def single_execution(index: int):
        """å•æ¬¡æ‰§è¡Œ"""
        test_data = {
            'input_data': f'concurrent test {index}',
            'results': [],
            'performance_metrics': {},
            'execution_count': 0
        }

        start_time = time.time()
        result = app.invoke(test_data)
        execution_time = time.time() - start_time

        return {
            'index': index,
            'execution_time': execution_time,
            'result_count': len(result['results'])
        }

    # å¹¶å‘æµ‹è¯•
    num_workers = 5
    num_tasks = 20

    print(f"å¯åŠ¨ {num_workers} ä¸ªå·¥ä½œçº¿ç¨‹ï¼Œæ‰§è¡Œ {num_tasks} ä¸ªä»»åŠ¡")

    start_time = time.time()

    with ThreadPoolExecutor(max_workers=num_workers) as executor:
        futures = [executor.submit(single_execution, i) for i in range(num_tasks)]
        results = [future.result() for future in as_completed(futures)]

    total_time = time.time() - start_time

    # åˆ†æç»“æœ
    execution_times = [r['execution_time'] for r in results]
    avg_time = sum(execution_times) / len(execution_times)
    max_time = max(execution_times)
    min_time = min(execution_times)

    print(f"\nğŸ“Š å¹¶å‘æµ‹è¯•ç»“æœ:")
    print(f"   æ€»æ—¶é—´: {total_time:.3f}s")
    print(f"   å¹³å‡å•æ¬¡æ—¶é—´: {avg_time:.3f}s")
    print(f"   æœ€é•¿å•æ¬¡æ—¶é—´: {max_time:.3f}s")
    print(f"   æœ€çŸ­å•æ¬¡æ—¶é—´: {min_time:.3f}s")
    print(f"   ååé‡: {num_tasks/total_time:.2f} tasks/s")

def run_memory_leak_test():
    """è¿è¡Œå†…å­˜æ³„æ¼æµ‹è¯•"""
    print(f"\nğŸ§ª å†…å­˜æ³„æ¼æµ‹è¯•")
    print("="*20)

    graph = create_performance_test_graphs()["streaming"]

    memory_readings = []
    num_iterations = 50

    print(f"æ‰§è¡Œ {num_iterations} æ¬¡è¿­ä»£ï¼Œç›‘æ§å†…å­˜ä½¿ç”¨...")

    for i in range(num_iterations):
        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        gc.collect()

        # è®°å½•å†…å­˜ä½¿ç”¨
        memory_mb = psutil.virtual_memory().used / 1024 / 1024
        memory_readings.append(memory_mb)

        # æ‰§è¡Œå›¾
        test_data = {
            'input_data': f'memory test iteration {i}' * 50,
            'results': [],
            'performance_metrics': {},
            'execution_count': 0
        }

        result = graph.invoke(test_data)

        if i % 10 == 0:
            print(f"   è¿­ä»£ {i}: å†…å­˜ä½¿ç”¨ {memory_mb:.2f}MB")

    # åˆ†æå†…å­˜è¶‹åŠ¿
    start_memory = memory_readings[0]
    end_memory = memory_readings[-1]
    max_memory = max(memory_readings)
    memory_growth = end_memory - start_memory

    print(f"\nğŸ“ˆ å†…å­˜åˆ†æ:")
    print(f"   èµ·å§‹å†…å­˜: {start_memory:.2f}MB")
    print(f"   ç»“æŸå†…å­˜: {end_memory:.2f}MB")
    print(f"   å³°å€¼å†…å­˜: {max_memory:.2f}MB")
    print(f"   å†…å­˜å¢é•¿: {memory_growth:+.2f}MB")

    if memory_growth > 10:  # 10MBé˜ˆå€¼
        print(f"   âš ï¸  è­¦å‘Š: å¯èƒ½å­˜åœ¨å†…å­˜æ³„æ¼")
    else:
        print(f"   âœ… å†…å­˜ä½¿ç”¨æ­£å¸¸")

async def run_async_performance_test():
    """è¿è¡Œå¼‚æ­¥æ€§èƒ½æµ‹è¯•"""
    print(f"\nâš¡ å¼‚æ­¥æ€§èƒ½æµ‹è¯•")
    print("="*20)

    async def async_task(index: int, delay: float):
        """å¼‚æ­¥ä»»åŠ¡"""
        await asyncio.sleep(delay)
        return f"å¼‚æ­¥ä»»åŠ¡ {index} å®Œæˆ"

    # å¯¹æ¯”åŒæ­¥å’Œå¼‚æ­¥æ‰§è¡Œ
    tasks = [(i, 0.1) for i in range(20)]

    # åŒæ­¥æ‰§è¡Œ
    print("ğŸ”„ åŒæ­¥æ‰§è¡Œ...")
    start_time = time.time()
    sync_results = []
    for index, delay in tasks:
        time.sleep(delay)
        sync_results.append(f"åŒæ­¥ä»»åŠ¡ {index} å®Œæˆ")
    sync_time = time.time() - start_time

    # å¼‚æ­¥æ‰§è¡Œ
    print("âš¡ å¼‚æ­¥æ‰§è¡Œ...")
    start_time = time.time()
    async_tasks = [async_task(index, delay) for index, delay in tasks]
    async_results = await asyncio.gather(*async_tasks)
    async_time = time.time() - start_time

    print(f"\nğŸ“Š æ€§èƒ½å¯¹æ¯”:")
    print(f"   åŒæ­¥æ‰§è¡Œæ—¶é—´: {sync_time:.3f}s")
    print(f"   å¼‚æ­¥æ‰§è¡Œæ—¶é—´: {async_time:.3f}s")
    print(f"   æ€§èƒ½æå‡: {sync_time/async_time:.2f}x")

def generate_performance_report():
    """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
    print(f"\nğŸ“„ ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š")
    print("="*20)

    summary = perf_monitor.get_summary()

    report = {
        "timestamp": datetime.now().isoformat(),
        "summary": summary,
        "metrics": [
            {
                "node_name": m.node_name,
                "execution_time": m.execution_time,
                "memory_usage_mb": m.memory_usage_mb,
                "cpu_percent": m.cpu_percent,
                "timestamp": m.timestamp
            }
            for m in perf_monitor.metrics
        ]
    }

    # ä¿å­˜æŠ¥å‘Š
    report_file = f"performance_report_{int(time.time())}.json"
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)

    print(f"ğŸ“Š æ€§èƒ½æŠ¥å‘Šå·²ä¿å­˜: {report_file}")

if __name__ == "__main__":
    print("ğŸš€ LangGraph æ€§èƒ½æµ‹è¯•å¥—ä»¶")
    print("="*50)

    # è¿è¡Œå„ç§æ€§èƒ½æµ‹è¯•
    run_performance_benchmarks()

    # å¹¶å‘å‹åŠ›æµ‹è¯•
    run_concurrent_stress_test()

    # å†…å­˜æ³„æ¼æµ‹è¯•
    run_memory_leak_test()

    # å¼‚æ­¥æ€§èƒ½æµ‹è¯•
    print("âš¡ å¯åŠ¨å¼‚æ­¥æµ‹è¯•...")
    asyncio.run(run_async_performance_test())

    # ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
    generate_performance_report()

    print("\nğŸ‰ æ€§èƒ½æµ‹è¯•å®Œæˆ!")
    print("ğŸ’¡ ä¼˜åŒ–å»ºè®®:")
    print("   1. CPUå¯†é›†å‹ä»»åŠ¡ä½¿ç”¨ç®—æ³•ä¼˜åŒ–")
    print("   2. IOå¯†é›†å‹ä»»åŠ¡è€ƒè™‘å¼‚æ­¥å¤„ç†")
    print("   3. å¹¶è¡Œå¤„ç†æå‡ååé‡")
    print("   4. åŠæ—¶æ¸…ç†å¤§å¯¹è±¡é¿å…å†…å­˜æ³„æ¼")
    print("   5. ä½¿ç”¨æµå¼å¤„ç†ä¼˜åŒ–ç”¨æˆ·ä½“éªŒ")