#!/usr/bin/env python3
"""
LangGraph æµ‹è¯•ç¤ºä¾‹ä»£ç 

æ¼”ç¤ºå…¨é¢çš„æµ‹è¯•ç­–ç•¥ï¼ŒåŒ…æ‹¬å•å…ƒæµ‹è¯•ã€é›†æˆæµ‹è¯•ã€æ€§èƒ½æµ‹è¯•ç­‰ã€‚
"""

import unittest
import pytest
import asyncio
import time
import json
from unittest.mock import Mock, patch, MagicMock
from typing import TypedDict, List, Dict, Any, Optional
from langgraph import StateGraph, START, END

# æµ‹è¯•çŠ¶æ€å®šä¹‰
class TestState(TypedDict):
    input_data: str
    processed_data: str
    step_count: int
    metadata: Dict[str, Any]
    test_results: Dict[str, Any]

# è¢«æµ‹è¯•çš„èŠ‚ç‚¹å‡½æ•°
def validation_node(state: TestState) -> TestState:
    """è¾“å…¥éªŒè¯èŠ‚ç‚¹"""
    input_data = state.get('input_data', '')

    if not input_data.strip():
        raise ValueError("è¾“å…¥æ•°æ®ä¸èƒ½ä¸ºç©º")

    if len(input_data) > 1000:
        raise ValueError("è¾“å…¥æ•°æ®è¿‡é•¿")

    return {
        **state,
        'step_count': state['step_count'] + 1,
        'metadata': {
            **state.get('metadata', {}),
            'validation_passed': True,
            'input_length': len(input_data)
        }
    }

def processing_node(state: TestState) -> TestState:
    """æ•°æ®å¤„ç†èŠ‚ç‚¹"""
    input_data = state['input_data']

    # ç®€å•çš„æ•°æ®å¤„ç†
    processed = input_data.upper().strip()

    return {
        **state,
        'processed_data': f"[å¤„ç†] {processed}",
        'step_count': state['step_count'] + 1,
        'metadata': {
            **state.get('metadata', {}),
            'processing_method': 'uppercase',
            'processed_length': len(processed)
        }
    }

def external_api_node(state: TestState) -> TestState:
    """å¤–éƒ¨APIè°ƒç”¨èŠ‚ç‚¹"""
    import requests

    try:
        # æ¨¡æ‹ŸAPIè°ƒç”¨
        response = requests.get(
            "https://httpbin.org/json",
            timeout=5
        )
        response.raise_for_status()

        api_data = response.json()

        return {
            **state,
            'step_count': state['step_count'] + 1,
            'test_results': {
                **state.get('test_results', {}),
                'api_call_success': True,
                'api_response': api_data
            }
        }
    except Exception as e:
        return {
            **state,
            'step_count': state['step_count'] + 1,
            'test_results': {
                **state.get('test_results', {}),
                'api_call_success': False,
                'api_error': str(e)
            }
        }

def conditional_router(state: TestState) -> str:
    """æ¡ä»¶è·¯ç”±å‡½æ•°"""
    input_length = len(state.get('input_data', ''))

    if input_length > 50:
        return "long_processing"
    elif input_length > 10:
        return "medium_processing"
    else:
        return "short_processing"

def long_processing_node(state: TestState) -> TestState:
    """é•¿æ–‡æœ¬å¤„ç†èŠ‚ç‚¹"""
    time.sleep(0.1)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´

    return {
        **state,
        'processed_data': f"[é•¿æ–‡æœ¬å¤„ç†] {state['input_data'][:50]}...",
        'step_count': state['step_count'] + 1
    }

def medium_processing_node(state: TestState) -> TestState:
    """ä¸­ç­‰æ–‡æœ¬å¤„ç†èŠ‚ç‚¹"""
    return {
        **state,
        'processed_data': f"[ä¸­ç­‰å¤„ç†] {state['input_data']}",
        'step_count': state['step_count'] + 1
    }

def short_processing_node(state: TestState) -> TestState:
    """çŸ­æ–‡æœ¬å¤„ç†èŠ‚ç‚¹"""
    return {
        **state,
        'processed_data': f"[çŸ­æ–‡æœ¬] {state['input_data']}",
        'step_count': state['step_count'] + 1
    }

# å›¾åˆ›å»ºå‡½æ•°
def create_simple_graph() -> StateGraph:
    """åˆ›å»ºç®€å•çš„æµ‹è¯•å›¾"""
    graph = StateGraph(TestState)

    graph.add_node("validate", validation_node)
    graph.add_node("process", processing_node)

    graph.add_edge(START, "validate")
    graph.add_edge("validate", "process")
    graph.add_edge("process", END)

    return graph.compile()

def create_conditional_graph() -> StateGraph:
    """åˆ›å»ºæ¡ä»¶è·¯ç”±å›¾"""
    graph = StateGraph(TestState)

    graph.add_node("validate", validation_node)
    graph.add_node("long_proc", long_processing_node)
    graph.add_node("medium_proc", medium_processing_node)
    graph.add_node("short_proc", short_processing_node)

    graph.add_edge(START, "validate")
    graph.add_conditional_edges(
        "validate",
        conditional_router,
        {
            "long_processing": "long_proc",
            "medium_processing": "medium_proc",
            "short_processing": "short_proc"
        }
    )

    graph.add_edge("long_proc", END)
    graph.add_edge("medium_proc", END)
    graph.add_edge("short_proc", END)

    return graph.compile()

def create_api_graph() -> StateGraph:
    """åˆ›å»ºåŒ…å«APIè°ƒç”¨çš„å›¾"""
    graph = StateGraph(TestState)

    graph.add_node("validate", validation_node)
    graph.add_node("api_call", external_api_node)
    graph.add_node("process", processing_node)

    graph.add_edge(START, "validate")
    graph.add_edge("validate", "api_call")
    graph.add_edge("api_call", "process")
    graph.add_edge("process", END)

    return graph.compile()

# å•å…ƒæµ‹è¯•ç±»
class TestNodeFunctions(unittest.TestCase):
    """èŠ‚ç‚¹å‡½æ•°å•å…ƒæµ‹è¯•"""

    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        self.base_state = {
            'input_data': 'test input',
            'processed_data': '',
            'step_count': 0,
            'metadata': {},
            'test_results': {}
        }

    def test_validation_node_success(self):
        """æµ‹è¯•éªŒè¯èŠ‚ç‚¹æˆåŠŸæƒ…å†µ"""
        result = validation_node(self.base_state)

        self.assertEqual(result['step_count'], 1)
        self.assertTrue(result['metadata']['validation_passed'])
        self.assertEqual(result['metadata']['input_length'], len('test input'))

    def test_validation_node_empty_input(self):
        """æµ‹è¯•éªŒè¯èŠ‚ç‚¹ç©ºè¾“å…¥"""
        state = {**self.base_state, 'input_data': ''}

        with self.assertRaises(ValueError) as context:
            validation_node(state)

        self.assertIn("ä¸èƒ½ä¸ºç©º", str(context.exception))

    def test_validation_node_long_input(self):
        """æµ‹è¯•éªŒè¯èŠ‚ç‚¹è¿‡é•¿è¾“å…¥"""
        state = {**self.base_state, 'input_data': 'x' * 1001}

        with self.assertRaises(ValueError) as context:
            validation_node(state)

        self.assertIn("è¿‡é•¿", str(context.exception))

    def test_processing_node(self):
        """æµ‹è¯•å¤„ç†èŠ‚ç‚¹"""
        result = processing_node(self.base_state)

        self.assertEqual(result['processed_data'], "[å¤„ç†] TEST INPUT")
        self.assertEqual(result['step_count'], 1)
        self.assertEqual(result['metadata']['processing_method'], 'uppercase')

    def test_conditional_router(self):
        """æµ‹è¯•æ¡ä»¶è·¯ç”±å‡½æ•°"""
        # çŸ­æ–‡æœ¬
        short_state = {**self.base_state, 'input_data': 'short'}
        self.assertEqual(conditional_router(short_state), "short_processing")

        # ä¸­ç­‰æ–‡æœ¬
        medium_state = {**self.base_state, 'input_data': 'medium length text'}
        self.assertEqual(conditional_router(medium_state), "medium_processing")

        # é•¿æ–‡æœ¬
        long_state = {**self.base_state, 'input_data': 'x' * 60}
        self.assertEqual(conditional_router(long_state), "long_processing")

class TestGraphExecution(unittest.TestCase):
    """å›¾æ‰§è¡Œé›†æˆæµ‹è¯•"""

    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        self.simple_app = create_simple_graph()
        self.conditional_app = create_conditional_graph()

        self.base_state = {
            'input_data': 'integration test',
            'processed_data': '',
            'step_count': 0,
            'metadata': {},
            'test_results': {}
        }

    def test_simple_graph_execution(self):
        """æµ‹è¯•ç®€å•å›¾æ‰§è¡Œ"""
        result = self.simple_app.invoke(self.base_state)

        self.assertEqual(result['step_count'], 2)  # ä¸¤ä¸ªèŠ‚ç‚¹
        self.assertIn("[å¤„ç†]", result['processed_data'])
        self.assertTrue(result['metadata']['validation_passed'])

    def test_conditional_graph_short_text(self):
        """æµ‹è¯•æ¡ä»¶å›¾çŸ­æ–‡æœ¬è·¯å¾„"""
        state = {**self.base_state, 'input_data': 'short'}
        result = self.conditional_app.invoke(state)

        self.assertEqual(result['step_count'], 2)  # éªŒè¯ + çŸ­æ–‡æœ¬å¤„ç†
        self.assertIn("[çŸ­æ–‡æœ¬]", result['processed_data'])

    def test_conditional_graph_long_text(self):
        """æµ‹è¯•æ¡ä»¶å›¾é•¿æ–‡æœ¬è·¯å¾„"""
        long_text = 'x' * 60
        state = {**self.base_state, 'input_data': long_text}
        result = self.conditional_app.invoke(state)

        self.assertEqual(result['step_count'], 2)  # éªŒè¯ + é•¿æ–‡æœ¬å¤„ç†
        self.assertIn("[é•¿æ–‡æœ¬å¤„ç†]", result['processed_data'])

    def test_graph_streaming(self):
        """æµ‹è¯•å›¾æµå¼æ‰§è¡Œ"""
        events = list(self.simple_app.stream(self.base_state))

        self.assertGreater(len(events), 0)

        # éªŒè¯äº‹ä»¶åŒ…å«é¢„æœŸçš„èŠ‚ç‚¹
        node_names = []
        for event in events:
            node_names.extend(event.keys())

        self.assertIn("validate", node_names)
        self.assertIn("process", node_names)

class TestAPIIntegration(unittest.TestCase):
    """APIé›†æˆæµ‹è¯•"""

    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        self.base_state = {
            'input_data': 'api test',
            'processed_data': '',
            'step_count': 0,
            'metadata': {},
            'test_results': {}
        }

    @patch('requests.get')
    def test_external_api_success(self, mock_get):
        """æµ‹è¯•APIè°ƒç”¨æˆåŠŸ"""
        # è®¾ç½®æ¨¡æ‹Ÿå“åº”
        mock_response = Mock()
        mock_response.json.return_value = {"test": "data"}
        mock_response.raise_for_status.return_value = None
        mock_get.return_value = mock_response

        result = external_api_node(self.base_state)

        # éªŒè¯APIè¢«è°ƒç”¨
        mock_get.assert_called_once()

        # éªŒè¯ç»“æœ
        self.assertTrue(result['test_results']['api_call_success'])
        self.assertEqual(result['test_results']['api_response'], {"test": "data"})

    @patch('requests.get')
    def test_external_api_failure(self, mock_get):
        """æµ‹è¯•APIè°ƒç”¨å¤±è´¥"""
        # è®¾ç½®æ¨¡æ‹Ÿå¼‚å¸¸
        mock_get.side_effect = Exception("Network error")

        result = external_api_node(self.base_state)

        # éªŒè¯é”™è¯¯å¤„ç†
        self.assertFalse(result['test_results']['api_call_success'])
        self.assertIn("Network error", result['test_results']['api_error'])

    @patch('requests.get')
    def test_api_graph_execution(self, mock_get):
        """æµ‹è¯•åŒ…å«APIçš„å®Œæ•´å›¾æ‰§è¡Œ"""
        # è®¾ç½®æ¨¡æ‹Ÿ
        mock_response = Mock()
        mock_response.json.return_value = {"success": True}
        mock_response.raise_for_status.return_value = None
        mock_get.return_value = mock_response

        app = create_api_graph()
        result = app.invoke(self.base_state)

        # éªŒè¯å®Œæ•´æµç¨‹
        self.assertEqual(result['step_count'], 3)  # ä¸‰ä¸ªèŠ‚ç‚¹
        self.assertTrue(result['test_results']['api_call_success'])
        self.assertIn("[å¤„ç†]", result['processed_data'])

class TestPerformance(unittest.TestCase):
    """æ€§èƒ½æµ‹è¯•"""

    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        self.app = create_simple_graph()
        self.base_state = {
            'input_data': 'performance test',
            'processed_data': '',
            'step_count': 0,
            'metadata': {},
            'test_results': {}
        }

    def test_execution_time(self):
        """æµ‹è¯•æ‰§è¡Œæ—¶é—´"""
        start_time = time.time()
        result = self.app.invoke(self.base_state)
        execution_time = time.time() - start_time

        # éªŒè¯æ‰§è¡Œæ—¶é—´åœ¨åˆç†èŒƒå›´å†…
        self.assertLess(execution_time, 1.0)  # åº”è¯¥åœ¨1ç§’å†…å®Œæˆ
        self.assertEqual(result['step_count'], 2)

    def test_concurrent_execution(self):
        """æµ‹è¯•å¹¶å‘æ‰§è¡Œ"""
        import threading
        from concurrent.futures import ThreadPoolExecutor, as_completed

        def single_execution():
            return self.app.invoke(self.base_state)

        # å¹¶å‘æ‰§è¡Œå¤šæ¬¡
        with ThreadPoolExecutor(max_workers=5) as executor:
            futures = [executor.submit(single_execution) for _ in range(10)]
            results = [future.result() for future in as_completed(futures)]

        # éªŒè¯æ‰€æœ‰æ‰§è¡Œéƒ½æˆåŠŸ
        self.assertEqual(len(results), 10)
        for result in results:
            self.assertEqual(result['step_count'], 2)

    def test_memory_usage(self):
        """æµ‹è¯•å†…å­˜ä½¿ç”¨"""
        import psutil
        import gc

        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        gc.collect()

        # è®°å½•åˆå§‹å†…å­˜
        process = psutil.Process()
        initial_memory = process.memory_info().rss

        # æ‰§è¡Œå¤šæ¬¡
        for _ in range(100):
            self.app.invoke(self.base_state)

        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        gc.collect()

        # æ£€æŸ¥å†…å­˜å¢é•¿
        final_memory = process.memory_info().rss
        memory_growth = final_memory - initial_memory

        # å†…å­˜å¢é•¿åº”è¯¥åœ¨åˆç†èŒƒå›´å†…ï¼ˆå°äº10MBï¼‰
        self.assertLess(memory_growth, 10 * 1024 * 1024)

# Pytest æµ‹è¯•å‡½æ•°
@pytest.mark.parametrize("input_data,expected_route", [
    ("short", "short_processing"),
    ("medium length text", "medium_processing"),
    ("x" * 60, "long_processing")
])
def test_conditional_routing_parametrized(input_data, expected_route):
    """å‚æ•°åŒ–æµ‹è¯•æ¡ä»¶è·¯ç”±"""
    state = {
        'input_data': input_data,
        'processed_data': '',
        'step_count': 0,
        'metadata': {},
        'test_results': {}
    }

    route = conditional_router(state)
    assert route == expected_route

@pytest.mark.asyncio
async def test_async_graph_execution():
    """æµ‹è¯•å¼‚æ­¥å›¾æ‰§è¡Œ"""
    app = create_simple_graph()

    state = {
        'input_data': 'async test',
        'processed_data': '',
        'step_count': 0,
        'metadata': {},
        'test_results': {}
    }

    result = await app.ainvoke(state)

    assert result['step_count'] == 2
    assert "[å¤„ç†]" in result['processed_data']

class TestDataValidation:
    """æ•°æ®éªŒè¯æµ‹è¯•"""

    @pytest.fixture
    def validation_test_cases(self):
        """æµ‹è¯•ç”¨ä¾‹å¤¹å…·"""
        return [
            {
                "input": "valid input",
                "should_pass": True,
                "description": "æ­£å¸¸è¾“å…¥"
            },
            {
                "input": "",
                "should_pass": False,
                "description": "ç©ºè¾“å…¥"
            },
            {
                "input": "   ",
                "should_pass": False,
                "description": "åªæœ‰ç©ºæ ¼"
            },
            {
                "input": "x" * 1001,
                "should_pass": False,
                "description": "è¿‡é•¿è¾“å…¥"
            }
        ]

    def test_validation_cases(self, validation_test_cases):
        """æµ‹è¯•éªŒè¯ç”¨ä¾‹"""
        for case in validation_test_cases:
            state = {
                'input_data': case['input'],
                'processed_data': '',
                'step_count': 0,
                'metadata': {},
                'test_results': {}
            }

            if case['should_pass']:
                result = validation_node(state)
                assert result['metadata']['validation_passed']
            else:
                with pytest.raises(ValueError):
                    validation_node(state)

# æµ‹è¯•å¥—ä»¶è¿è¡Œå‡½æ•°
def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸ§ª è¿è¡Œ LangGraph æµ‹è¯•å¥—ä»¶")
    print("="*40)

    # è¿è¡Œ unittest
    print("\nğŸ“‹ è¿è¡Œå•å…ƒæµ‹è¯•...")
    unittest.main(argv=[''], exit=False, verbosity=2)

    # è¿è¡Œ pytestï¼ˆå¦‚æœå®‰è£…äº†ï¼‰
    try:
        import pytest
        print("\nğŸ”¬ è¿è¡Œ pytest æµ‹è¯•...")
        pytest.main(["-v", __file__])
    except ImportError:
        print("âš ï¸  pytest æœªå®‰è£…ï¼Œè·³è¿‡ pytest æµ‹è¯•")

# æµ‹è¯•æŠ¥å‘Šç”Ÿæˆ
class TestReporter:
    """æµ‹è¯•æŠ¥å‘Šç”Ÿæˆå™¨"""

    def __init__(self):
        self.results = []

    def add_result(self, test_name: str, passed: bool, execution_time: float, details: str = ""):
        """æ·»åŠ æµ‹è¯•ç»“æœ"""
        self.results.append({
            "test_name": test_name,
            "passed": passed,
            "execution_time": execution_time,
            "details": details,
            "timestamp": time.time()
        })

    def generate_report(self, filename: str = "test_report.json"):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        total_tests = len(self.results)
        passed_tests = sum(1 for r in self.results if r['passed'])
        failed_tests = total_tests - passed_tests
        total_time = sum(r['execution_time'] for r in self.results)

        report = {
            "summary": {
                "total_tests": total_tests,
                "passed": passed_tests,
                "failed": failed_tests,
                "success_rate": passed_tests / total_tests if total_tests > 0 else 0,
                "total_execution_time": total_time
            },
            "results": self.results
        }

        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)

        print(f"ğŸ“Š æµ‹è¯•æŠ¥å‘Šå·²ç”Ÿæˆ: {filename}")
        return report

def demo_comprehensive_testing():
    """æ¼”ç¤ºç»¼åˆæµ‹è¯•"""
    print("ğŸ¯ ç»¼åˆæµ‹è¯•æ¼”ç¤º")
    print("="*20)

    reporter = TestReporter()

    # æµ‹è¯•é¡¹ç›®åˆ—è¡¨
    test_items = [
        ("ç®€å•å›¾æ‰§è¡Œ", lambda: create_simple_graph().invoke({
            'input_data': 'demo test',
            'processed_data': '',
            'step_count': 0,
            'metadata': {},
            'test_results': {}
        })),
        ("æ¡ä»¶è·¯ç”±", lambda: conditional_router({'input_data': 'test'})),
        ("éªŒè¯èŠ‚ç‚¹", lambda: validation_node({
            'input_data': 'valid input',
            'processed_data': '',
            'step_count': 0,
            'metadata': {},
            'test_results': {}
        }))
    ]

    for test_name, test_func in test_items:
        try:
            start_time = time.time()
            result = test_func()
            execution_time = time.time() - start_time

            reporter.add_result(test_name, True, execution_time, "æµ‹è¯•é€šè¿‡")
            print(f"âœ… {test_name}: é€šè¿‡ ({execution_time:.3f}s)")

        except Exception as e:
            execution_time = time.time() - start_time
            reporter.add_result(test_name, False, execution_time, str(e))
            print(f"âŒ {test_name}: å¤±è´¥ - {e}")

    # ç”ŸæˆæŠ¥å‘Š
    report = reporter.generate_report()

    print(f"\nğŸ“ˆ æµ‹è¯•æ‘˜è¦:")
    print(f"   æ€»æµ‹è¯•æ•°: {report['summary']['total_tests']}")
    print(f"   é€šè¿‡: {report['summary']['passed']}")
    print(f"   å¤±è´¥: {report['summary']['failed']}")
    print(f"   æˆåŠŸç‡: {report['summary']['success_rate']:.1%}")
    print(f"   æ€»è€—æ—¶: {report['summary']['total_execution_time']:.3f}s")

if __name__ == "__main__":
    # æ¼”ç¤ºç»¼åˆæµ‹è¯•
    demo_comprehensive_testing()

    print("\nğŸ’¡ æµ‹è¯•è¦ç‚¹:")
    print("   1. å•å…ƒæµ‹è¯•è¦†ç›–æ‰€æœ‰èŠ‚ç‚¹å‡½æ•°")
    print("   2. é›†æˆæµ‹è¯•éªŒè¯å®Œæ•´æµç¨‹")
    print("   3. ä½¿ç”¨Mockæµ‹è¯•å¤–éƒ¨ä¾èµ–")
    print("   4. å‚æ•°åŒ–æµ‹è¯•æé«˜è¦†ç›–ç‡")
    print("   5. æ€§èƒ½æµ‹è¯•ç¡®ä¿ç³»ç»Ÿæ•ˆç‡")
    print("   6. ç”Ÿæˆè¯¦ç»†çš„æµ‹è¯•æŠ¥å‘Š")

    print("\nğŸš€ è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶:")
    print("   python -m unittest discover")
    print("   pytest test_graph.py -v")