# LangGraph 最佳实践

> 🎯 **学习目标**：掌握 LangGraph 开发的设计模式、代码规范和架构原则，构建可维护、可扩展的应用

## 🏗️ 架构设计原则

### 1. 单一职责原则 (SRP)

每个节点应该只负责一个明确的功能。

```python
from typing import TypedDict, List, Dict, Any
from langgraph import StateGraph, START, END

# ❌ 错误：节点职责混乱
def bad_multi_purpose_node(state: dict) -> dict:
    """反例：一个节点做太多事情"""
    # 验证输入
    if not state.get("input"):
        raise ValueError("输入为空")

    # 调用API
    import requests
    response = requests.get("https://api.example.com/data")

    # 处理数据
    processed_data = response.json()["data"].upper()

    # 发送邮件
    send_email(processed_data)

    # 保存到数据库
    save_to_database(processed_data)

    return {"result": processed_data}

# ✅ 正确：拆分为多个专职节点
class ProcessingState(TypedDict):
    input_data: str
    validated_data: str
    api_response: Dict[str, Any]
    processed_data: str
    email_sent: bool
    db_saved: bool
    errors: List[str]

def validation_node(state: ProcessingState) -> ProcessingState:
    """专职：输入验证"""
    input_data = state.get("input_data", "")
    errors = state.get("errors", [])

    if not input_data.strip():
        errors.append("输入数据为空")
        return {**state, "errors": errors}

    return {
        **state,
        "validated_data": input_data.strip(),
        "errors": errors
    }

def api_call_node(state: ProcessingState) -> ProcessingState:
    """专职：API调用"""
    try:
        import requests
        response = requests.get(
            "https://api.example.com/data",
            params={"input": state["validated_data"]},
            timeout=5
        )
        response.raise_for_status()

        return {
            **state,
            "api_response": response.json()
        }
    except Exception as e:
        errors = state.get("errors", [])
        errors.append(f"API调用失败: {str(e)}")
        return {**state, "errors": errors}

def data_processing_node(state: ProcessingState) -> ProcessingState:
    """专职：数据处理"""
    if state.get("errors"):
        return state  # 有错误时跳过处理

    api_data = state.get("api_response", {}).get("data", "")
    processed_data = api_data.upper() if api_data else ""

    return {
        **state,
        "processed_data": processed_data
    }

def notification_node(state: ProcessingState) -> ProcessingState:
    """专职：通知发送"""
    if state.get("errors") or not state.get("processed_data"):
        return state

    try:
        # 模拟发送邮件
        send_email_notification(state["processed_data"])
        return {**state, "email_sent": True}
    except Exception as e:
        errors = state.get("errors", [])
        errors.append(f"邮件发送失败: {str(e)}")
        return {**state, "errors": errors, "email_sent": False}

def persistence_node(state: ProcessingState) -> ProcessingState:
    """专职：数据持久化"""
    if state.get("errors") or not state.get("processed_data"):
        return state

    try:
        # 模拟保存到数据库
        save_to_database(state["processed_data"])
        return {**state, "db_saved": True}
    except Exception as e:
        errors = state.get("errors", [])
        errors.append(f"数据库保存失败: {str(e)}")
        return {**state, "errors": errors, "db_saved": False}

def create_well_architected_graph():
    """创建架构良好的图"""
    graph = StateGraph(ProcessingState)

    # 添加专职节点
    graph.add_node("validate", validation_node)
    graph.add_node("api_call", api_call_node)
    graph.add_node("process", data_processing_node)
    graph.add_node("notify", notification_node)
    graph.add_node("persist", persistence_node)

    # 定义执行流程
    graph.add_edge(START, "validate")
    graph.add_edge("validate", "api_call")
    graph.add_edge("api_call", "process")

    # 并行执行通知和持久化
    graph.add_edge("process", "notify")
    graph.add_edge("process", "persist")

    graph.add_edge("notify", END)
    graph.add_edge("persist", END)

    return graph.compile()

def send_email_notification(data: str):
    """模拟邮件发送"""
    print(f"📧 发送邮件: {data}")

def save_to_database(data: str):
    """模拟数据库保存"""
    print(f"💾 保存到数据库: {data}")
```

### 2. 开闭原则 (OCP)

代码应该对扩展开放，对修改关闭。

```python
from abc import ABC, abstractmethod
from typing import Protocol

# ✅ 使用策略模式实现可扩展的处理器
class DataProcessor(Protocol):
    """数据处理器协议"""

    def process(self, data: str) -> str:
        """处理数据"""
        ...

class UpperCaseProcessor:
    """大写处理器"""

    def process(self, data: str) -> str:
        return data.upper()

class LowerCaseProcessor:
    """小写处理器"""

    def process(self, data: str) -> str:
        return data.lower()

class TitleCaseProcessor:
    """标题格式处理器"""

    def process(self, data: str) -> str:
        return data.title()

class ReverseProcessor:
    """反转处理器"""

    def process(self, data: str) -> str:
        return data[::-1]

# 处理器注册表
PROCESSORS = {
    "upper": UpperCaseProcessor(),
    "lower": LowerCaseProcessor(),
    "title": TitleCaseProcessor(),
    "reverse": ReverseProcessor()
}

def extensible_processing_node(state: dict) -> dict:
    """可扩展的处理节点"""
    processor_type = state.get("processor_type", "upper")
    input_data = state.get("input_data", "")

    # 获取处理器
    processor = PROCESSORS.get(processor_type)
    if not processor:
        return {
            **state,
            "error": f"未知的处理器类型: {processor_type}",
            "processed_data": ""
        }

    # 执行处理
    try:
        processed_data = processor.process(input_data)
        return {
            **state,
            "processed_data": processed_data,
            "processor_used": processor_type
        }
    except Exception as e:
        return {
            **state,
            "error": f"处理失败: {str(e)}",
            "processed_data": ""
        }

# 注册新的处理器（扩展）
class JsonFormatter:
    """JSON格式化处理器"""

    def process(self, data: str) -> str:
        import json
        try:
            # 尝试解析并美化JSON
            parsed = json.loads(data)
            return json.dumps(parsed, indent=2, ensure_ascii=False)
        except json.JSONDecodeError:
            # 如果不是JSON，包装成JSON
            return json.dumps({"text": data}, indent=2, ensure_ascii=False)

# 动态注册新处理器
PROCESSORS["json"] = JsonFormatter()

# 测试可扩展性
def test_extensible_processing():
    """测试可扩展处理"""
    test_cases = [
        {"processor_type": "upper", "input_data": "hello world"},
        {"processor_type": "lower", "input_data": "HELLO WORLD"},
        {"processor_type": "title", "input_data": "hello world"},
        {"processor_type": "reverse", "input_data": "hello"},
        {"processor_type": "json", "input_data": '{"name": "test"}'},
        {"processor_type": "unknown", "input_data": "test"}
    ]

    for case in test_cases:
        result = extensible_processing_node(case)
        print(f"输入: {case}, 输出: {result['processed_data'][:50]}")
```

### 3. 依赖倒置原则 (DIP)

高层模块不应该依赖低层模块，两者都应该依赖抽象。

```python
from abc import ABC, abstractmethod
from typing import Optional

# ✅ 定义抽象接口
class DatabaseInterface(ABC):
    """数据库接口抽象"""

    @abstractmethod
    def save(self, key: str, data: str) -> bool:
        pass

    @abstractmethod
    def load(self, key: str) -> Optional[str]:
        pass

class CacheInterface(ABC):
    """缓存接口抽象"""

    @abstractmethod
    def get(self, key: str) -> Optional[str]:
        pass

    @abstractmethod
    def set(self, key: str, value: str, ttl: int = 3600) -> bool:
        pass

class NotificationInterface(ABC):
    """通知接口抽象"""

    @abstractmethod
    def send(self, message: str, recipient: str) -> bool:
        pass

# 具体实现
class PostgreSQLDatabase(DatabaseInterface):
    """PostgreSQL数据库实现"""

    def save(self, key: str, data: str) -> bool:
        print(f"保存到PostgreSQL: {key} = {data}")
        return True

    def load(self, key: str) -> Optional[str]:
        print(f"从PostgreSQL加载: {key}")
        return f"data_from_postgres_{key}"

class RedisCache(CacheInterface):
    """Redis缓存实现"""

    def get(self, key: str) -> Optional[str]:
        print(f"从Redis获取: {key}")
        return f"cached_{key}"

    def set(self, key: str, value: str, ttl: int = 3600) -> bool:
        print(f"存储到Redis: {key} = {value} (TTL: {ttl}s)")
        return True

class EmailNotification(NotificationInterface):
    """邮件通知实现"""

    def send(self, message: str, recipient: str) -> bool:
        print(f"发送邮件到 {recipient}: {message}")
        return True

# 高层业务逻辑依赖抽象
class DataService:
    """数据服务 - 依赖抽象接口"""

    def __init__(self,
                 database: DatabaseInterface,
                 cache: CacheInterface,
                 notification: NotificationInterface):
        self.database = database
        self.cache = cache
        self.notification = notification

    def process_data(self, key: str, data: str, notify_recipient: str = None) -> dict:
        """处理数据的高层逻辑"""
        try:
            # 1. 检查缓存
            cached_data = self.cache.get(key)
            if cached_data:
                return {"result": cached_data, "source": "cache"}

            # 2. 处理数据
            processed_data = f"processed_{data}"

            # 3. 保存到数据库
            if self.database.save(key, processed_data):
                # 4. 更新缓存
                self.cache.set(key, processed_data)

                # 5. 发送通知
                if notify_recipient:
                    self.notification.send(
                        f"数据处理完成: {key}",
                        notify_recipient
                    )

                return {"result": processed_data, "source": "processed"}
            else:
                return {"error": "数据保存失败"}

        except Exception as e:
            return {"error": f"处理失败: {str(e)}"}

# 依赖注入节点
def dependency_injection_node(state: dict) -> dict:
    """使用依赖注入的节点"""
    # 从状态中获取依赖（在图创建时注入）
    data_service = state.get("data_service")
    if not data_service:
        return {**state, "error": "数据服务未注入"}

    key = state.get("key", "default")
    data = state.get("input_data", "")
    recipient = state.get("notification_recipient")

    result = data_service.process_data(key, data, recipient)

    return {
        **state,
        "service_result": result
    }

def create_dependency_injection_graph():
    """创建使用依赖注入的图"""
    # 创建具体实现
    database = PostgreSQLDatabase()
    cache = RedisCache()
    notification = EmailNotification()

    # 注入依赖
    data_service = DataService(database, cache, notification)

    graph = StateGraph(dict)
    graph.add_node("process", dependency_injection_node)
    graph.add_edge(START, "process")
    graph.add_edge("process", END)

    app = graph.compile()

    # 返回配置了依赖的应用
    def configured_invoke(state: dict):
        # 在调用时注入服务
        state_with_deps = {
            **state,
            "data_service": data_service
        }
        return app.invoke(state_with_deps)

    return configured_invoke
```

## 🎨 设计模式

### 1. 策略模式

根据不同条件选择不同的处理策略。

```python
from enum import Enum
from typing import Dict, Callable

class ProcessingStrategy(Enum):
    """处理策略枚举"""
    SIMPLE = "simple"
    ADVANCED = "advanced"
    BATCH = "batch"
    STREAMING = "streaming"

class StrategyManager:
    """策略管理器"""

    def __init__(self):
        self.strategies: Dict[ProcessingStrategy, Callable] = {}

    def register_strategy(self, strategy: ProcessingStrategy, handler: Callable):
        """注册策略"""
        self.strategies[strategy] = handler

    def execute_strategy(self, strategy: ProcessingStrategy, state: dict) -> dict:
        """执行策略"""
        handler = self.strategies.get(strategy)
        if not handler:
            return {**state, "error": f"未找到策略: {strategy.value}"}

        return handler(state)

# 策略实现
def simple_processing_strategy(state: dict) -> dict:
    """简单处理策略"""
    data = state.get("input_data", "")
    return {
        **state,
        "processed_data": f"简单处理: {data}",
        "strategy_used": "simple"
    }

def advanced_processing_strategy(state: dict) -> dict:
    """高级处理策略"""
    data = state.get("input_data", "")
    # 模拟复杂处理
    processed = data.upper().replace(" ", "_")
    return {
        **state,
        "processed_data": f"高级处理: {processed}",
        "strategy_used": "advanced",
        "metadata": {"complexity": "high", "transformations": ["upper", "underscore"]}
    }

def batch_processing_strategy(state: dict) -> dict:
    """批处理策略"""
    data = state.get("input_data", "")
    items = data.split(",") if "," in data else [data]

    processed_items = [f"批处理_{item.strip()}" for item in items]

    return {
        **state,
        "processed_data": ",".join(processed_items),
        "strategy_used": "batch",
        "batch_size": len(items)
    }

def streaming_processing_strategy(state: dict) -> dict:
    """流处理策略"""
    data = state.get("input_data", "")
    # 模拟流处理
    chunks = [data[i:i+10] for i in range(0, len(data), 10)]

    return {
        **state,
        "processed_data": f"流处理: {len(chunks)}个块",
        "strategy_used": "streaming",
        "chunks": chunks
    }

# 创建策略管理器
strategy_manager = StrategyManager()
strategy_manager.register_strategy(ProcessingStrategy.SIMPLE, simple_processing_strategy)
strategy_manager.register_strategy(ProcessingStrategy.ADVANCED, advanced_processing_strategy)
strategy_manager.register_strategy(ProcessingStrategy.BATCH, batch_processing_strategy)
strategy_manager.register_strategy(ProcessingStrategy.STREAMING, streaming_processing_strategy)

def strategy_selection_node(state: dict) -> dict:
    """策略选择节点"""
    # 根据输入特征选择策略
    data = state.get("input_data", "")
    data_length = len(data)

    if "," in data:
        strategy = ProcessingStrategy.BATCH
    elif data_length > 100:
        strategy = ProcessingStrategy.STREAMING
    elif data_length > 20:
        strategy = ProcessingStrategy.ADVANCED
    else:
        strategy = ProcessingStrategy.SIMPLE

    print(f"选择策略: {strategy.value} (数据长度: {data_length})")

    return strategy_manager.execute_strategy(strategy, state)
```

### 2. 观察者模式

实现事件驱动的架构。

```python
from typing import List, Callable, Any
from dataclasses import dataclass
from datetime import datetime

@dataclass
class GraphEvent:
    """图事件"""
    event_type: str
    node_name: str
    timestamp: datetime
    data: Any

class EventObserver(ABC):
    """事件观察者抽象基类"""

    @abstractmethod
    def on_event(self, event: GraphEvent):
        """处理事件"""
        pass

class LoggingObserver(EventObserver):
    """日志观察者"""

    def on_event(self, event: GraphEvent):
        print(f"📝 [{event.timestamp.strftime('%H:%M:%S')}] "
              f"{event.event_type}: {event.node_name} - {event.data}")

class MetricsObserver(EventObserver):
    """指标观察者"""

    def __init__(self):
        self.metrics = {
            "node_executions": {},
            "total_events": 0,
            "errors": 0
        }

    def on_event(self, event: GraphEvent):
        self.metrics["total_events"] += 1

        if event.event_type == "node_start":
            node_name = event.node_name
            if node_name not in self.metrics["node_executions"]:
                self.metrics["node_executions"][node_name] = 0
            self.metrics["node_executions"][node_name] += 1

        elif event.event_type == "node_error":
            self.metrics["errors"] += 1

    def get_metrics(self) -> dict:
        return self.metrics.copy()

class AlertObserver(EventObserver):
    """告警观察者"""

    def __init__(self, error_threshold: int = 3):
        self.error_threshold = error_threshold
        self.error_count = 0

    def on_event(self, event: GraphEvent):
        if event.event_type == "node_error":
            self.error_count += 1
            if self.error_count >= self.error_threshold:
                self.send_alert(event)

    def send_alert(self, event: GraphEvent):
        print(f"🚨 告警: 错误次数达到阈值 ({self.error_count})! "
              f"最新错误: {event.node_name} - {event.data}")

class EventPublisher:
    """事件发布器"""

    def __init__(self):
        self.observers: List[EventObserver] = []

    def add_observer(self, observer: EventObserver):
        """添加观察者"""
        self.observers.append(observer)

    def remove_observer(self, observer: EventObserver):
        """移除观察者"""
        if observer in self.observers:
            self.observers.remove(observer)

    def notify_observers(self, event: GraphEvent):
        """通知所有观察者"""
        for observer in self.observers:
            try:
                observer.on_event(event)
            except Exception as e:
                print(f"⚠️ 观察者处理事件时出错: {e}")

# 全局事件发布器
event_publisher = EventPublisher()

def observable_node(node_name: str):
    """可观察节点装饰器"""
    def decorator(func: Callable):
        def wrapper(state: dict) -> dict:
            # 发布节点开始事件
            event_publisher.notify_observers(GraphEvent(
                event_type="node_start",
                node_name=node_name,
                timestamp=datetime.now(),
                data={"input_keys": list(state.keys())}
            ))

            try:
                result = func(state)

                # 发布节点完成事件
                event_publisher.notify_observers(GraphEvent(
                    event_type="node_complete",
                    node_name=node_name,
                    timestamp=datetime.now(),
                    data={"output_keys": list(result.keys())}
                ))

                return result

            except Exception as e:
                # 发布节点错误事件
                event_publisher.notify_observers(GraphEvent(
                    event_type="node_error",
                    node_name=node_name,
                    timestamp=datetime.now(),
                    data={"error": str(e)}
                ))
                raise

        return wrapper
    return decorator

# 使用观察者模式
@observable_node("processing")
def observed_processing_node(state: dict) -> dict:
    """被观察的处理节点"""
    data = state.get("input_data", "")

    # 模拟可能的错误
    if "error" in data.lower():
        raise ValueError("模拟处理错误")

    return {
        **state,
        "processed_data": f"观察者模式处理: {data}"
    }

def setup_observers():
    """设置观察者"""
    # 添加各种观察者
    event_publisher.add_observer(LoggingObserver())

    metrics_observer = MetricsObserver()
    event_publisher.add_observer(metrics_observer)

    alert_observer = AlertObserver(error_threshold=2)
    event_publisher.add_observer(alert_observer)

    return metrics_observer, alert_observer
```

### 3. 工厂模式

动态创建不同类型的图和节点。

```python
from typing import Type, Dict, Any
from enum import Enum

class GraphType(Enum):
    """图类型枚举"""
    SIMPLE_PIPELINE = "simple_pipeline"
    CONDITIONAL_FLOW = "conditional_flow"
    PARALLEL_PROCESSING = "parallel_processing"
    LOOP_PROCESSING = "loop_processing"

class NodeFactory:
    """节点工厂"""

    @staticmethod
    def create_processing_node(processing_type: str) -> Callable:
        """创建处理节点"""
        processing_functions = {
            "text_upper": lambda state: {
                **state, "result": state.get("input", "").upper()
            },
            "text_lower": lambda state: {
                **state, "result": state.get("input", "").lower()
            },
            "text_reverse": lambda state: {
                **state, "result": state.get("input", "")[::-1]
            },
            "math_double": lambda state: {
                **state, "result": str(int(state.get("input", "0")) * 2)
            }
        }

        processor = processing_functions.get(processing_type)
        if not processor:
            raise ValueError(f"未知的处理类型: {processing_type}")

        return processor

    @staticmethod
    def create_condition_node(condition_type: str) -> Callable:
        """创建条件节点"""
        condition_functions = {
            "length_check": lambda state: (
                "long" if len(state.get("input", "")) > 10 else "short"
            ),
            "type_check": lambda state: (
                "numeric" if state.get("input", "").isdigit() else "text"
            ),
            "empty_check": lambda state: (
                "empty" if not state.get("input", "").strip() else "not_empty"
            )
        }

        condition = condition_functions.get(condition_type)
        if not condition:
            raise ValueError(f"未知的条件类型: {condition_type}")

        return condition

class GraphFactory:
    """图工厂"""

    @classmethod
    def create_graph(cls, graph_type: GraphType, config: Dict[str, Any] = None) -> StateGraph:
        """创建图"""
        config = config or {}

        if graph_type == GraphType.SIMPLE_PIPELINE:
            return cls._create_simple_pipeline(config)
        elif graph_type == GraphType.CONDITIONAL_FLOW:
            return cls._create_conditional_flow(config)
        elif graph_type == GraphType.PARALLEL_PROCESSING:
            return cls._create_parallel_processing(config)
        elif graph_type == GraphType.LOOP_PROCESSING:
            return cls._create_loop_processing(config)
        else:
            raise ValueError(f"未知的图类型: {graph_type}")

    @classmethod
    def _create_simple_pipeline(cls, config: Dict[str, Any]) -> StateGraph:
        """创建简单管道图"""
        processing_steps = config.get("processing_steps", ["text_upper"])

        graph = StateGraph(dict)

        # 创建处理节点
        for i, step in enumerate(processing_steps):
            node_name = f"step_{i+1}"
            processor = NodeFactory.create_processing_node(step)
            graph.add_node(node_name, processor)

        # 连接节点
        if processing_steps:
            graph.add_edge(START, "step_1")
            for i in range(len(processing_steps) - 1):
                graph.add_edge(f"step_{i+1}", f"step_{i+2}")
            graph.add_edge(f"step_{len(processing_steps)}", END)

        return graph

    @classmethod
    def _create_conditional_flow(cls, config: Dict[str, Any]) -> StateGraph:
        """创建条件流图"""
        condition_type = config.get("condition_type", "length_check")
        branches = config.get("branches", {
            "long": "text_upper",
            "short": "text_lower"
        })

        graph = StateGraph(dict)

        # 创建条件函数
        condition_func = NodeFactory.create_condition_node(condition_type)

        # 创建分支节点
        for branch_name, processing_type in branches.items():
            processor = NodeFactory.create_processing_node(processing_type)
            graph.add_node(branch_name, processor)

        # 创建条件边
        graph.add_conditional_edges(
            START,
            condition_func,
            {branch: branch for branch in branches.keys()}
        )

        # 连接到结束
        for branch in branches.keys():
            graph.add_edge(branch, END)

        return graph

    @classmethod
    def _create_parallel_processing(cls, config: Dict[str, Any]) -> StateGraph:
        """创建并行处理图"""
        parallel_processes = config.get("parallel_processes", ["text_upper", "text_lower"])

        graph = StateGraph(dict)

        # 创建并行节点
        for i, process_type in enumerate(parallel_processes):
            node_name = f"parallel_{i+1}"
            processor = NodeFactory.create_processing_node(process_type)
            graph.add_node(node_name, processor)

        # 并行启动
        for i in range(len(parallel_processes)):
            graph.add_edge(START, f"parallel_{i+1}")
            graph.add_edge(f"parallel_{i+1}", END)

        return graph

    @classmethod
    def _create_loop_processing(cls, config: Dict[str, Any]) -> StateGraph:
        """创建循环处理图"""
        max_iterations = config.get("max_iterations", 3)
        processing_type = config.get("processing_type", "text_upper")

        # 创建带计数的处理节点
        def loop_processor(state: dict) -> dict:
            iteration = state.get("iteration", 0) + 1
            processor = NodeFactory.create_processing_node(processing_type)

            result = processor(state)
            result["iteration"] = iteration

            return result

        def should_continue(state: dict) -> str:
            return "continue" if state.get("iteration", 0) < max_iterations else "end"

        graph = StateGraph(dict)
        graph.add_node("loop_processor", loop_processor)

        graph.add_edge(START, "loop_processor")
        graph.add_conditional_edges(
            "loop_processor",
            should_continue,
            {
                "continue": "loop_processor",
                "end": END
            }
        )

        return graph

# 使用工厂模式
def demonstrate_graph_factory():
    """演示图工厂"""
    # 创建不同类型的图
    configs = [
        {
            "type": GraphType.SIMPLE_PIPELINE,
            "config": {"processing_steps": ["text_upper", "text_reverse"]}
        },
        {
            "type": GraphType.CONDITIONAL_FLOW,
            "config": {
                "condition_type": "length_check",
                "branches": {"long": "text_upper", "short": "text_lower"}
            }
        },
        {
            "type": GraphType.PARALLEL_PROCESSING,
            "config": {"parallel_processes": ["text_upper", "text_lower", "text_reverse"]}
        },
        {
            "type": GraphType.LOOP_PROCESSING,
            "config": {"max_iterations": 2, "processing_type": "text_upper"}
        }
    ]

    for graph_config in configs:
        print(f"\n📊 创建图类型: {graph_config['type'].value}")

        graph = GraphFactory.create_graph(
            graph_config['type'],
            graph_config['config']
        )

        app = graph.compile()

        result = app.invoke({"input": "hello world"})
        print(f"结果: {result}")
```

## 📝 代码规范

### 1. 命名规范

```python
# ✅ 好的命名规范
class UserDataProcessingState(TypedDict):
    """用户数据处理状态

    使用描述性的类名，遵循 PascalCase
    """
    user_input: str              # 使用 snake_case
    processed_output: str
    validation_errors: List[str]
    processing_metadata: Dict[str, Any]

def validate_user_input_node(state: UserDataProcessingState) -> UserDataProcessingState:
    """验证用户输入节点

    函数名使用 snake_case，清晰描述功能
    """
    # 常量使用 UPPER_CASE
    MAX_INPUT_LENGTH = 1000
    MIN_INPUT_LENGTH = 1

    user_input = state["user_input"]
    validation_errors = []

    # 使用描述性的变量名
    input_length = len(user_input)
    is_input_valid = True

    if input_length < MIN_INPUT_LENGTH:
        validation_errors.append("输入长度不能少于1个字符")
        is_input_valid = False

    if input_length > MAX_INPUT_LENGTH:
        validation_errors.append(f"输入长度不能超过{MAX_INPUT_LENGTH}个字符")
        is_input_valid = False

    return {
        **state,
        "validation_errors": validation_errors,
        "processing_metadata": {
            "input_length": input_length,
            "is_valid": is_input_valid,
            "validation_timestamp": __import__('datetime').datetime.now().isoformat()
        }
    }

# ❌ 不好的命名
def proc_data(st):  # 函数名不清晰
    x = st["data"]  # 变量名没有意义
    if len(x) > 100:  # 魔数
        return {"result": x[:100]}
    return {"result": x}
```

### 2. 文档规范

```python
from typing import TypedDict, List, Dict, Any, Optional

class DocumentedState(TypedDict):
    """文档化的状态定义

    这个状态用于演示完整的文档化规范，包含了所有必要的字段类型和说明。

    Attributes:
        input_text: 原始输入文本，不能为空
        processed_text: 处理后的文本，初始为空字符串
        processing_steps: 记录处理步骤的列表
        metadata: 存储额外元数据的字典
        error_message: 错误信息，无错误时为 None
    """
    input_text: str
    processed_text: str
    processing_steps: List[str]
    metadata: Dict[str, Any]
    error_message: Optional[str]

def text_preprocessing_node(state: DocumentedState) -> DocumentedState:
    """文本预处理节点

    对输入文本进行标准化预处理，包括去除多余空格、转换编码等。

    Args:
        state: 包含输入文本的状态对象

    Returns:
        处理后的状态对象，包含预处理后的文本

    Raises:
        ValueError: 当输入文本为空或None时

    Examples:
        >>> initial_state = {
        ...     "input_text": "  Hello World  ",
        ...     "processed_text": "",
        ...     "processing_steps": [],
        ...     "metadata": {},
        ...     "error_message": None
        ... }
        >>> result = text_preprocessing_node(initial_state)
        >>> result["processed_text"]
        'Hello World'
    """
    try:
        # 验证输入
        if not state["input_text"] or not state["input_text"].strip():
            raise ValueError("输入文本不能为空")

        # 执行预处理
        cleaned_text = state["input_text"].strip()
        # 移除多余的空格
        cleaned_text = " ".join(cleaned_text.split())

        # 记录处理步骤
        processing_steps = state["processing_steps"] + ["text_preprocessing"]

        # 更新元数据
        metadata = state["metadata"].copy()
        metadata.update({
            "preprocessing_applied": True,
            "original_length": len(state["input_text"]),
            "cleaned_length": len(cleaned_text),
            "characters_removed": len(state["input_text"]) - len(cleaned_text)
        })

        return {
            **state,
            "processed_text": cleaned_text,
            "processing_steps": processing_steps,
            "metadata": metadata,
            "error_message": None
        }

    except Exception as e:
        # 错误处理
        return {
            **state,
            "error_message": f"预处理失败: {str(e)}"
        }

def advanced_text_analysis_node(
    state: DocumentedState,
    enable_sentiment_analysis: bool = True,
    enable_entity_extraction: bool = False,
    confidence_threshold: float = 0.8
) -> DocumentedState:
    """高级文本分析节点

    对预处理后的文本进行深度分析，包括情感分析、实体提取等功能。

    Args:
        state: 包含预处理文本的状态对象
        enable_sentiment_analysis: 是否启用情感分析，默认为True
        enable_entity_extraction: 是否启用实体提取，默认为False
        confidence_threshold: 置信度阈值，默认为0.8

    Returns:
        包含分析结果的状态对象

    Note:
        此节点需要预处理文本不为空。如果启用实体提取，
        将会增加处理时间但提供更丰富的分析结果。

    Warning:
        实体提取功能目前为实验性功能，可能影响性能。
    """
    if state["error_message"]:
        return state  # 如果已有错误，直接返回

    try:
        text = state["processed_text"]
        if not text:
            raise ValueError("没有找到预处理后的文本")

        analysis_results = {}
        processing_steps = state["processing_steps"].copy()

        # 情感分析
        if enable_sentiment_analysis:
            # 模拟情感分析
            sentiment_score = 0.7  # 示例分数
            if sentiment_score >= confidence_threshold:
                analysis_results["sentiment"] = {
                    "score": sentiment_score,
                    "label": "positive" if sentiment_score > 0.5 else "negative",
                    "confidence": sentiment_score
                }
                processing_steps.append("sentiment_analysis")

        # 实体提取
        if enable_entity_extraction:
            # 模拟实体提取
            entities = [{"text": "World", "type": "LOCATION"}]  # 示例实体
            analysis_results["entities"] = entities
            processing_steps.append("entity_extraction")

        # 更新元数据
        metadata = state["metadata"].copy()
        metadata.update({
            "analysis_performed": True,
            "analysis_features": {
                "sentiment_analysis": enable_sentiment_analysis,
                "entity_extraction": enable_entity_extraction
            },
            "confidence_threshold": confidence_threshold
        })

        return {
            **state,
            "processed_text": text,  # 保持文本不变
            "processing_steps": processing_steps,
            "metadata": {**metadata, "analysis_results": analysis_results},
            "error_message": None
        }

    except Exception as e:
        return {
            **state,
            "error_message": f"文本分析失败: {str(e)}"
        }

# 图的文档化
def create_documented_text_processing_graph() -> StateGraph:
    """创建文档化的文本处理图

    构建一个完整的文本处理管道，包括预处理和高级分析功能。

    Returns:
        编译后的状态图，可直接调用invoke方法

    Graph Structure:
        START -> preprocess -> analyze -> END

    State Flow:
        1. preprocess: 清理和标准化输入文本
        2. analyze: 执行情感分析和实体提取

    Example:
        >>> graph = create_documented_text_processing_graph()
        >>> app = graph.compile()
        >>> result = app.invoke({
        ...     "input_text": "I love this product!",
        ...     "processed_text": "",
        ...     "processing_steps": [],
        ...     "metadata": {},
        ...     "error_message": None
        ... })
    """
    graph = StateGraph(DocumentedState)

    # 添加节点
    graph.add_node("preprocess", text_preprocessing_node)
    graph.add_node("analyze", advanced_text_analysis_node)

    # 定义边
    graph.add_edge(START, "preprocess")
    graph.add_edge("preprocess", "analyze")
    graph.add_edge("analyze", END)

    return graph
```

### 3. 类型注解规范

```python
from typing import (
    TypedDict, List, Dict, Any, Optional, Union,
    Callable, Tuple, Set, Protocol, TypeVar, Generic
)
from dataclasses import dataclass
from abc import ABC, abstractmethod

# 类型别名
NodeFunction = Callable[[Dict[str, Any]], Dict[str, Any]]
ConditionFunction = Callable[[Dict[str, Any]], str]
StateType = TypeVar('StateType', bound=Dict[str, Any])

class ProcessingResult(TypedDict):
    """处理结果类型定义"""
    success: bool
    data: Any
    error_message: Optional[str]
    metadata: Dict[str, Any]

class ConfigurableNode(Protocol):
    """可配置节点协议"""

    def configure(self, config: Dict[str, Any]) -> None:
        """配置节点"""
        ...

    def process(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """处理状态"""
        ...

@dataclass
class NodeMetrics:
    """节点指标数据类"""
    execution_count: int = 0
    total_execution_time: float = 0.0
    error_count: int = 0
    last_execution_time: Optional[float] = None

class BaseProcessor(ABC, Generic[StateType]):
    """基础处理器泛型抽象类"""

    @abstractmethod
    def validate_state(self, state: StateType) -> bool:
        """验证状态"""
        pass

    @abstractmethod
    def process_state(self, state: StateType) -> StateType:
        """处理状态"""
        pass

class TextProcessor(BaseProcessor[DocumentedState]):
    """文本处理器实现"""

    def __init__(self,
                 min_length: int = 1,
                 max_length: int = 10000,
                 allowed_languages: Optional[Set[str]] = None) -> None:
        self.min_length = min_length
        self.max_length = max_length
        self.allowed_languages = allowed_languages or {"zh", "en"}
        self.metrics = NodeMetrics()

    def validate_state(self, state: DocumentedState) -> bool:
        """验证文本状态

        Args:
            state: 要验证的状态

        Returns:
            验证是否通过
        """
        text = state.get("input_text", "")
        if not isinstance(text, str):
            return False

        text_length = len(text.strip())
        return self.min_length <= text_length <= self.max_length

    def process_state(self, state: DocumentedState) -> DocumentedState:
        """处理文本状态

        Args:
            state: 输入状态

        Returns:
            处理后的状态

        Raises:
            ValueError: 当状态验证失败时
        """
        if not self.validate_state(state):
            raise ValueError("状态验证失败")

        # 处理逻辑
        processed_text = state["input_text"].strip().title()

        return {
            **state,
            "processed_text": processed_text,
            "processing_steps": state["processing_steps"] + ["text_processing"],
            "metadata": {
                **state["metadata"],
                "processor_type": "TextProcessor",
                "processing_time": 0.1  # 模拟处理时间
            }
        }

def create_typed_processing_node(
    processor: BaseProcessor[StateType],
    metrics_enabled: bool = True
) -> Callable[[StateType], StateType]:
    """创建类型化处理节点

    Args:
        processor: 处理器实例
        metrics_enabled: 是否启用指标收集

    Returns:
        配置好的节点函数
    """
    import time

    def typed_node(state: StateType) -> StateType:
        start_time = time.time() if metrics_enabled else None

        try:
            result = processor.process_state(state)

            if metrics_enabled and hasattr(processor, 'metrics'):
                execution_time = time.time() - start_time
                processor.metrics.execution_count += 1
                processor.metrics.total_execution_time += execution_time
                processor.metrics.last_execution_time = execution_time

            return result

        except Exception as e:
            if metrics_enabled and hasattr(processor, 'metrics'):
                processor.metrics.error_count += 1
            raise

    return typed_node

# 使用类型化组件
def create_fully_typed_graph() -> Tuple[StateGraph, TextProcessor]:
    """创建完全类型化的图

    Returns:
        编译好的图和处理器实例的元组
    """
    processor = TextProcessor(min_length=5, max_length=500)

    graph = StateGraph(DocumentedState)

    # 使用类型化节点
    typed_node = create_typed_processing_node(processor, metrics_enabled=True)
    graph.add_node("typed_processor", typed_node)

    graph.add_edge(START, "typed_processor")
    graph.add_edge("typed_processor", END)

    return graph, processor
```

## 🚀 部署和运维最佳实践

### 1. 配置管理

```python
import os
import json
from pathlib import Path
from typing import Any, Dict, Optional
from dataclasses import dataclass, asdict
from enum import Enum

class Environment(Enum):
    """环境枚举"""
    DEVELOPMENT = "development"
    TESTING = "testing"
    STAGING = "staging"
    PRODUCTION = "production"

@dataclass
class DatabaseConfig:
    """数据库配置"""
    host: str
    port: int
    database: str
    username: str
    password: str
    pool_size: int = 10
    ssl_enabled: bool = True

@dataclass
class LLMConfig:
    """LLM配置"""
    provider: str
    model_name: str
    api_key: str
    max_tokens: int = 1000
    temperature: float = 0.7
    timeout: int = 30

@dataclass
class AppConfig:
    """应用配置"""
    environment: Environment
    debug: bool
    log_level: str
    database: DatabaseConfig
    llm: LLMConfig
    redis_url: str
    max_workers: int = 4
    enable_metrics: bool = True

class ConfigManager:
    """配置管理器"""

    def __init__(self, config_dir: str = "config"):
        self.config_dir = Path(config_dir)
        self.config_dir.mkdir(exist_ok=True)
        self._config: Optional[AppConfig] = None

    def load_config(self, environment: Environment = None) -> AppConfig:
        """加载配置"""
        if environment is None:
            environment = Environment(os.getenv("APP_ENV", "development"))

        # 加载基础配置
        base_config = self._load_config_file("base.json")

        # 加载环境特定配置
        env_config = self._load_config_file(f"{environment.value}.json")

        # 合并配置
        merged_config = {**base_config, **env_config}

        # 应用环境变量覆盖
        self._apply_env_overrides(merged_config)

        # 创建配置对象
        self._config = self._create_config_object(merged_config, environment)

        return self._config

    def _load_config_file(self, filename: str) -> Dict[str, Any]:
        """加载配置文件"""
        filepath = self.config_dir / filename
        if not filepath.exists():
            return {}

        with open(filepath, 'r', encoding='utf-8') as f:
            return json.load(f)

    def _apply_env_overrides(self, config: Dict[str, Any]):
        """应用环境变量覆盖"""
        env_mapping = {
            "DB_HOST": ("database", "host"),
            "DB_PORT": ("database", "port"),
            "DB_PASSWORD": ("database", "password"),
            "LLM_API_KEY": ("llm", "api_key"),
            "LLM_MODEL": ("llm", "model_name"),
            "REDIS_URL": ("redis_url",),
            "DEBUG": ("debug",),
            "LOG_LEVEL": ("log_level",),
        }

        for env_var, config_path in env_mapping.items():
            value = os.getenv(env_var)
            if value is not None:
                # 类型转换
                if env_var in ["DB_PORT", "DEBUG"]:
                    value = int(value) if env_var == "DB_PORT" else value.lower() == "true"

                # 设置嵌套配置值
                target = config
                for key in config_path[:-1]:
                    if key not in target:
                        target[key] = {}
                    target = target[key]
                target[config_path[-1]] = value

    def _create_config_object(self, config: Dict[str, Any], environment: Environment) -> AppConfig:
        """创建配置对象"""
        return AppConfig(
            environment=environment,
            debug=config.get("debug", False),
            log_level=config.get("log_level", "INFO"),
            database=DatabaseConfig(**config.get("database", {})),
            llm=LLMConfig(**config.get("llm", {})),
            redis_url=config.get("redis_url", "redis://localhost:6379"),
            max_workers=config.get("max_workers", 4),
            enable_metrics=config.get("enable_metrics", True)
        )

    def save_config_template(self):
        """保存配置模板"""
        template_config = {
            "debug": False,
            "log_level": "INFO",
            "max_workers": 4,
            "enable_metrics": True,
            "database": {
                "host": "localhost",
                "port": 5432,
                "database": "langgraph_app",
                "username": "user",
                "password": "password",
                "pool_size": 10,
                "ssl_enabled": True
            },
            "llm": {
                "provider": "openai",
                "model_name": "gpt-3.5-turbo",
                "api_key": "your-api-key",
                "max_tokens": 1000,
                "temperature": 0.7,
                "timeout": 30
            },
            "redis_url": "redis://localhost:6379"
        }

        # 保存基础配置
        base_file = self.config_dir / "base.json"
        with open(base_file, 'w', encoding='utf-8') as f:
            json.dump(template_config, f, indent=2)

        # 保存环境特定配置模板
        env_configs = {
            "development": {"debug": True, "log_level": "DEBUG"},
            "testing": {"database": {"database": "test_db"}},
            "production": {"debug": False, "enable_metrics": True}
        }

        for env, config in env_configs.items():
            env_file = self.config_dir / f"{env}.json"
            with open(env_file, 'w', encoding='utf-8') as f:
                json.dump(config, f, indent=2)

# 全局配置管理器
config_manager = ConfigManager()

def get_config() -> AppConfig:
    """获取应用配置"""
    return config_manager.load_config()

# 使用配置的图创建
def create_configured_graph(config: AppConfig = None) -> StateGraph:
    """创建配置化的图"""
    if config is None:
        config = get_config()

    def configured_llm_node(state: dict) -> dict:
        """配置化的LLM节点"""
        # 使用配置中的LLM设置
        llm_config = config.llm

        # 模拟LLM调用
        response = f"使用 {llm_config.model_name} 处理: {state.get('input', '')}"

        return {
            **state,
            "llm_response": response,
            "model_used": llm_config.model_name,
            "provider": llm_config.provider
        }

    graph = StateGraph(dict)
    graph.add_node("llm_processor", configured_llm_node)
    graph.add_edge(START, "llm_processor")
    graph.add_edge("llm_processor", END)

    return graph
```

### 2. 日志和监控

```python
import logging
import json
import time
from datetime import datetime
from typing import Dict, Any, Optional
from functools import wraps
from dataclasses import dataclass, asdict

@dataclass
class LogEntry:
    """日志条目"""
    timestamp: str
    level: str
    message: str
    node_name: Optional[str] = None
    execution_time: Optional[float] = None
    metadata: Optional[Dict[str, Any]] = None

class StructuredLogger:
    """结构化日志器"""

    def __init__(self, name: str, config: AppConfig):
        self.logger = logging.getLogger(name)
        self.config = config
        self._setup_logger()

    def _setup_logger(self):
        """设置日志器"""
        # 设置日志级别
        level = getattr(logging, self.config.log_level.upper())
        self.logger.setLevel(level)

        # 清除现有处理器
        self.logger.handlers.clear()

        # 创建格式化器
        if self.config.environment == Environment.PRODUCTION:
            # 生产环境使用JSON格式
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
        else:
            # 开发环境使用可读格式
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )

        # 控制台处理器
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(formatter)
        self.logger.addHandler(console_handler)

        # 文件处理器（生产环境）
        if self.config.environment == Environment.PRODUCTION:
            file_handler = logging.FileHandler('app.log')
            file_handler.setFormatter(formatter)
            self.logger.addHandler(file_handler)

    def log_node_execution(self,
                          node_name: str,
                          level: str,
                          message: str,
                          execution_time: Optional[float] = None,
                          metadata: Optional[Dict[str, Any]] = None):
        """记录节点执行日志"""
        log_entry = LogEntry(
            timestamp=datetime.now().isoformat(),
            level=level,
            message=message,
            node_name=node_name,
            execution_time=execution_time,
            metadata=metadata
        )

        # 根据环境选择日志格式
        if self.config.environment == Environment.PRODUCTION:
            log_message = json.dumps(asdict(log_entry), ensure_ascii=False)
        else:
            log_message = f"[{node_name}] {message}"
            if execution_time:
                log_message += f" (耗时: {execution_time:.3f}s)"

        # 记录日志
        log_level = getattr(self.logger, level.lower())
        log_level(log_message)

class MetricsCollector:
    """指标收集器"""

    def __init__(self, enabled: bool = True):
        self.enabled = enabled
        self.metrics = {
            "node_executions": {},
            "execution_times": {},
            "error_counts": {},
            "graph_runs": 0,
            "total_execution_time": 0.0
        }

    def record_node_execution(self, node_name: str, execution_time: float, success: bool):
        """记录节点执行指标"""
        if not self.enabled:
            return

        # 执行次数
        if node_name not in self.metrics["node_executions"]:
            self.metrics["node_executions"][node_name] = 0
        self.metrics["node_executions"][node_name] += 1

        # 执行时间
        if node_name not in self.metrics["execution_times"]:
            self.metrics["execution_times"][node_name] = []
        self.metrics["execution_times"][node_name].append(execution_time)

        # 错误计数
        if not success:
            if node_name not in self.metrics["error_counts"]:
                self.metrics["error_counts"][node_name] = 0
            self.metrics["error_counts"][node_name] += 1

    def record_graph_run(self, execution_time: float):
        """记录图运行指标"""
        if not self.enabled:
            return

        self.metrics["graph_runs"] += 1
        self.metrics["total_execution_time"] += execution_time

    def get_metrics_summary(self) -> Dict[str, Any]:
        """获取指标摘要"""
        if not self.enabled:
            return {"metrics_disabled": True}

        summary = {}

        # 节点指标摘要
        for node_name, times in self.metrics["execution_times"].items():
            if times:
                summary[node_name] = {
                    "executions": self.metrics["node_executions"].get(node_name, 0),
                    "avg_time": sum(times) / len(times),
                    "max_time": max(times),
                    "min_time": min(times),
                    "errors": self.metrics["error_counts"].get(node_name, 0)
                }

        # 整体指标
        summary["overall"] = {
            "total_graph_runs": self.metrics["graph_runs"],
            "total_execution_time": self.metrics["total_execution_time"],
            "avg_graph_time": (
                self.metrics["total_execution_time"] / self.metrics["graph_runs"]
                if self.metrics["graph_runs"] > 0 else 0
            )
        }

        return summary

# 全局组件
app_config = get_config()
structured_logger = StructuredLogger("langgraph_app", app_config)
metrics_collector = MetricsCollector(enabled=app_config.enable_metrics)

def monitored_node(node_name: str):
    """监控节点装饰器"""
    def decorator(func):
        @wraps(func)
        def wrapper(state: dict) -> dict:
            start_time = time.time()

            # 记录开始
            structured_logger.log_node_execution(
                node_name, "INFO", f"开始执行节点: {node_name}"
            )

            try:
                result = func(state)
                execution_time = time.time() - start_time

                # 记录成功
                structured_logger.log_node_execution(
                    node_name, "INFO", f"节点执行成功: {node_name}",
                    execution_time=execution_time
                )

                metrics_collector.record_node_execution(
                    node_name, execution_time, success=True
                )

                return result

            except Exception as e:
                execution_time = time.time() - start_time

                # 记录错误
                structured_logger.log_node_execution(
                    node_name, "ERROR", f"节点执行失败: {node_name} - {str(e)}",
                    execution_time=execution_time,
                    metadata={"error_type": type(e).__name__}
                )

                metrics_collector.record_node_execution(
                    node_name, execution_time, success=False
                )

                raise

        return wrapper
    return decorator

def create_monitored_graph() -> StateGraph:
    """创建监控化的图"""

    @monitored_node("data_processor")
    def data_processor(state: dict) -> dict:
        # 模拟处理
        time.sleep(0.1)
        return {**state, "processed": True}

    @monitored_node("validator")
    def validator(state: dict) -> dict:
        # 模拟验证
        if not state.get("input"):
            raise ValueError("输入为空")
        return {**state, "validated": True}

    graph = StateGraph(dict)
    graph.add_node("validator", validator)
    graph.add_node("processor", data_processor)

    graph.add_edge(START, "validator")
    graph.add_edge("validator", "processor")
    graph.add_edge("processor", END)

    return graph

def run_with_monitoring(graph_app, input_state: dict) -> dict:
    """运行带监控的图"""
    start_time = time.time()

    try:
        result = graph_app.invoke(input_state)
        execution_time = time.time() - start_time

        metrics_collector.record_graph_run(execution_time)

        structured_logger.log_node_execution(
            "graph", "INFO", "图执行完成",
            execution_time=execution_time,
            metadata={"success": True}
        )

        return result

    except Exception as e:
        execution_time = time.time() - start_time

        structured_logger.log_node_execution(
            "graph", "ERROR", f"图执行失败: {str(e)}",
            execution_time=execution_time,
            metadata={"success": False, "error_type": type(e).__name__}
        )

        raise
```

## 📚 延伸阅读

- [Clean Code 原则](https://clean-code-developer.com/)
- [Python 代码风格指南 PEP 8](https://pep8.org/)
- [设计模式详解](https://refactoring.guru/design-patterns)
- [十二要素应用](https://12factor.net/zh_cn/)

---

💡 **小贴士**：好的实践需要持续的坚持和改进。从小处着手，逐步建立起完整的开发规范体系！